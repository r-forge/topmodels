[
  {
    "objectID": "man/Empirical.html",
    "href": "man/Empirical.html",
    "title": "topmodels",
    "section": "",
    "text": "An empirical distribution consists of a series of N observations out of a typically unknown distribution, i.e., a random sample ‘X’.\nDraws n random values from the empirical ensemble with replacement.\nPlease see the documentation of [Empirical()] for some properties of the empircal ensemble distribution, as well as extensive examples showing to how calculate p-values and confidence intervals.\nPlease see the documentation of [Empirical()] for some properties of the Empirical distribution, as well as extensive examples showing to how calculate p-values and confidence intervals. ‘quantile()’\nTODO(RETO): Check description\n\nEmpirical(x)\n\npempirical(q, y, lower.tail = TRUE, log.p = FALSE, na.rm = TRUE)\n\ndempirical(x, y, log = FALSE, method = \"hist\", ...)\n\nqempirical(p, y, lower.tail = TRUE, log.p = FALSE, na.rm = TRUE, ...)\n\nrempirical(n, y, na.rm = TRUE)\n\n## S3 method for class 'Empirical'\nmean(x, ...)\n\n## S3 method for class 'Empirical'\nvariance(x, ...)\n\n## S3 method for class 'Empirical'\nskewness(x, type = 1L, ...)\n\n## S3 method for class 'Empirical'\nkurtosis(x, type = 3L, ...)\n\n## S3 method for class 'Empirical'\nrandom(x, n = 1L, drop = TRUE, ...)\n\n## S3 method for class 'Empirical'\npdf(d, x, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\nlog_pdf(d, x, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\ncdf(d, x, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\nquantile(x, probs, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\nsupport(d, drop = TRUE, ...)\n\n\n\n\n\nx\n\n\nA vector of elements whose cumulative probabilities you would like to determine given the distribution ‘d’.\n\n\n\n\nq\n\n\nvector of quantiles.\n\n\n\n\ny\n\n\nvector of observations of the empirical distribution with two or more non-missing finite values.\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x]. or “density”.\n\n\n\n\nna.rm\n\n\nlogical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nmethod\n\n\ncharacter; the method to calculate the empirical density. Either “hist” (default)\n\n\n\n\n…\n\n\nCurrently not used.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nThe number of samples to draw. Defaults to ‘1L’.\n\n\n\n\ntype\n\n\ninteger between 1L and 3L (default) selecting one of three algorithms. See Details for more information.\n\n\n\n\ndrop\n\n\nlogical. Should the result be simplified to a vector if possible?\n\n\n\n\nd\n\n\nAn ‘Empirical’ object created by a call to [Empirical()].\n\n\n\n\nelementwise\n\n\nlogical. Should each distribution in x be evaluated at all elements of probs (elementwise = FALSE, yielding a matrix)? Or, if x and probs have the same length, should the evaluation be done element by element (elementwise = TRUE, yielding a vector)? The default of NULL means that elementwise = TRUE is used if the lengths match and otherwise elementwise = FALSE is used.\n\n\n\n\nprobs\n\n\nA vector of probabilities.\n\n\n\nThe creation function [Empirical()] allows for a variety of different objects as main input x.\n\nVector: Assumes that the vector contains a series of observations from one empirical distribution.\nList (named or unnamed) of vectors: Each element in the list describes one empirical distribution defined by the numeric values in each of the vectors.\nMatrix or data.frame: Each row corresponds to one empirical distribution, whilst the columns contain the individual observations.\n\nMissing values are allowed, however, each distribution requires at least two finite observations (-Inf/Inf is replaced by NA).\nSupport: \\(R\\), the set of all real numbers\nMean:\n\n\n\\(\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i\\)\nVariance:\n\n\n\\(\\frac{1}{N - 1} \\sum_{i=1}^{N} (x_i - \\bar{x})\\)\nSkewness:\n\\(S_1 = \\sqrt{N} \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^3}{\\sqrt{\\big(\\sum_{i=1}^N (x_i - \\bar{x})^2\\big)^3}}\\)\n\\(S_2 = \\frac{\\sqrt{N * (N - 1)}}{(N - 2)} S_1\\) (only defined for \\(N &gt; 2\\))\n\\(S_3 = \\sqrt{(1 - \\frac{1}{N})^3} * S_1\\) (default)\nFor more details about the different types of sample skewness see Joanes and Gill (1998).\nKurtosis:\n\\(K_1 = N * \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^4}{\\big(\\sum_{i=1}^N (x_i - \\bar{x})^2\\big)^2} - 3\\)\n\\(K_2 = \\frac{(N + 1) * K_1 + 6) * (N - 1)}{(N - 2) * (N - 3)}\\) (only defined for \\(N &gt; 2\\))\n\\(K_3 = \\big(1 - \\frac{1}{N}\\big)^2 * (K_1 + 3) - 3\\) (default)\nFor more details about the different types of sample kurtosis see Joanes and Gill (1998).\nTODO(RETO): Add empirical distribution function information (step-function 1/N)\nProbability density function (p.d.f):\nThis function returns the same values that you get from a Z-table. Note ‘quantile()’ is the inverse of ‘cdf()’. Please see the documentation of [Empirical()] for some properties of the Empirical distribution, as well as extensive examples showing to how calculate p-values and confidence intervals.\n\nAn ‘Empirical’ object.\nIn case of a single distribution object or ‘n = 1’, either a numeric vector of length ‘n’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘n’ columns (if ‘drop = FALSE’).\nIn case of a single distribution object, either a numeric vector of length ‘probs’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘length(x)’ columns (if ‘drop = FALSE’). In case of a vectorized distribution object, a matrix with ‘length(x)’ columns containing all possible combinations.\nIn case of a single distribution object, either a numeric vector of length ‘probs’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘length(x)’ columns (if ‘drop = FALSE’). In case of a vectorized distribution object, a matrix with ‘length(x)’ columns containing all possible combinations.\nIn case of a single distribution object, either a numeric vector of length ‘probs’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘length(probs)’ columns (if ‘drop = FALSE’). In case of a vectorized distribution object, a matrix with ‘length(probs)’ columns containing all possible combinations.\nIn case of a single distribution object, a numeric vector of length 2 with the minimum and maximum value of the support (if ‘drop = TRUE’, default) or a ‘matrix’ with 2 columns. In case of a vectorized distribution object, a matrix with 2 columns containing all minima and maxima.\n\nJoanes DN and Gill CA (1998). “Comparing Measures of Sample Skewness and Kurtosis.” Journal of the Royal Statistical Society D, 47(1), 183–189. doi:10.1111/1467-9884.00122\n\n\nlibrary(\"topmodels\")\n\n\nrequire(\"distributions3\")\nset.seed(28)\n\nX &lt;- Empirical(rnorm(50))\nX\n\n[1] \"Empirical distribution (Min. -2.100, Max.  2.187, N = 50)\"\n\nmean(X)\n\n[1] -0.09838857\n\nvariance(X)\n\n[1] 1.076242\n\nskewness(X)\n\n[1] 0.1027858\n\nkurtosis(X)\n\n[1] -0.5339262\n\nrandom(X, 10)\n\n [1]  0.62280108 -1.66020539 -0.06429479 -0.61645815  0.14298835 -1.85883315\n [7] -0.82054223 -1.66020539 -0.88294400 -0.43544484\n\npdf(X, 2)\n\n[1] 0.04\n\nlog_pdf(X, 2)\n\n[1] -3.218876\n\ncdf(X, 4)\n\n[1] 1\n\nquantile(X, 0.7)\n\n[1] 0.3600124\n\n### example: allowed types/classes of input arguments\n\n## Single vector (will be coerced to numeric)\nY1  &lt;- rnorm(3, mean = -10)\nd1 &lt;- Empirical(Y1)\nd1\n\n[1] \"Empirical distribution (Min. -10.70, Max.  -9.95, N = 3)\"\n\nmean(d1)\n\n[1] -10.28573\n\n## Unnamed list of vectors\nY2 &lt;- list(as.character(rnorm(3, mean = -10)),\n           runif(6),\n           rpois(4, lambda = 15))\nd2 &lt;- Empirical(Y2)\nd2\n\n[1] \"Empirical distribution (Min. -10.6917, Max.  -8.1584, N = 3)\"\n[2] \"Empirical distribution (Min.   0.2365, Max.   0.8445, N = 6)\"\n[3] \"Empirical distribution (Min.  13.0000, Max.  22.0000, N = 4)\"\n\nmean(d2)\n\n[1] -9.7327191  0.5375046 17.5000000\n\n## Named list of vectors\nY3 &lt;- list(\"Normal\"  = as.character(rnorm(3, mean = -10)),\n           \"Uniform\" = runif(6),\n           \"Poisson\" = rpois(4, lambda = 15))\nd3 &lt;- Empirical(Y3)\nd3\n\n                                                        Normal \n\"Empirical distribution (Min. -11.1410, Max.  -8.4768, N = 3)\" \n                                                       Uniform \n\"Empirical distribution (Min.   0.1372, Max.   0.9940, N = 6)\" \n                                                       Poisson \n\"Empirical distribution (Min.  16.0000, Max.  22.0000, N = 4)\" \n\nmean(d3)\n\n     Normal     Uniform     Poisson \n-10.0322492   0.5316866  18.2500000 \n\n## Matrix or data.frame\nY4 &lt;- matrix(rnorm(20), ncol = 5, dimnames = list(sprintf(\"D_%d\", 1:4), sprintf(\"obs_%d\", 1:5)))\nd4 &lt;- Empirical(Y4)\nd4\n\n                                                         D_1 \n\"Empirical distribution (Min. -0.2841, Max.  1.0164, N = 5)\" \n                                                         D_2 \n\"Empirical distribution (Min. -0.6239, Max.  1.1759, N = 5)\" \n                                                         D_3 \n\"Empirical distribution (Min. -2.3085, Max.  1.7337, N = 5)\" \n                                                         D_4 \n\"Empirical distribution (Min. -1.5264, Max.  2.4897, N = 5)\" \n\nd5 &lt;- Empirical(as.data.frame(Y4))\nd5\n\n                                                       obs_1 \n\"Empirical distribution (Min. -2.3085, Max. -0.2841, N = 4)\" \n                                                       obs_2 \n\"Empirical distribution (Min. -1.1744, Max.  1.1759, N = 4)\" \n                                                       obs_3 \n\"Empirical distribution (Min. -0.1304, Max.  2.4897, N = 4)\" \n                                                       obs_4 \n\"Empirical distribution (Min. -1.5264, Max.  1.0164, N = 4)\" \n                                                       obs_5 \n\"Empirical distribution (Min.  0.1128, Max.  1.6950, N = 4)\"",
    "crumbs": [
      "Interfaces to models/distributions",
      "Empirical"
    ]
  },
  {
    "objectID": "man/Empirical.html#create-an-empirical-distribution",
    "href": "man/Empirical.html#create-an-empirical-distribution",
    "title": "topmodels",
    "section": "",
    "text": "An empirical distribution consists of a series of N observations out of a typically unknown distribution, i.e., a random sample ‘X’.\nDraws n random values from the empirical ensemble with replacement.\nPlease see the documentation of [Empirical()] for some properties of the empircal ensemble distribution, as well as extensive examples showing to how calculate p-values and confidence intervals.\nPlease see the documentation of [Empirical()] for some properties of the Empirical distribution, as well as extensive examples showing to how calculate p-values and confidence intervals. ‘quantile()’\nTODO(RETO): Check description\n\nEmpirical(x)\n\npempirical(q, y, lower.tail = TRUE, log.p = FALSE, na.rm = TRUE)\n\ndempirical(x, y, log = FALSE, method = \"hist\", ...)\n\nqempirical(p, y, lower.tail = TRUE, log.p = FALSE, na.rm = TRUE, ...)\n\nrempirical(n, y, na.rm = TRUE)\n\n## S3 method for class 'Empirical'\nmean(x, ...)\n\n## S3 method for class 'Empirical'\nvariance(x, ...)\n\n## S3 method for class 'Empirical'\nskewness(x, type = 1L, ...)\n\n## S3 method for class 'Empirical'\nkurtosis(x, type = 3L, ...)\n\n## S3 method for class 'Empirical'\nrandom(x, n = 1L, drop = TRUE, ...)\n\n## S3 method for class 'Empirical'\npdf(d, x, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\nlog_pdf(d, x, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\ncdf(d, x, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\nquantile(x, probs, drop = TRUE, elementwise = NULL, ...)\n\n## S3 method for class 'Empirical'\nsupport(d, drop = TRUE, ...)\n\n\n\n\n\nx\n\n\nA vector of elements whose cumulative probabilities you would like to determine given the distribution ‘d’.\n\n\n\n\nq\n\n\nvector of quantiles.\n\n\n\n\ny\n\n\nvector of observations of the empirical distribution with two or more non-missing finite values.\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x]. or “density”.\n\n\n\n\nna.rm\n\n\nlogical evaluating to TRUE or FALSE indicating whether NA values should be stripped before the computation proceeds.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nmethod\n\n\ncharacter; the method to calculate the empirical density. Either “hist” (default)\n\n\n\n\n…\n\n\nCurrently not used.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nThe number of samples to draw. Defaults to ‘1L’.\n\n\n\n\ntype\n\n\ninteger between 1L and 3L (default) selecting one of three algorithms. See Details for more information.\n\n\n\n\ndrop\n\n\nlogical. Should the result be simplified to a vector if possible?\n\n\n\n\nd\n\n\nAn ‘Empirical’ object created by a call to [Empirical()].\n\n\n\n\nelementwise\n\n\nlogical. Should each distribution in x be evaluated at all elements of probs (elementwise = FALSE, yielding a matrix)? Or, if x and probs have the same length, should the evaluation be done element by element (elementwise = TRUE, yielding a vector)? The default of NULL means that elementwise = TRUE is used if the lengths match and otherwise elementwise = FALSE is used.\n\n\n\n\nprobs\n\n\nA vector of probabilities.\n\n\n\nThe creation function [Empirical()] allows for a variety of different objects as main input x.\n\nVector: Assumes that the vector contains a series of observations from one empirical distribution.\nList (named or unnamed) of vectors: Each element in the list describes one empirical distribution defined by the numeric values in each of the vectors.\nMatrix or data.frame: Each row corresponds to one empirical distribution, whilst the columns contain the individual observations.\n\nMissing values are allowed, however, each distribution requires at least two finite observations (-Inf/Inf is replaced by NA).\nSupport: \\(R\\), the set of all real numbers\nMean:\n\n\n\\(\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i\\)\nVariance:\n\n\n\\(\\frac{1}{N - 1} \\sum_{i=1}^{N} (x_i - \\bar{x})\\)\nSkewness:\n\\(S_1 = \\sqrt{N} \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^3}{\\sqrt{\\big(\\sum_{i=1}^N (x_i - \\bar{x})^2\\big)^3}}\\)\n\\(S_2 = \\frac{\\sqrt{N * (N - 1)}}{(N - 2)} S_1\\) (only defined for \\(N &gt; 2\\))\n\\(S_3 = \\sqrt{(1 - \\frac{1}{N})^3} * S_1\\) (default)\nFor more details about the different types of sample skewness see Joanes and Gill (1998).\nKurtosis:\n\\(K_1 = N * \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^4}{\\big(\\sum_{i=1}^N (x_i - \\bar{x})^2\\big)^2} - 3\\)\n\\(K_2 = \\frac{(N + 1) * K_1 + 6) * (N - 1)}{(N - 2) * (N - 3)}\\) (only defined for \\(N &gt; 2\\))\n\\(K_3 = \\big(1 - \\frac{1}{N}\\big)^2 * (K_1 + 3) - 3\\) (default)\nFor more details about the different types of sample kurtosis see Joanes and Gill (1998).\nTODO(RETO): Add empirical distribution function information (step-function 1/N)\nProbability density function (p.d.f):\nThis function returns the same values that you get from a Z-table. Note ‘quantile()’ is the inverse of ‘cdf()’. Please see the documentation of [Empirical()] for some properties of the Empirical distribution, as well as extensive examples showing to how calculate p-values and confidence intervals.\n\nAn ‘Empirical’ object.\nIn case of a single distribution object or ‘n = 1’, either a numeric vector of length ‘n’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘n’ columns (if ‘drop = FALSE’).\nIn case of a single distribution object, either a numeric vector of length ‘probs’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘length(x)’ columns (if ‘drop = FALSE’). In case of a vectorized distribution object, a matrix with ‘length(x)’ columns containing all possible combinations.\nIn case of a single distribution object, either a numeric vector of length ‘probs’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘length(x)’ columns (if ‘drop = FALSE’). In case of a vectorized distribution object, a matrix with ‘length(x)’ columns containing all possible combinations.\nIn case of a single distribution object, either a numeric vector of length ‘probs’ (if ‘drop = TRUE’, default) or a ‘matrix’ with ‘length(probs)’ columns (if ‘drop = FALSE’). In case of a vectorized distribution object, a matrix with ‘length(probs)’ columns containing all possible combinations.\nIn case of a single distribution object, a numeric vector of length 2 with the minimum and maximum value of the support (if ‘drop = TRUE’, default) or a ‘matrix’ with 2 columns. In case of a vectorized distribution object, a matrix with 2 columns containing all minima and maxima.\n\nJoanes DN and Gill CA (1998). “Comparing Measures of Sample Skewness and Kurtosis.” Journal of the Royal Statistical Society D, 47(1), 183–189. doi:10.1111/1467-9884.00122\n\n\nlibrary(\"topmodels\")\n\n\nrequire(\"distributions3\")\nset.seed(28)\n\nX &lt;- Empirical(rnorm(50))\nX\n\n[1] \"Empirical distribution (Min. -2.100, Max.  2.187, N = 50)\"\n\nmean(X)\n\n[1] -0.09838857\n\nvariance(X)\n\n[1] 1.076242\n\nskewness(X)\n\n[1] 0.1027858\n\nkurtosis(X)\n\n[1] -0.5339262\n\nrandom(X, 10)\n\n [1]  0.62280108 -1.66020539 -0.06429479 -0.61645815  0.14298835 -1.85883315\n [7] -0.82054223 -1.66020539 -0.88294400 -0.43544484\n\npdf(X, 2)\n\n[1] 0.04\n\nlog_pdf(X, 2)\n\n[1] -3.218876\n\ncdf(X, 4)\n\n[1] 1\n\nquantile(X, 0.7)\n\n[1] 0.3600124\n\n### example: allowed types/classes of input arguments\n\n## Single vector (will be coerced to numeric)\nY1  &lt;- rnorm(3, mean = -10)\nd1 &lt;- Empirical(Y1)\nd1\n\n[1] \"Empirical distribution (Min. -10.70, Max.  -9.95, N = 3)\"\n\nmean(d1)\n\n[1] -10.28573\n\n## Unnamed list of vectors\nY2 &lt;- list(as.character(rnorm(3, mean = -10)),\n           runif(6),\n           rpois(4, lambda = 15))\nd2 &lt;- Empirical(Y2)\nd2\n\n[1] \"Empirical distribution (Min. -10.6917, Max.  -8.1584, N = 3)\"\n[2] \"Empirical distribution (Min.   0.2365, Max.   0.8445, N = 6)\"\n[3] \"Empirical distribution (Min.  13.0000, Max.  22.0000, N = 4)\"\n\nmean(d2)\n\n[1] -9.7327191  0.5375046 17.5000000\n\n## Named list of vectors\nY3 &lt;- list(\"Normal\"  = as.character(rnorm(3, mean = -10)),\n           \"Uniform\" = runif(6),\n           \"Poisson\" = rpois(4, lambda = 15))\nd3 &lt;- Empirical(Y3)\nd3\n\n                                                        Normal \n\"Empirical distribution (Min. -11.1410, Max.  -8.4768, N = 3)\" \n                                                       Uniform \n\"Empirical distribution (Min.   0.1372, Max.   0.9940, N = 6)\" \n                                                       Poisson \n\"Empirical distribution (Min.  16.0000, Max.  22.0000, N = 4)\" \n\nmean(d3)\n\n     Normal     Uniform     Poisson \n-10.0322492   0.5316866  18.2500000 \n\n## Matrix or data.frame\nY4 &lt;- matrix(rnorm(20), ncol = 5, dimnames = list(sprintf(\"D_%d\", 1:4), sprintf(\"obs_%d\", 1:5)))\nd4 &lt;- Empirical(Y4)\nd4\n\n                                                         D_1 \n\"Empirical distribution (Min. -0.2841, Max.  1.0164, N = 5)\" \n                                                         D_2 \n\"Empirical distribution (Min. -0.6239, Max.  1.1759, N = 5)\" \n                                                         D_3 \n\"Empirical distribution (Min. -2.3085, Max.  1.7337, N = 5)\" \n                                                         D_4 \n\"Empirical distribution (Min. -1.5264, Max.  2.4897, N = 5)\" \n\nd5 &lt;- Empirical(as.data.frame(Y4))\nd5\n\n                                                       obs_1 \n\"Empirical distribution (Min. -2.3085, Max. -0.2841, N = 4)\" \n                                                       obs_2 \n\"Empirical distribution (Min. -1.1744, Max.  1.1759, N = 4)\" \n                                                       obs_3 \n\"Empirical distribution (Min. -0.1304, Max.  2.4897, N = 4)\" \n                                                       obs_4 \n\"Empirical distribution (Min. -1.5264, Max.  1.0164, N = 4)\" \n                                                       obs_5 \n\"Empirical distribution (Min.  0.1128, Max.  1.6950, N = 4)\"",
    "crumbs": [
      "Interfaces to models/distributions",
      "Empirical"
    ]
  },
  {
    "objectID": "man/procast.html",
    "href": "man/procast.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and methods for computing various kinds of probabilistic forecasts from (regression) models.\n\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...\n)\n\n## Default S3 method:\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = c(\"distribution\", \"mean\", \"variance\", \"quantile\", \"probability\", \"density\",\n    \"loglikelihood\", \"parameters\", \"kurtosis\", \"skewness\"),\n  at = 0.5,\n  drop = FALSE,\n  ...\n)\n\n## S3 method for class 'lm'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  sigma = \"ML\"\n)\n\n## S3 method for class 'glm'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  dispersion = NULL\n)\n\n## S3 method for class 'bamlss'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  distributions3 = FALSE\n)\n\n## S3 method for class 'disttree'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  distributions3 = FALSE\n)\n\n\n\n\n\nobject\n\n\na fitted model object. For the default method this needs to have a prodist method (or object can inherit from distribution directly).\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to employ NA.\n\n\n\n\ntype\n\n\ncharacter specifying the type of probabilistic forecast to compute. The default is to return a “distribution” object (using the infrastructure from distributions3). Alternatively, just the “parameters” of the distribution can be computed or the corresponding moments: “mean”, “variance”, “skewness”, “kurtosis”. Finally, standard functions for the distribution can be evaluated (at argument at, see below), namely the “density” (or equivalently “pdf” or “pmf”), the “log_likelihood” (or equivalently “log_pdf”), the “quantile” function, or the cumulative “probability” (or equivalently “cdf”).\n\n\n\n\nat\n\n\nnumeric vector at which the forecasts should be evaluated if type specifies a function that takes an additional argument.\n\n\n\n\ndrop\n\n\nlogical. Should forecasts be returned in a data frame (default) or (if possible) dropped to a vector, see return value description below.\n\n\n\n\n…\n\n\nfurther parameters passed to methods. In particular, this includes the logical argument elementwise = NULL. Should each element of distribution only be evaluated at the corresponding element of at (elementwise = TRUE) or at all elements in at (elementwise = FALSE). Elementwise evaluation is only possible if the number of observations is the same as the length of at and in that case a vector of the same length is returned. Otherwise a matrix is returned. The default is to use elementwise = TRUE if possible, and otherwise elementwise = FALSE.\n\n\n\n\nsigma\n\n\ncharacter or numeric or NULL. Specification of the standard deviation sigma to be used for the Normal distribution in the lm method. The default “ML” (or equivalently “MLE” or NULL) uses the maximum likelihood estimate based on the residual sum of squares divided by the number of observations, n. Alternatively, sigma = “OLS” uses the least-squares estimate (divided by the residual degrees of freedom, n - k). Finally, a concrete numeric value can also be specified in sigma.\n\n\n\n\ndispersion\n\n\ncharacter or numeric or NULL. Specification of the dispersion parameter in the glm method. The default NULL (or equivalently “deviance”) is to use the deviance divided by the number of observations, n. Alternatively, dispersion = “Chisquared” uses the Chi-squared statistic divided by the residual degrees of freedom, n - k. Finally, a concrete numeric value can also be specified in dispersion.\n\n\n\n\ndistributions3\n\n\nlogical. If a dedicated distributions3 object is available (e.g., such as Normal) and uses the same parameterization, should this be used instead of the general disttree distribution?\n\n\n\nThe function procast provides a unified framework for probabilistic forcasting (or procasting, for short) based on probabilistic (regression) models, also known as distributional regression approaches. Typical types of predictions include quantiles, probabilities, (conditional) expectations, variances, and (log-)densities. Internally, procast methods typically compute the predicted parameters for each observation and then compute the desired outcome for the distributions with the respective parameters.\nSome quantities, e.g., the moments of the distribution (like mean or variance), can be computed directly from the predicted parameters of the distribution while others require an additional argument at which the distribution is evaluated (e.g., the probability of a quantile or an observation of the response).\nThe default procast method leverages the S3 classes and methods for probability distributions from the distributions3 package. In a first step the predicted probability distribution object is obtained and, by default (type = “distribution”), returned in order to reflect the distributional nature of the forecast. For all other types (e.g., “mean”, “quantile”, or “density”), the corresponding extractor methods (e.g., mean, quantile, or pdf) are used to compute the desired quantity from the distribution objects. The examples provide some worked illustrations.\nPackage authors or users, who want to enable procast for new types of model objects, only need to provide a suitable prodist extractor for the predicted probability distribution. Then the default procast works out of the box. However, if the distributions3 package does not support the necessary probability distribution, then it may also be necessary to implement a new distribution objects, see apply_dpqr.\n\nEither a data.frame of predictions with the same number of rows as the newdata (or the original observations if that is NULL). If drop = TRUE predictions with just a single column are simplified to a vector and predictions with multiple columns to a matrix.\n\n\nlibrary(\"topmodels\")\n\n## load packages\nlibrary(\"topmodels\")\nlibrary(\"distributions3\")\n\n## Poisson regression model for FIFA 2018 data:\n## number of goals scored by each team in each game, explained by\n## predicted ability difference of the competing teams\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## predicted probability distributions for all matches (in sample)\nhead(procast(m))\n\n                 distribution\n1 Poisson(lambda = 1.7680273)\n2 Poisson(lambda = 0.8655224)\n3 Poisson(lambda = 1.0296663)\n4 Poisson(lambda = 1.4861779)\n5 Poisson(lambda = 1.4353952)\n6 Poisson(lambda = 1.0660948)\n\nhead(procast(m, drop = TRUE))\n\n                         1                          2 \n\"Poisson(lambda = 1.7680)\" \"Poisson(lambda = 0.8655)\" \n                         3                          4 \n\"Poisson(lambda = 1.0297)\" \"Poisson(lambda = 1.4862)\" \n                         5                          6 \n\"Poisson(lambda = 1.4354)\" \"Poisson(lambda = 1.0661)\" \n\n## procasts for new data\n## much lower, equal, and much higher ability than opponent\nnd &lt;- data.frame(difference = c(-1, 0, 1))\n\n## predicted goal distribution object\ngoals &lt;- procast(m, newdata = nd, drop = TRUE)\ngoals\n\n                         1                          2 \n\"Poisson(lambda = 0.8181)\" \"Poisson(lambda = 1.2370)\" \n                         3 \n\"Poisson(lambda = 1.8704)\" \n\n## predicted densities/probabilities for scoring 0, 1, ..., 5 goals\nprocast(m, newdata = nd, type = \"density\", at = 0:5)\n\n        d_0       d_1       d_2        d_3         d_4         d_5\n1 0.4412492 0.3610060 0.1476777 0.04027394 0.008237485 0.001347892\n2 0.2902421 0.3590411 0.2220740 0.09157147 0.028319386 0.007006441\n3 0.1540605 0.2881563 0.2694852 0.16801593 0.078564672 0.029389630\n\n## by hand\npdf(goals, 0:5)\n\n        d_0       d_1       d_2        d_3         d_4         d_5\n1 0.4412492 0.3610060 0.1476777 0.04027394 0.008237485 0.001347892\n2 0.2902421 0.3590411 0.2220740 0.09157147 0.028319386 0.007006441\n3 0.1540605 0.2881563 0.2694852 0.16801593 0.078564672 0.029389630\n\n## means and medians\nprocast(m, newdata = nd, type = \"mean\")\n\n       mean\n1 0.8181454\n2 1.2370397\n3 1.8704100\n\nprocast(m, newdata = nd, type = \"quantile\", at = 0.5)\n\n  quantile\n1        1\n2        1\n3        2\n\n## by hand\nmean(goals)\n\n        1         2         3 \n0.8181454 1.2370397 1.8704100 \n\nquantile(goals, 0.5)\n\n1 2 3 \n1 1 2 \n\n## evaluate procast elementwise or for all possible combinations\n## of distributions from 'nd' and observations in 'at'\nprocast(m, newdata = nd, type = \"probability\", at = 1:3, elementwise = TRUE)\n\n  probability\n1   0.8022553\n2   0.8713572\n3   0.8797179\n\nprocast(m, newdata = nd, type = \"probability\", at = 1:3, elementwise = FALSE)\n\n        p_1       p_2       p_3\n1 0.8022553 0.9499330 0.9902069\n2 0.6492832 0.8713572 0.9629287\n3 0.4422167 0.7117019 0.8797179\n\n## compute in-sample log-likelihood sum via procast\nsum(procast(m, type = \"density\", at = FIFA2018$goals, log = TRUE))\n\n[1] -177.6971\n\nlogLik(m)\n\n'log Lik.' -177.6971 (df=2)",
    "crumbs": [
      "Procast infrastructure",
      "procast"
    ]
  },
  {
    "objectID": "man/procast.html#procast-probabilistic-forecasting",
    "href": "man/procast.html#procast-probabilistic-forecasting",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and methods for computing various kinds of probabilistic forecasts from (regression) models.\n\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...\n)\n\n## Default S3 method:\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = c(\"distribution\", \"mean\", \"variance\", \"quantile\", \"probability\", \"density\",\n    \"loglikelihood\", \"parameters\", \"kurtosis\", \"skewness\"),\n  at = 0.5,\n  drop = FALSE,\n  ...\n)\n\n## S3 method for class 'lm'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  sigma = \"ML\"\n)\n\n## S3 method for class 'glm'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  dispersion = NULL\n)\n\n## S3 method for class 'bamlss'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  distributions3 = FALSE\n)\n\n## S3 method for class 'disttree'\nprocast(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = \"distribution\",\n  at = 0.5,\n  drop = FALSE,\n  ...,\n  distributions3 = FALSE\n)\n\n\n\n\n\nobject\n\n\na fitted model object. For the default method this needs to have a prodist method (or object can inherit from distribution directly).\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to employ NA.\n\n\n\n\ntype\n\n\ncharacter specifying the type of probabilistic forecast to compute. The default is to return a “distribution” object (using the infrastructure from distributions3). Alternatively, just the “parameters” of the distribution can be computed or the corresponding moments: “mean”, “variance”, “skewness”, “kurtosis”. Finally, standard functions for the distribution can be evaluated (at argument at, see below), namely the “density” (or equivalently “pdf” or “pmf”), the “log_likelihood” (or equivalently “log_pdf”), the “quantile” function, or the cumulative “probability” (or equivalently “cdf”).\n\n\n\n\nat\n\n\nnumeric vector at which the forecasts should be evaluated if type specifies a function that takes an additional argument.\n\n\n\n\ndrop\n\n\nlogical. Should forecasts be returned in a data frame (default) or (if possible) dropped to a vector, see return value description below.\n\n\n\n\n…\n\n\nfurther parameters passed to methods. In particular, this includes the logical argument elementwise = NULL. Should each element of distribution only be evaluated at the corresponding element of at (elementwise = TRUE) or at all elements in at (elementwise = FALSE). Elementwise evaluation is only possible if the number of observations is the same as the length of at and in that case a vector of the same length is returned. Otherwise a matrix is returned. The default is to use elementwise = TRUE if possible, and otherwise elementwise = FALSE.\n\n\n\n\nsigma\n\n\ncharacter or numeric or NULL. Specification of the standard deviation sigma to be used for the Normal distribution in the lm method. The default “ML” (or equivalently “MLE” or NULL) uses the maximum likelihood estimate based on the residual sum of squares divided by the number of observations, n. Alternatively, sigma = “OLS” uses the least-squares estimate (divided by the residual degrees of freedom, n - k). Finally, a concrete numeric value can also be specified in sigma.\n\n\n\n\ndispersion\n\n\ncharacter or numeric or NULL. Specification of the dispersion parameter in the glm method. The default NULL (or equivalently “deviance”) is to use the deviance divided by the number of observations, n. Alternatively, dispersion = “Chisquared” uses the Chi-squared statistic divided by the residual degrees of freedom, n - k. Finally, a concrete numeric value can also be specified in dispersion.\n\n\n\n\ndistributions3\n\n\nlogical. If a dedicated distributions3 object is available (e.g., such as Normal) and uses the same parameterization, should this be used instead of the general disttree distribution?\n\n\n\nThe function procast provides a unified framework for probabilistic forcasting (or procasting, for short) based on probabilistic (regression) models, also known as distributional regression approaches. Typical types of predictions include quantiles, probabilities, (conditional) expectations, variances, and (log-)densities. Internally, procast methods typically compute the predicted parameters for each observation and then compute the desired outcome for the distributions with the respective parameters.\nSome quantities, e.g., the moments of the distribution (like mean or variance), can be computed directly from the predicted parameters of the distribution while others require an additional argument at which the distribution is evaluated (e.g., the probability of a quantile or an observation of the response).\nThe default procast method leverages the S3 classes and methods for probability distributions from the distributions3 package. In a first step the predicted probability distribution object is obtained and, by default (type = “distribution”), returned in order to reflect the distributional nature of the forecast. For all other types (e.g., “mean”, “quantile”, or “density”), the corresponding extractor methods (e.g., mean, quantile, or pdf) are used to compute the desired quantity from the distribution objects. The examples provide some worked illustrations.\nPackage authors or users, who want to enable procast for new types of model objects, only need to provide a suitable prodist extractor for the predicted probability distribution. Then the default procast works out of the box. However, if the distributions3 package does not support the necessary probability distribution, then it may also be necessary to implement a new distribution objects, see apply_dpqr.\n\nEither a data.frame of predictions with the same number of rows as the newdata (or the original observations if that is NULL). If drop = TRUE predictions with just a single column are simplified to a vector and predictions with multiple columns to a matrix.\n\n\nlibrary(\"topmodels\")\n\n## load packages\nlibrary(\"topmodels\")\nlibrary(\"distributions3\")\n\n## Poisson regression model for FIFA 2018 data:\n## number of goals scored by each team in each game, explained by\n## predicted ability difference of the competing teams\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## predicted probability distributions for all matches (in sample)\nhead(procast(m))\n\n                 distribution\n1 Poisson(lambda = 1.7680273)\n2 Poisson(lambda = 0.8655224)\n3 Poisson(lambda = 1.0296663)\n4 Poisson(lambda = 1.4861779)\n5 Poisson(lambda = 1.4353952)\n6 Poisson(lambda = 1.0660948)\n\nhead(procast(m, drop = TRUE))\n\n                         1                          2 \n\"Poisson(lambda = 1.7680)\" \"Poisson(lambda = 0.8655)\" \n                         3                          4 \n\"Poisson(lambda = 1.0297)\" \"Poisson(lambda = 1.4862)\" \n                         5                          6 \n\"Poisson(lambda = 1.4354)\" \"Poisson(lambda = 1.0661)\" \n\n## procasts for new data\n## much lower, equal, and much higher ability than opponent\nnd &lt;- data.frame(difference = c(-1, 0, 1))\n\n## predicted goal distribution object\ngoals &lt;- procast(m, newdata = nd, drop = TRUE)\ngoals\n\n                         1                          2 \n\"Poisson(lambda = 0.8181)\" \"Poisson(lambda = 1.2370)\" \n                         3 \n\"Poisson(lambda = 1.8704)\" \n\n## predicted densities/probabilities for scoring 0, 1, ..., 5 goals\nprocast(m, newdata = nd, type = \"density\", at = 0:5)\n\n        d_0       d_1       d_2        d_3         d_4         d_5\n1 0.4412492 0.3610060 0.1476777 0.04027394 0.008237485 0.001347892\n2 0.2902421 0.3590411 0.2220740 0.09157147 0.028319386 0.007006441\n3 0.1540605 0.2881563 0.2694852 0.16801593 0.078564672 0.029389630\n\n## by hand\npdf(goals, 0:5)\n\n        d_0       d_1       d_2        d_3         d_4         d_5\n1 0.4412492 0.3610060 0.1476777 0.04027394 0.008237485 0.001347892\n2 0.2902421 0.3590411 0.2220740 0.09157147 0.028319386 0.007006441\n3 0.1540605 0.2881563 0.2694852 0.16801593 0.078564672 0.029389630\n\n## means and medians\nprocast(m, newdata = nd, type = \"mean\")\n\n       mean\n1 0.8181454\n2 1.2370397\n3 1.8704100\n\nprocast(m, newdata = nd, type = \"quantile\", at = 0.5)\n\n  quantile\n1        1\n2        1\n3        2\n\n## by hand\nmean(goals)\n\n        1         2         3 \n0.8181454 1.2370397 1.8704100 \n\nquantile(goals, 0.5)\n\n1 2 3 \n1 1 2 \n\n## evaluate procast elementwise or for all possible combinations\n## of distributions from 'nd' and observations in 'at'\nprocast(m, newdata = nd, type = \"probability\", at = 1:3, elementwise = TRUE)\n\n  probability\n1   0.8022553\n2   0.8713572\n3   0.8797179\n\nprocast(m, newdata = nd, type = \"probability\", at = 1:3, elementwise = FALSE)\n\n        p_1       p_2       p_3\n1 0.8022553 0.9499330 0.9902069\n2 0.6492832 0.8713572 0.9629287\n3 0.4422167 0.7117019 0.8797179\n\n## compute in-sample log-likelihood sum via procast\nsum(procast(m, type = \"density\", at = FIFA2018$goals, log = TRUE))\n\n[1] -177.6971\n\nlogLik(m)\n\n'log Lik.' -177.6971 (df=2)",
    "crumbs": [
      "Procast infrastructure",
      "procast"
    ]
  },
  {
    "objectID": "man/wormplot.html",
    "href": "man/wormplot.html",
    "title": "topmodels",
    "section": "",
    "text": "Visualize goodness of fit of regression models by worm plots using quantile residuals. If plot = TRUE, the resulting object of class “wormplot” is plotted by plot.qqrplot or autoplot.qqrplot before it is returned, depending on whether the package ggplot2 is loaded.\n\nwormplot(object, ...)\n\n## Default S3 method:\nwormplot(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  detrend = TRUE,\n  scale = c(\"normal\", \"uniform\"),\n  nsim = 1L,\n  delta = NULL,\n  confint = TRUE,\n  simint = TRUE,\n  simint_level = 0.95,\n  simint_nrep = 250,\n  single_graph = FALSE,\n  xlab = \"Theoretical quantiles\",\n  ylab = \"Deviation\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which probability integral transforms can be extracted using the generic function procast.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nShould the plot or autoplot method be called to draw the computed Q-Q plot? Either set plot expicitly to “base” vs. “ggplot2” to choose the type of plot, or for a logical plot argument it’s chosen conditional if the package ggplot2 is loaded.\n\n\n\n\nclass\n\n\nShould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\ndetrend\n\n\nlogical. Should the qqrplot be detrended, i.e, plotted as a ‘wormplot()’?\n\n\n\n\nscale\n\n\nOn which scale should the quantile residuals be shown: on the probability scale (“uniform”) or on the normal scale (“normal”).\n\n\n\n\nnsim, delta\n\n\narguments passed to proresiduals.\n\n\n\n\nconfint\n\n\nlogical or character string describing the type for plotting ‘c(\"polygon\", \"line\")’. If not set to ‘FALSE’, the pointwise confidence interval of the (randomized) quantile residuals are visualized.\n\n\n\n\nsimint\n\n\nlogical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized?\n\n\n\n\nsimint_level\n\n\nnumeric. The confidence level required for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsimint_nrep\n\n\nnumeric. The repetition number of simulated quantiles for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph?\n\n\n\n\nxlab, ylab, main, …\n\n\ngraphical parameters passed to plot.qqrplot or autoplot.qqrplot.\n\n\n\nWorm plots (de-trended Q-Q plots) draw deviations of quantile residuals (by default: transformed to standard normal scale) and theoretical quantiles from the same distribution against the same theoretical quantiles. For computation, wormplot leverages the function proresiduals employing the procast.\nAdditional options are offered for models with discrete responses where randomization of quantiles is needed.\nIn addition to the plot and autoplot method for wormplot objects, it is also possible to combine two (or more) worm plots by c/rbind, which creates a set of worm plots that can then be plotted in one go.\n\nAn object of class “qqrplot” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nx\n\n\ntheoretical quantiles,\n\n\n\n\ny\n\n\ndeviations between theoretical and empirical quantiles.\n\n\n\nIn case of randomized residuals, nsim different x and y values, and lower and upper confidence interval bounds (x_rg_lwr, y_rg_lwr, x_rg_upr, y_rg_upr) can optionally be returned. Additionally, xlab, ylab, main, and simint_level, as well as the the (scale) and wether a detrended Q-Q residuals plot was computed are stored as attributes.\n\nvan Buuren S and Fredriks M (2001). “Worm plot: simple diagnostic device for modelling growth reference curves”. Statistics in Medicine, 20, 1259–1277. doi:10.1002/sim.746\n\nqqrplot, plot.qqrplot, qqrplot, proresiduals, qqnorm\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot wormplot\nwormplot(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot wormplot as base graphic\nw1 &lt;- wormplot(m1_pois, plot = FALSE)\nw2 &lt;- wormplot(m2_pois, plot = FALSE)\n\n## plot combined wormplot as \"ggplot2\" graphic\nggplot2::autoplot(c(w1, w2), single_graph = TRUE, col = c(1, 2), fill = c(1, 2))",
    "crumbs": [
      "Probabilistic model diagnostics",
      "wormplot"
    ]
  },
  {
    "objectID": "man/wormplot.html#worm-plots-for-quantile-residuals",
    "href": "man/wormplot.html#worm-plots-for-quantile-residuals",
    "title": "topmodels",
    "section": "",
    "text": "Visualize goodness of fit of regression models by worm plots using quantile residuals. If plot = TRUE, the resulting object of class “wormplot” is plotted by plot.qqrplot or autoplot.qqrplot before it is returned, depending on whether the package ggplot2 is loaded.\n\nwormplot(object, ...)\n\n## Default S3 method:\nwormplot(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  detrend = TRUE,\n  scale = c(\"normal\", \"uniform\"),\n  nsim = 1L,\n  delta = NULL,\n  confint = TRUE,\n  simint = TRUE,\n  simint_level = 0.95,\n  simint_nrep = 250,\n  single_graph = FALSE,\n  xlab = \"Theoretical quantiles\",\n  ylab = \"Deviation\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which probability integral transforms can be extracted using the generic function procast.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nShould the plot or autoplot method be called to draw the computed Q-Q plot? Either set plot expicitly to “base” vs. “ggplot2” to choose the type of plot, or for a logical plot argument it’s chosen conditional if the package ggplot2 is loaded.\n\n\n\n\nclass\n\n\nShould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\ndetrend\n\n\nlogical. Should the qqrplot be detrended, i.e, plotted as a ‘wormplot()’?\n\n\n\n\nscale\n\n\nOn which scale should the quantile residuals be shown: on the probability scale (“uniform”) or on the normal scale (“normal”).\n\n\n\n\nnsim, delta\n\n\narguments passed to proresiduals.\n\n\n\n\nconfint\n\n\nlogical or character string describing the type for plotting ‘c(\"polygon\", \"line\")’. If not set to ‘FALSE’, the pointwise confidence interval of the (randomized) quantile residuals are visualized.\n\n\n\n\nsimint\n\n\nlogical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized?\n\n\n\n\nsimint_level\n\n\nnumeric. The confidence level required for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsimint_nrep\n\n\nnumeric. The repetition number of simulated quantiles for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph?\n\n\n\n\nxlab, ylab, main, …\n\n\ngraphical parameters passed to plot.qqrplot or autoplot.qqrplot.\n\n\n\nWorm plots (de-trended Q-Q plots) draw deviations of quantile residuals (by default: transformed to standard normal scale) and theoretical quantiles from the same distribution against the same theoretical quantiles. For computation, wormplot leverages the function proresiduals employing the procast.\nAdditional options are offered for models with discrete responses where randomization of quantiles is needed.\nIn addition to the plot and autoplot method for wormplot objects, it is also possible to combine two (or more) worm plots by c/rbind, which creates a set of worm plots that can then be plotted in one go.\n\nAn object of class “qqrplot” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nx\n\n\ntheoretical quantiles,\n\n\n\n\ny\n\n\ndeviations between theoretical and empirical quantiles.\n\n\n\nIn case of randomized residuals, nsim different x and y values, and lower and upper confidence interval bounds (x_rg_lwr, y_rg_lwr, x_rg_upr, y_rg_upr) can optionally be returned. Additionally, xlab, ylab, main, and simint_level, as well as the the (scale) and wether a detrended Q-Q residuals plot was computed are stored as attributes.\n\nvan Buuren S and Fredriks M (2001). “Worm plot: simple diagnostic device for modelling growth reference curves”. Statistics in Medicine, 20, 1259–1277. doi:10.1002/sim.746\n\nqqrplot, plot.qqrplot, qqrplot, proresiduals, qqnorm\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot wormplot\nwormplot(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot wormplot as base graphic\nw1 &lt;- wormplot(m1_pois, plot = FALSE)\nw2 &lt;- wormplot(m2_pois, plot = FALSE)\n\n## plot combined wormplot as \"ggplot2\" graphic\nggplot2::autoplot(c(w1, w2), single_graph = TRUE, col = c(1, 2), fill = c(1, 2))",
    "crumbs": [
      "Probabilistic model diagnostics",
      "wormplot"
    ]
  },
  {
    "objectID": "man/rootogram.html",
    "href": "man/rootogram.html",
    "title": "topmodels",
    "section": "",
    "text": "Rootograms graphically compare (square roots) of empirical frequencies with expected (fitted) frequencies from a probabilistic model. If plot = TRUE, the resulting object of class “rootogram” is plotted by plot.rootogram or autoplot.rootogram before it is returned, depending on whether the package ggplot2 is loaded.\n\nrootogram(object, ...)\n\n## Default S3 method:\nrootogram(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  breaks = NULL,\n  width = NULL,\n  style = c(\"hanging\", \"standing\", \"suspended\"),\n  scale = c(\"sqrt\", \"raw\"),\n  expected = TRUE,\n  confint = TRUE,\n  ref = TRUE,\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which an rootogram can be extracted with procast.\n\n\n\n\n…\n\n\nfurther graphical parameters passed to the plotting function.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nlogical or character. Should the plot or autoplot method be called to draw the computed extended reliability diagram? Logical FALSE will suppress plotting, TRUE (default) will choose the type of plot conditional if the package ggplot2 is loaded. Alternatively “base” or “ggplot2” can be specified to explicitly choose the type of plot.\n\n\n\n\nclass\n\n\nshould the invisible return value be either a data.frame or a tbl_df. Can be set to “data.frame” or “tibble” to explicitly specify the return class, or to NULL (default) in which case the return class is conditional on whether the package “tibble” is loaded.\n\n\n\n\nbreaks\n\n\nNULL (default) or numeric vector to specifying the breaks for the rootogram intervals. A single numeric (larger than 0) specifies the number of breaks to be chosen via pretty (except for discrete distributions).\n\n\n\n\nwidth\n\n\nNULL (default) or single positive numeric. Width of the histogram bars. Will be ignored for non-discrete distributions.\n\n\n\n\nstyle\n\n\ncharacter specifying the syle of rootogram (see ‘Details’).\n\n\n\n\nscale\n\n\ncharacter specifying whether “raw” frequencies or their square roots (“sqrt”; default) should be drawn.\n\n\n\n\nexpected\n\n\nlogical or character. Should the expected (fitted) frequencies be plotted? Can be set to “both” (same as TRUE; default), “line”, “point”, or FALSE which will suppress plotting.\n\n\n\n\nconfint\n\n\nlogical, defaults to TRUE. Should confident intervals be drawn?\n\n\n\n\nref\n\n\nlogical, defaults to TRUE. Should a reference line be plotted?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters forwarded to plot.rootogram or autoplot.rootogram.\n\n\n\nRootograms graphically compare frequencies of empirical distributions and expected (fitted) probability models. For the observed distribution the histogram is drawn on a square root scale (hence the name) and superimposed with a line for the expected frequencies. The histogram can be “hanging” from the expected curve (default), “standing” on the (like bars in barplot), or drawn as a “suspended” histogram of deviations.\nRootograms are associated with the work of John W. Tukey (see Tukey 1977) and were originally proposed for assessing the goodness of fit of univariate distributions. See Friendly (2000) for a software implementation, in particular geared towards count data models. Kleiber and Zeileis (2016) extend it to regression models for count data, essentially by replacing the expected frequencies of a univariate distribution by the sum of the expected frequencies from the different conditional distributions for all observations.\nThe function rootogram leverages the procast generic in order to compute all necessary coordinates based on observed and expected (fitted) frequencies. It is thus not only applicable to count data regressions but to all (regression) models that are supported by procast.\nIn addition to the plot and autoplot method for rootogram objects, it is also possible to combine two (or more) rootograms by c/rbind, which creates a set of rootograms that can then be plotted in one go.\n\nAn object of class “rootogram” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nobserved\n\n\nobserved frequencies,\n\n\n\n\nexpected\n\n\nexpected (fitted) frequencies,\n\n\n\n\nmid\n\n\nhistogram interval midpoints on the x-axis,\n\n\n\n\nwidth\n\n\nwidths of the histogram bars,\n\n\n\n\nconfint_lwr, confint_upr\n\n\nlower and upper confidence interval bound.\n\n\n\nAdditionally, style, scale, expected, confint, ref, xlab, ylab, amd main are stored as attributes.\n\nNote that there is also a rootogram function in the vcd package that is similar to the numeric method provided here. However, it is much more limited in scope, hence a function has been created here.\n\nFriendly M (2000), Visualizing Categorical Data. SAS Institute, Cary.\nKleiber C, Zeileis A (2016). “Visualizing Count Data Regressions Using Rootograms.” The American Statistician, 70(3), 296–303. doi:10.1080/00031305.2016.1173590\nTukey JW (1977). Exploratory Data Analysis. Addison-Wesley, Reading.\n\nplot.rootogram, procast\n\n\nlibrary(\"topmodels\")\n\n## plots and output\n\n## number of deaths by horsekicks in Prussian army (Von Bortkiewicz 1898)\ndeaths &lt;- rep(0:4, c(109, 65, 22, 3, 1))\n\n## fit glm model\nm1_pois &lt;- glm(deaths ~ 1, family = poisson)\nrootogram(m1_pois)\n\n\n\n\n\n\n## inspect output (without plotting)\nr1 &lt;- rootogram(m1_pois, plot = FALSE)\nr1\n\nA `rootogram` object with `scale = \"sqrt\"` and `style = \"hanging\"`\n(column `distribution` not shown)\n\n   observed   expected mid width\n1 10.440307 10.4244987   0   0.9\n2  8.062258  8.1417938   1   0.9\n3  4.690416  4.4964526   2   0.9\n4  1.732051  2.0275628   3   0.9\n5  1.000000  0.7917886   4   0.9\n\n## combine plots\nplot(c(r1, r1), col = c(1, 2), expected_col = c(1, 2))\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## different styles\n\n## artificial data from negative binomial (mu = 3, theta = 2)\n## and Poisson (mu = 3) distribution\nset.seed(1090)\ny &lt;- rnbinom(100, mu = 3, size = 2)\nx &lt;- rpois(100, lambda = 3)\n\n## glm method: fitted values via glm()\nm2_pois &lt;- glm(y ~ x, family = poisson)\n\n## correctly specified Poisson model fit\npar(mfrow = c(1, 3))\nr1 &lt;- rootogram(m2_pois, style = \"standing\", ylim = c(-2.2, 4.8), main = \"Standing\")\nr2 &lt;- rootogram(m2_pois, style = \"hanging\", ylim = c(-2.2, 4.8), main = \"Hanging\")\nr3 &lt;- rootogram(m2_pois, style = \"suspended\", ylim = c(-2.2, 4.8), main = \"Suspended\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n#-------------------------------------------------------------------------------\n## linear regression with normal/Gaussian response: anorexia data\n\ndata(\"anorexia\", package = \"MASS\")\n\nm3_gauss &lt;- glm(Postwt ~ Prewt + Treat + offset(Prewt), family = gaussian, data = anorexia)\n\n## plot rootogram as \"ggplot2\" graphic\nrootogram(m3_gauss, plot = \"ggplot2\")",
    "crumbs": [
      "Probabilistic model diagnostics",
      "rootogram"
    ]
  },
  {
    "objectID": "man/rootogram.html#rootograms-for-assessing-goodness-of-fit-of-probability-models",
    "href": "man/rootogram.html#rootograms-for-assessing-goodness-of-fit-of-probability-models",
    "title": "topmodels",
    "section": "",
    "text": "Rootograms graphically compare (square roots) of empirical frequencies with expected (fitted) frequencies from a probabilistic model. If plot = TRUE, the resulting object of class “rootogram” is plotted by plot.rootogram or autoplot.rootogram before it is returned, depending on whether the package ggplot2 is loaded.\n\nrootogram(object, ...)\n\n## Default S3 method:\nrootogram(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  breaks = NULL,\n  width = NULL,\n  style = c(\"hanging\", \"standing\", \"suspended\"),\n  scale = c(\"sqrt\", \"raw\"),\n  expected = TRUE,\n  confint = TRUE,\n  ref = TRUE,\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which an rootogram can be extracted with procast.\n\n\n\n\n…\n\n\nfurther graphical parameters passed to the plotting function.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nlogical or character. Should the plot or autoplot method be called to draw the computed extended reliability diagram? Logical FALSE will suppress plotting, TRUE (default) will choose the type of plot conditional if the package ggplot2 is loaded. Alternatively “base” or “ggplot2” can be specified to explicitly choose the type of plot.\n\n\n\n\nclass\n\n\nshould the invisible return value be either a data.frame or a tbl_df. Can be set to “data.frame” or “tibble” to explicitly specify the return class, or to NULL (default) in which case the return class is conditional on whether the package “tibble” is loaded.\n\n\n\n\nbreaks\n\n\nNULL (default) or numeric vector to specifying the breaks for the rootogram intervals. A single numeric (larger than 0) specifies the number of breaks to be chosen via pretty (except for discrete distributions).\n\n\n\n\nwidth\n\n\nNULL (default) or single positive numeric. Width of the histogram bars. Will be ignored for non-discrete distributions.\n\n\n\n\nstyle\n\n\ncharacter specifying the syle of rootogram (see ‘Details’).\n\n\n\n\nscale\n\n\ncharacter specifying whether “raw” frequencies or their square roots (“sqrt”; default) should be drawn.\n\n\n\n\nexpected\n\n\nlogical or character. Should the expected (fitted) frequencies be plotted? Can be set to “both” (same as TRUE; default), “line”, “point”, or FALSE which will suppress plotting.\n\n\n\n\nconfint\n\n\nlogical, defaults to TRUE. Should confident intervals be drawn?\n\n\n\n\nref\n\n\nlogical, defaults to TRUE. Should a reference line be plotted?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters forwarded to plot.rootogram or autoplot.rootogram.\n\n\n\nRootograms graphically compare frequencies of empirical distributions and expected (fitted) probability models. For the observed distribution the histogram is drawn on a square root scale (hence the name) and superimposed with a line for the expected frequencies. The histogram can be “hanging” from the expected curve (default), “standing” on the (like bars in barplot), or drawn as a “suspended” histogram of deviations.\nRootograms are associated with the work of John W. Tukey (see Tukey 1977) and were originally proposed for assessing the goodness of fit of univariate distributions. See Friendly (2000) for a software implementation, in particular geared towards count data models. Kleiber and Zeileis (2016) extend it to regression models for count data, essentially by replacing the expected frequencies of a univariate distribution by the sum of the expected frequencies from the different conditional distributions for all observations.\nThe function rootogram leverages the procast generic in order to compute all necessary coordinates based on observed and expected (fitted) frequencies. It is thus not only applicable to count data regressions but to all (regression) models that are supported by procast.\nIn addition to the plot and autoplot method for rootogram objects, it is also possible to combine two (or more) rootograms by c/rbind, which creates a set of rootograms that can then be plotted in one go.\n\nAn object of class “rootogram” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nobserved\n\n\nobserved frequencies,\n\n\n\n\nexpected\n\n\nexpected (fitted) frequencies,\n\n\n\n\nmid\n\n\nhistogram interval midpoints on the x-axis,\n\n\n\n\nwidth\n\n\nwidths of the histogram bars,\n\n\n\n\nconfint_lwr, confint_upr\n\n\nlower and upper confidence interval bound.\n\n\n\nAdditionally, style, scale, expected, confint, ref, xlab, ylab, amd main are stored as attributes.\n\nNote that there is also a rootogram function in the vcd package that is similar to the numeric method provided here. However, it is much more limited in scope, hence a function has been created here.\n\nFriendly M (2000), Visualizing Categorical Data. SAS Institute, Cary.\nKleiber C, Zeileis A (2016). “Visualizing Count Data Regressions Using Rootograms.” The American Statistician, 70(3), 296–303. doi:10.1080/00031305.2016.1173590\nTukey JW (1977). Exploratory Data Analysis. Addison-Wesley, Reading.\n\nplot.rootogram, procast\n\n\nlibrary(\"topmodels\")\n\n## plots and output\n\n## number of deaths by horsekicks in Prussian army (Von Bortkiewicz 1898)\ndeaths &lt;- rep(0:4, c(109, 65, 22, 3, 1))\n\n## fit glm model\nm1_pois &lt;- glm(deaths ~ 1, family = poisson)\nrootogram(m1_pois)\n\n\n\n\n\n\n## inspect output (without plotting)\nr1 &lt;- rootogram(m1_pois, plot = FALSE)\nr1\n\nA `rootogram` object with `scale = \"sqrt\"` and `style = \"hanging\"`\n(column `distribution` not shown)\n\n   observed   expected mid width\n1 10.440307 10.4244987   0   0.9\n2  8.062258  8.1417938   1   0.9\n3  4.690416  4.4964526   2   0.9\n4  1.732051  2.0275628   3   0.9\n5  1.000000  0.7917886   4   0.9\n\n## combine plots\nplot(c(r1, r1), col = c(1, 2), expected_col = c(1, 2))\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## different styles\n\n## artificial data from negative binomial (mu = 3, theta = 2)\n## and Poisson (mu = 3) distribution\nset.seed(1090)\ny &lt;- rnbinom(100, mu = 3, size = 2)\nx &lt;- rpois(100, lambda = 3)\n\n## glm method: fitted values via glm()\nm2_pois &lt;- glm(y ~ x, family = poisson)\n\n## correctly specified Poisson model fit\npar(mfrow = c(1, 3))\nr1 &lt;- rootogram(m2_pois, style = \"standing\", ylim = c(-2.2, 4.8), main = \"Standing\")\nr2 &lt;- rootogram(m2_pois, style = \"hanging\", ylim = c(-2.2, 4.8), main = \"Hanging\")\nr3 &lt;- rootogram(m2_pois, style = \"suspended\", ylim = c(-2.2, 4.8), main = \"Suspended\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n#-------------------------------------------------------------------------------\n## linear regression with normal/Gaussian response: anorexia data\n\ndata(\"anorexia\", package = \"MASS\")\n\nm3_gauss &lt;- glm(Postwt ~ Prewt + Treat + offset(Prewt), family = gaussian, data = anorexia)\n\n## plot rootogram as \"ggplot2\" graphic\nrootogram(m3_gauss, plot = \"ggplot2\")",
    "crumbs": [
      "Probabilistic model diagnostics",
      "rootogram"
    ]
  },
  {
    "objectID": "man/reliagram.html",
    "href": "man/reliagram.html",
    "title": "topmodels",
    "section": "",
    "text": "Reliagram (extended reliability diagram) assess the reliability of a fitted probabilistic distributional forecast for a binary event. If plot = TRUE, the resulting object of class “reliagram” is plotted by plot.reliagram or autoplot.reliagram before it is returned, depending on whether the package ggplot2 is loaded.\n\nreliagram(object, ...)\n\n## Default S3 method:\nreliagram(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  breaks = seq(0, 1, by = 0.1),\n  quantiles = 0.5,\n  thresholds = NULL,\n  confint = TRUE,\n  confint_level = 0.95,\n  confint_nboot = 250,\n  confint_seed = 1,\n  single_graph = FALSE,\n  xlab = \"Forecast probability\",\n  ylab = \"Observed relative frequency\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which an extended reliability diagram can be extracted with procast.\n\n\n\n\n…\n\n\nfurther graphical parameters.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nShould the plot or autoplot method be called to draw the computed extended reliability diagram? Either set plot expicitly to “base” vs. “ggplot2” to choose the type of plot, or for a logical plot argument it’s chosen conditional if the package ggplot2 is loaded.\n\n\n\n\nclass\n\n\nShould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\nbreaks\n\n\nnumeric vector passed on to cut in order to bin the observations and the predicted probabilities or a function applied to the predicted probabilities to calculate a numeric value for cut. Typically quantiles to ensure equal number of predictions per bin, e.g., by breaks = function(x) quantile(x).\n\n\n\n\nquantiles\n\n\nnumeric vector of quantile probabilities with values in [0,1] to calculate single or several thresholds. Only used if thresholds is not specified. For binary responses typically the 50%-quantile is used.\n\n\n\n\nthresholds\n\n\nnumeric vector specifying both where to cut the observations into binary values and at which values the predicted probabilities should be calculated (procast).\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be calculated and drawn?\n\n\n\n\nconfint_level\n\n\nnumeric. The confidence level required.\n\n\n\n\nconfint_nboot\n\n\nnumeric. The number of bootstrap steps.\n\n\n\n\nconfint_seed\n\n\nnumeric. The seed to be set for the bootstrapping.\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters.\n\n\n\nReliagrams evaluate if a probability model is calibrated (reliable) by first partitioning the predicted probability for a binary event into a certain number of bins and then plotting (within each bin) the averaged forecast probability against the observered/empirical relative frequency. For computation, reliagram leverages the procast generic to forecast the respective predictive probabilities.\nFor continous probability forecasts, reliability diagrams can be computed either for a pre-specified threshold or for a specific quantile probability of the response values. Per default, reliagrams are computed for the 50%-quantile of the reponse.\nIn addition to the plot and autoplot method for reliagram objects, it is also possible to combine two (or more) reliability diagrams by c/rbind, which creates a set of reliability diagrams that can then be plotted in one go.\n\nAn object of class “reliagram” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nx\n\n\nforecast probabilities,\n\n\n\n\ny\n\n\nobservered/empirical relative frequencies,\n\n\n\n\nbin_lwr, bin_upr\n\n\nlower and upper bound of the binned forecast probabilities,\n\n\n\n\nn_pred\n\n\nnumber of predictions within the binned forecasts probabilites,\n\n\n\n\nci_lwr, ci_upr\n\n\nlower and upper confidence interval bound.\n\n\n\nAdditionally, xlab, ylab, main, and treshold, confint_level, as well as the total and the decomposed Brier Score (bs, rel, res, unc) are stored as attributes.\n\nNote that there is also a reliability.plot function in the verification package. However, it only works for numeric forecast probabilities and numeric observed relative frequencies, hence a function has been created here.\n\nWilks DS (2011) Statistical Methods in the Atmospheric Sciences, 3rd ed., Academic Press, 704 pp.\n\nlink{plot.reliagram}, procast\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot reliagram\nreliagram(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot reliagram as base graphic\nr1 &lt;- reliagram(m1_pois, plot = FALSE)\nr2 &lt;- reliagram(m2_pois, plot = FALSE)\n\n## plot combined reliagram as \"ggplot2\" graphic\nggplot2::autoplot(c(r1, r2), single_graph = TRUE, col = c(1, 2), fill = c(1, 2))",
    "crumbs": [
      "Probabilistic model diagnostics",
      "reliagram"
    ]
  },
  {
    "objectID": "man/reliagram.html#reliagram-extended-reliability-diagram",
    "href": "man/reliagram.html#reliagram-extended-reliability-diagram",
    "title": "topmodels",
    "section": "",
    "text": "Reliagram (extended reliability diagram) assess the reliability of a fitted probabilistic distributional forecast for a binary event. If plot = TRUE, the resulting object of class “reliagram” is plotted by plot.reliagram or autoplot.reliagram before it is returned, depending on whether the package ggplot2 is loaded.\n\nreliagram(object, ...)\n\n## Default S3 method:\nreliagram(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  breaks = seq(0, 1, by = 0.1),\n  quantiles = 0.5,\n  thresholds = NULL,\n  confint = TRUE,\n  confint_level = 0.95,\n  confint_nboot = 250,\n  confint_seed = 1,\n  single_graph = FALSE,\n  xlab = \"Forecast probability\",\n  ylab = \"Observed relative frequency\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which an extended reliability diagram can be extracted with procast.\n\n\n\n\n…\n\n\nfurther graphical parameters.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nShould the plot or autoplot method be called to draw the computed extended reliability diagram? Either set plot expicitly to “base” vs. “ggplot2” to choose the type of plot, or for a logical plot argument it’s chosen conditional if the package ggplot2 is loaded.\n\n\n\n\nclass\n\n\nShould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\nbreaks\n\n\nnumeric vector passed on to cut in order to bin the observations and the predicted probabilities or a function applied to the predicted probabilities to calculate a numeric value for cut. Typically quantiles to ensure equal number of predictions per bin, e.g., by breaks = function(x) quantile(x).\n\n\n\n\nquantiles\n\n\nnumeric vector of quantile probabilities with values in [0,1] to calculate single or several thresholds. Only used if thresholds is not specified. For binary responses typically the 50%-quantile is used.\n\n\n\n\nthresholds\n\n\nnumeric vector specifying both where to cut the observations into binary values and at which values the predicted probabilities should be calculated (procast).\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be calculated and drawn?\n\n\n\n\nconfint_level\n\n\nnumeric. The confidence level required.\n\n\n\n\nconfint_nboot\n\n\nnumeric. The number of bootstrap steps.\n\n\n\n\nconfint_seed\n\n\nnumeric. The seed to be set for the bootstrapping.\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters.\n\n\n\nReliagrams evaluate if a probability model is calibrated (reliable) by first partitioning the predicted probability for a binary event into a certain number of bins and then plotting (within each bin) the averaged forecast probability against the observered/empirical relative frequency. For computation, reliagram leverages the procast generic to forecast the respective predictive probabilities.\nFor continous probability forecasts, reliability diagrams can be computed either for a pre-specified threshold or for a specific quantile probability of the response values. Per default, reliagrams are computed for the 50%-quantile of the reponse.\nIn addition to the plot and autoplot method for reliagram objects, it is also possible to combine two (or more) reliability diagrams by c/rbind, which creates a set of reliability diagrams that can then be plotted in one go.\n\nAn object of class “reliagram” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nx\n\n\nforecast probabilities,\n\n\n\n\ny\n\n\nobservered/empirical relative frequencies,\n\n\n\n\nbin_lwr, bin_upr\n\n\nlower and upper bound of the binned forecast probabilities,\n\n\n\n\nn_pred\n\n\nnumber of predictions within the binned forecasts probabilites,\n\n\n\n\nci_lwr, ci_upr\n\n\nlower and upper confidence interval bound.\n\n\n\nAdditionally, xlab, ylab, main, and treshold, confint_level, as well as the total and the decomposed Brier Score (bs, rel, res, unc) are stored as attributes.\n\nNote that there is also a reliability.plot function in the verification package. However, it only works for numeric forecast probabilities and numeric observed relative frequencies, hence a function has been created here.\n\nWilks DS (2011) Statistical Methods in the Atmospheric Sciences, 3rd ed., Academic Press, 704 pp.\n\nlink{plot.reliagram}, procast\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot reliagram\nreliagram(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot reliagram as base graphic\nr1 &lt;- reliagram(m1_pois, plot = FALSE)\nr2 &lt;- reliagram(m2_pois, plot = FALSE)\n\n## plot combined reliagram as \"ggplot2\" graphic\nggplot2::autoplot(c(r1, r2), single_graph = TRUE, col = c(1, 2), fill = c(1, 2))",
    "crumbs": [
      "Probabilistic model diagnostics",
      "reliagram"
    ]
  },
  {
    "objectID": "man/SerumPotassium.html",
    "href": "man/SerumPotassium.html",
    "title": "topmodels",
    "section": "",
    "text": "Sample of 152 serum potassium levels.\n\ndata(\"SerumPotassium\", package = \"topmodels\")\n\n\nA numeric vector of 152 serum potassium levels.\n\nThe data are taken from Rice (2007) who obtained the data from Martin, Gudzinowicz and Fanger (1975) and reports them rounded to one digit.\n\nPage 350 in Rice (2007).\n\nRice JA (2007). Mathematical Statistics and Data Analysis, 3rd ed. Duxbury, Belmont, CA.\nMartin HF, Gudzinowicz BJ, Fanger H (1975). Normal Values in Clinical Chemistry: A Guide to Statistical Analysis of Laboratory Data. Marcel Dekker, New York.\n\n\nlibrary(\"topmodels\")\n\nlibrary(\"topmodels\")\ndata(\"SerumPotassium\", package = \"topmodels\")\n\n## Figure 9.3a-c from Rice (2007), and actual hanging rootogram\n## (note that Rice erroneously refers to suspended rootograms as hanging)\nsp &lt;- lm(SerumPotassium ~ 1)\nbr &lt;- 32:54/10 - 0.05\nrootogram(sp, scale = \"raw\", style = \"standing\",\n  breaks = br, col = \"transparent\")\n\n\n\n\n\n\nrootogram(sp, scale = \"raw\", style = \"suspended\",\n  breaks = br, col = \"transparent\", ylim = c(2.8, -4))\n\n\n\n\n\n\nrootogram(sp, scale = \"sqrt\", style = \"suspended\",\n  breaks = br, col = \"transparent\", ylim = c(1, -1.5))\n\n\n\n\n\n\nrootogram(sp, breaks = br)",
    "crumbs": [
      "Data sets",
      "SerumPotassium"
    ]
  },
  {
    "objectID": "man/SerumPotassium.html#serum-potassium-levels",
    "href": "man/SerumPotassium.html#serum-potassium-levels",
    "title": "topmodels",
    "section": "",
    "text": "Sample of 152 serum potassium levels.\n\ndata(\"SerumPotassium\", package = \"topmodels\")\n\n\nA numeric vector of 152 serum potassium levels.\n\nThe data are taken from Rice (2007) who obtained the data from Martin, Gudzinowicz and Fanger (1975) and reports them rounded to one digit.\n\nPage 350 in Rice (2007).\n\nRice JA (2007). Mathematical Statistics and Data Analysis, 3rd ed. Duxbury, Belmont, CA.\nMartin HF, Gudzinowicz BJ, Fanger H (1975). Normal Values in Clinical Chemistry: A Guide to Statistical Analysis of Laboratory Data. Marcel Dekker, New York.\n\n\nlibrary(\"topmodels\")\n\nlibrary(\"topmodels\")\ndata(\"SerumPotassium\", package = \"topmodels\")\n\n## Figure 9.3a-c from Rice (2007), and actual hanging rootogram\n## (note that Rice erroneously refers to suspended rootograms as hanging)\nsp &lt;- lm(SerumPotassium ~ 1)\nbr &lt;- 32:54/10 - 0.05\nrootogram(sp, scale = \"raw\", style = \"standing\",\n  breaks = br, col = \"transparent\")\n\n\n\n\n\n\nrootogram(sp, scale = \"raw\", style = \"suspended\",\n  breaks = br, col = \"transparent\", ylim = c(2.8, -4))\n\n\n\n\n\n\nrootogram(sp, scale = \"sqrt\", style = \"suspended\",\n  breaks = br, col = \"transparent\", ylim = c(1, -1.5))\n\n\n\n\n\n\nrootogram(sp, breaks = br)",
    "crumbs": [
      "Data sets",
      "SerumPotassium"
    ]
  },
  {
    "objectID": "man/geom_rootogram.html",
    "href": "man/geom_rootogram.html",
    "title": "topmodels",
    "section": "",
    "text": "Various geom_ and stat_ used within autoplot for producing rootograms.\n\nstat_rootogram(\n  mapping = NULL,\n  data = NULL,\n  geom = \"rootogram\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\ngeom_rootogram(\n  mapping = NULL,\n  data = NULL,\n  stat = \"rootogram\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\nstat_rootogram_expected(\n  mapping = NULL,\n  data = NULL,\n  geom = \"rootogram_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  ...\n)\n\ngeom_rootogram_expected(\n  mapping = NULL,\n  data = NULL,\n  stat = \"rootogram_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  linestyle = c(\"both\", \"line\", \"point\"),\n  ...\n)\n\nGeomRootogramExpected\n\ngeom_rootogram_ref(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\nstat_rootogram_confint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"rootogram_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  level = 0.95,\n  nrep = 1000,\n  type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  scale = c(\"sqrt\", \"raw\"),\n  rootogram_style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\ngeom_rootogram_confint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"rootogram_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  level = 0.95,\n  nrep = 1000,\n  type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  scale = c(\"sqrt\", \"raw\"),\n  rootogram_style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\n\n\n\n\nmapping\n\n\nSet of aesthetic mappings created by aes(). If specified and inherit.aes = TRUE (the default), it is combined with the default mapping at the top level of the plot. You must supply mapping if there is no plot mapping.\n\n\n\n\ndata\n\n\nThe data to be displayed in this layer. There are three options:\nIf NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\nA data.frame, or other object, will override the plot data. All objects will be fortified to produce a data frame. See fortify() for which variables will be created.\nA function will be called with a single argument, the plot data. The return value must be a data.frame, and will be used as the layer data. A function can be created from a formula (e.g. ~ head(.x, 10)).\n\n\n\n\ngeom\n\n\nThe geometric object to use to display the data for this layer. When using a stat_*() function to construct a layer, the geom argument can be used to override the default coupling between stats and geoms. The geom argument accepts the following:\n\n\nA Geom ggproto subclass, for example GeomPoint.\n\n\nA string naming the geom. To give the geom as a string, strip the function name of the geom_ prefix. For example, to use geom_point(), give the geom as “point”.\n\n\nFor more information and other ways to specify the geom, see the layer geom documentation.\n\n\n\n\n\n\nposition\n\n\nA position adjustment to use on the data for this layer. This can be used in various ways, including to prevent overplotting and improving the display. The position argument accepts the following:\n\n\nThe result of calling a position function, such as position_jitter(). This method allows for passing extra arguments to the position.\n\n\nA string naming the position adjustment. To give the position as a string, strip the function name of the position_ prefix. For example, to use position_jitter(), give the position as “jitter”.\n\n\nFor more information and other ways to specify the position, see the layer position documentation.\n\n\n\n\n\n\nna.rm\n\n\nIf FALSE, the default, missing values are removed with a warning. If TRUE, missing values are silently removed.\n\n\n\n\nshow.legend\n\n\nlogical. Should this layer be included in the legends? NA, the default, includes if any aesthetics are mapped. FALSE never includes, and TRUE always includes. It can also be a named logical vector to finely select the aesthetics to display.\n\n\n\n\ninherit.aes\n\n\nIf FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\n\n\n\nscale\n\n\ncharacter specifying whether values should be transformed to the square root scale (not checking for original scale, so maybe applied again).\n\n\n\n\nstyle\n\n\ncharacter specifying the syle of rootogram (see below).\n\n\n\n\n…\n\n\nOther arguments passed on to layer()’s params argument. These arguments broadly fall into one of 4 categories below. Notably, further arguments to the position argument, or aesthetics that are required can not be passed through …. Unknown arguments that are not part of the 4 categories below are ignored.\n\n\nStatic aesthetics that are not mapped to a scale, but are at a fixed value and apply to the layer as a whole. For example, colour = “red” or linewidth = 3. The geom’s documentation has an Aesthetics section that lists the available options. The ‘required’ aesthetics cannot be passed on to the params. Please note that while passing unmapped aesthetics as vectors is technically possible, the order and required length is not guaranteed to be parallel to the input data.\n\n\nWhen constructing a layer using a stat_*() function, the … argument can be used to pass on parameters to the geom part of the layer. An example of this is stat_density(geom = “area”, outline.type = “both”). The geom’s documentation lists which parameters it can accept.\n\n\nInversely, when constructing a layer using a geom_*() function, the … argument can be used to pass on parameters to the stat part of the layer. An example of this is geom_area(stat = “density”, adjust = 0.5). The stat’s documentation lists which parameters it can accept.\n\n\nThe key_glyph argument of layer() may also be passed on through …. This can be one of the functions described as key glyphs, to change the display of the layer in the legend.\n\n\n\n\n\n\nstat\n\n\nThe statistical transformation to use on the data for this layer. When using a geom_*() function to construct a layer, the stat argument can be used the override the default coupling between geoms and stats. The stat argument accepts the following:\n\n\nA Stat ggproto subclass, for example StatCount.\n\n\nA string naming the stat. To give the stat as a string, strip the function name of the stat_ prefix. For example, to use stat_count(), give the stat as “count”.\n\n\nFor more information and other ways to specify the stat, see the layer stat documentation.\n\n\n\n\n\n\nlinestyle\n\n\nCharacter string defining one of ‘\"both\"’, ‘\"line\"’ or ‘\"point\"’.\n\n\n\n\nlevel\n\n\nnumeric. The confidence level required.\n\n\n\n\nnrep\n\n\nnumeric. The repetition number of simulation for computing the confidence intervals.\n\n\n\n\ntype\n\n\ncharacter. Should “tukey”, “pointwise”, or “simultaneous” confidence intervals be visualized?\n\n\n\n\nrootogram_style\n\n\ncharacter specifying the syle of rootogram.\n\n\n\nAn object of class GeomRootogramExpected (inherits from GeomPath, Geom, ggproto, gg) of length 3.\n\n\nlibrary(\"topmodels\")\n\nif (require(\"ggplot2\")) {\n  ## Fit model\n  data(\"CrabSatellites\", package = \"countreg\")\n  m1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n  m2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n  ## Compute rootogram (on raw scale)\n  p1 &lt;- rootogram(m1_pois, scale = \"raw\", plot = FALSE)\n  p2 &lt;- rootogram(m2_pois, scale = \"raw\", plot = FALSE)\n\n  d &lt;- c(p1, p2)\n\n  ## Get label names\n  main &lt;- attr(d, \"main\")\n  main &lt;- make.names(main, unique = TRUE)\n  d$group &lt;- factor(d$group, labels = main)\n\n  ## Plot rootograms w/ on default \"sqrt\" scale\n  gg1 &lt;- ggplot(data = d) +\n    geom_rootogram(aes(\n      observed = observed, expected = expected, mid = mid,\n      width = width, group = group\n    )) +\n    geom_rootogram_expected(aes(expected = expected, mid = mid)) +\n    geom_rootogram_ref() +\n    facet_grid(group ~ .) + \n    xlab(\"satellites\") +\n    ylab(\"sqrt(Frequency)\")\n  gg1\n}",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "geom_rootogram"
    ]
  },
  {
    "objectID": "man/geom_rootogram.html#geom_-and-stat_-for-producing-rootograms-with-ggplot2",
    "href": "man/geom_rootogram.html#geom_-and-stat_-for-producing-rootograms-with-ggplot2",
    "title": "topmodels",
    "section": "",
    "text": "Various geom_ and stat_ used within autoplot for producing rootograms.\n\nstat_rootogram(\n  mapping = NULL,\n  data = NULL,\n  geom = \"rootogram\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\ngeom_rootogram(\n  mapping = NULL,\n  data = NULL,\n  stat = \"rootogram\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\nstat_rootogram_expected(\n  mapping = NULL,\n  data = NULL,\n  geom = \"rootogram_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  ...\n)\n\ngeom_rootogram_expected(\n  mapping = NULL,\n  data = NULL,\n  stat = \"rootogram_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"sqrt\", \"raw\"),\n  linestyle = c(\"both\", \"line\", \"point\"),\n  ...\n)\n\nGeomRootogramExpected\n\ngeom_rootogram_ref(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\nstat_rootogram_confint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"rootogram_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  level = 0.95,\n  nrep = 1000,\n  type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  scale = c(\"sqrt\", \"raw\"),\n  rootogram_style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\ngeom_rootogram_confint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"rootogram_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  level = 0.95,\n  nrep = 1000,\n  type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  scale = c(\"sqrt\", \"raw\"),\n  rootogram_style = c(\"hanging\", \"standing\", \"suspended\"),\n  ...\n)\n\n\n\n\n\nmapping\n\n\nSet of aesthetic mappings created by aes(). If specified and inherit.aes = TRUE (the default), it is combined with the default mapping at the top level of the plot. You must supply mapping if there is no plot mapping.\n\n\n\n\ndata\n\n\nThe data to be displayed in this layer. There are three options:\nIf NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\nA data.frame, or other object, will override the plot data. All objects will be fortified to produce a data frame. See fortify() for which variables will be created.\nA function will be called with a single argument, the plot data. The return value must be a data.frame, and will be used as the layer data. A function can be created from a formula (e.g. ~ head(.x, 10)).\n\n\n\n\ngeom\n\n\nThe geometric object to use to display the data for this layer. When using a stat_*() function to construct a layer, the geom argument can be used to override the default coupling between stats and geoms. The geom argument accepts the following:\n\n\nA Geom ggproto subclass, for example GeomPoint.\n\n\nA string naming the geom. To give the geom as a string, strip the function name of the geom_ prefix. For example, to use geom_point(), give the geom as “point”.\n\n\nFor more information and other ways to specify the geom, see the layer geom documentation.\n\n\n\n\n\n\nposition\n\n\nA position adjustment to use on the data for this layer. This can be used in various ways, including to prevent overplotting and improving the display. The position argument accepts the following:\n\n\nThe result of calling a position function, such as position_jitter(). This method allows for passing extra arguments to the position.\n\n\nA string naming the position adjustment. To give the position as a string, strip the function name of the position_ prefix. For example, to use position_jitter(), give the position as “jitter”.\n\n\nFor more information and other ways to specify the position, see the layer position documentation.\n\n\n\n\n\n\nna.rm\n\n\nIf FALSE, the default, missing values are removed with a warning. If TRUE, missing values are silently removed.\n\n\n\n\nshow.legend\n\n\nlogical. Should this layer be included in the legends? NA, the default, includes if any aesthetics are mapped. FALSE never includes, and TRUE always includes. It can also be a named logical vector to finely select the aesthetics to display.\n\n\n\n\ninherit.aes\n\n\nIf FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\n\n\n\nscale\n\n\ncharacter specifying whether values should be transformed to the square root scale (not checking for original scale, so maybe applied again).\n\n\n\n\nstyle\n\n\ncharacter specifying the syle of rootogram (see below).\n\n\n\n\n…\n\n\nOther arguments passed on to layer()’s params argument. These arguments broadly fall into one of 4 categories below. Notably, further arguments to the position argument, or aesthetics that are required can not be passed through …. Unknown arguments that are not part of the 4 categories below are ignored.\n\n\nStatic aesthetics that are not mapped to a scale, but are at a fixed value and apply to the layer as a whole. For example, colour = “red” or linewidth = 3. The geom’s documentation has an Aesthetics section that lists the available options. The ‘required’ aesthetics cannot be passed on to the params. Please note that while passing unmapped aesthetics as vectors is technically possible, the order and required length is not guaranteed to be parallel to the input data.\n\n\nWhen constructing a layer using a stat_*() function, the … argument can be used to pass on parameters to the geom part of the layer. An example of this is stat_density(geom = “area”, outline.type = “both”). The geom’s documentation lists which parameters it can accept.\n\n\nInversely, when constructing a layer using a geom_*() function, the … argument can be used to pass on parameters to the stat part of the layer. An example of this is geom_area(stat = “density”, adjust = 0.5). The stat’s documentation lists which parameters it can accept.\n\n\nThe key_glyph argument of layer() may also be passed on through …. This can be one of the functions described as key glyphs, to change the display of the layer in the legend.\n\n\n\n\n\n\nstat\n\n\nThe statistical transformation to use on the data for this layer. When using a geom_*() function to construct a layer, the stat argument can be used the override the default coupling between geoms and stats. The stat argument accepts the following:\n\n\nA Stat ggproto subclass, for example StatCount.\n\n\nA string naming the stat. To give the stat as a string, strip the function name of the stat_ prefix. For example, to use stat_count(), give the stat as “count”.\n\n\nFor more information and other ways to specify the stat, see the layer stat documentation.\n\n\n\n\n\n\nlinestyle\n\n\nCharacter string defining one of ‘\"both\"’, ‘\"line\"’ or ‘\"point\"’.\n\n\n\n\nlevel\n\n\nnumeric. The confidence level required.\n\n\n\n\nnrep\n\n\nnumeric. The repetition number of simulation for computing the confidence intervals.\n\n\n\n\ntype\n\n\ncharacter. Should “tukey”, “pointwise”, or “simultaneous” confidence intervals be visualized?\n\n\n\n\nrootogram_style\n\n\ncharacter specifying the syle of rootogram.\n\n\n\nAn object of class GeomRootogramExpected (inherits from GeomPath, Geom, ggproto, gg) of length 3.\n\n\nlibrary(\"topmodels\")\n\nif (require(\"ggplot2\")) {\n  ## Fit model\n  data(\"CrabSatellites\", package = \"countreg\")\n  m1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n  m2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n  ## Compute rootogram (on raw scale)\n  p1 &lt;- rootogram(m1_pois, scale = \"raw\", plot = FALSE)\n  p2 &lt;- rootogram(m2_pois, scale = \"raw\", plot = FALSE)\n\n  d &lt;- c(p1, p2)\n\n  ## Get label names\n  main &lt;- attr(d, \"main\")\n  main &lt;- make.names(main, unique = TRUE)\n  d$group &lt;- factor(d$group, labels = main)\n\n  ## Plot rootograms w/ on default \"sqrt\" scale\n  gg1 &lt;- ggplot(data = d) +\n    geom_rootogram(aes(\n      observed = observed, expected = expected, mid = mid,\n      width = width, group = group\n    )) +\n    geom_rootogram_expected(aes(expected = expected, mid = mid)) +\n    geom_rootogram_ref() +\n    facet_grid(group ~ .) + \n    xlab(\"satellites\") +\n    ylab(\"sqrt(Frequency)\")\n  gg1\n}",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "geom_rootogram"
    ]
  },
  {
    "objectID": "man/geom_qqrplot.html",
    "href": "man/geom_qqrplot.html",
    "title": "topmodels",
    "section": "",
    "text": "Various geom_ and stat_ used within autoplot for producing quantile residual Q-Q plots.\n\ngeom_qqrplot(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\nstat_qqrplot_simint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"qqrplot_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\ngeom_qqrplot_simint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"qqrplot_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\nstat_qqrplot_ref(\n  mapping = NULL,\n  data = NULL,\n  geom = \"qqrplot_ref\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  detrend = FALSE,\n  identity = TRUE,\n  probs = c(0.25, 0.75),\n  scale = c(\"normal\", \"uniform\"),\n  ...\n)\n\ngeom_qqrplot_ref(\n  mapping = NULL,\n  data = NULL,\n  stat = \"qqrplot_ref\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  detrend = FALSE,\n  identity = TRUE,\n  probs = c(0.25, 0.75),\n  scale = c(\"normal\", \"uniform\"),\n  ...\n)\n\ngeom_qqrplot_confint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"qqrplot_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  detrend = FALSE,\n  type = c(\"pointwise\", \"simultaneous\", \"beta\", \"normal\", \"ks\", \"ell\"),\n  level = 0.95,\n  identity = TRUE,\n  probs = c(0.25, 0.75),\n  scale = c(\"normal\", \"uniform\"),\n  style = c(\"polygon\", \"line\"),\n  ...\n)\n\nGeomQqrplotConfint\n\n\n\n\n\nmapping\n\n\nSet of aesthetic mappings created by aes(). If specified and inherit.aes = TRUE (the default), it is combined with the default mapping at the top level of the plot. You must supply mapping if there is no plot mapping.\n\n\n\n\ndata\n\n\nThe data to be displayed in this layer. There are three options:\nIf NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\nA data.frame, or other object, will override the plot data. All objects will be fortified to produce a data frame. See fortify() for which variables will be created.\nA function will be called with a single argument, the plot data. The return value must be a data.frame, and will be used as the layer data. A function can be created from a formula (e.g. ~ head(.x, 10)).\n\n\n\n\nstat\n\n\nThe statistical transformation to use on the data for this layer. When using a geom_*() function to construct a layer, the stat argument can be used the override the default coupling between geoms and stats. The stat argument accepts the following:\n\n\nA Stat ggproto subclass, for example StatCount.\n\n\nA string naming the stat. To give the stat as a string, strip the function name of the stat_ prefix. For example, to use stat_count(), give the stat as “count”.\n\n\nFor more information and other ways to specify the stat, see the layer stat documentation.\n\n\n\n\n\n\nposition\n\n\nA position adjustment to use on the data for this layer. This can be used in various ways, including to prevent overplotting and improving the display. The position argument accepts the following:\n\n\nThe result of calling a position function, such as position_jitter(). This method allows for passing extra arguments to the position.\n\n\nA string naming the position adjustment. To give the position as a string, strip the function name of the position_ prefix. For example, to use position_jitter(), give the position as “jitter”.\n\n\nFor more information and other ways to specify the position, see the layer position documentation.\n\n\n\n\n\n\nna.rm\n\n\nIf FALSE, the default, missing values are removed with a warning. If TRUE, missing values are silently removed.\n\n\n\n\nshow.legend\n\n\nlogical. Should this layer be included in the legends? NA, the default, includes if any aesthetics are mapped. FALSE never includes, and TRUE always includes. It can also be a named logical vector to finely select the aesthetics to display.\n\n\n\n\ninherit.aes\n\n\nIf FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\n\n\n\n…\n\n\nOther arguments passed on to layer()’s params argument. These arguments broadly fall into one of 4 categories below. Notably, further arguments to the position argument, or aesthetics that are required can not be passed through …. Unknown arguments that are not part of the 4 categories below are ignored.\n\n\nStatic aesthetics that are not mapped to a scale, but are at a fixed value and apply to the layer as a whole. For example, colour = “red” or linewidth = 3. The geom’s documentation has an Aesthetics section that lists the available options. The ‘required’ aesthetics cannot be passed on to the params. Please note that while passing unmapped aesthetics as vectors is technically possible, the order and required length is not guaranteed to be parallel to the input data.\n\n\nWhen constructing a layer using a stat_*() function, the … argument can be used to pass on parameters to the geom part of the layer. An example of this is stat_density(geom = “area”, outline.type = “both”). The geom’s documentation lists which parameters it can accept.\n\n\nInversely, when constructing a layer using a geom_*() function, the … argument can be used to pass on parameters to the stat part of the layer. An example of this is geom_area(stat = “density”, adjust = 0.5). The stat’s documentation lists which parameters it can accept.\n\n\nThe key_glyph argument of layer() may also be passed on through …. This can be one of the functions described as key glyphs, to change the display of the layer in the legend.\n\n\n\n\n\n\ngeom\n\n\nThe geometric object to use to display the data for this layer. When using a stat_*() function to construct a layer, the geom argument can be used to override the default coupling between stats and geoms. The geom argument accepts the following:\n\n\nA Geom ggproto subclass, for example GeomPoint.\n\n\nA string naming the geom. To give the geom as a string, strip the function name of the geom_ prefix. For example, to use geom_point(), give the geom as “point”.\n\n\nFor more information and other ways to specify the geom, see the layer geom documentation.\n\n\n\n\n\n\ndetrend\n\n\nlogical, default FALSE. If set to TRUE the qqrplot is detrended, i.e, plotted as a wormplot.\n\n\n\n\nidentity\n\n\nlogical. Should the identity line be plotted or a theoretical line which passes through probs quantiles on the “uniform” or “normal” scale.\n\n\n\n\nprobs\n\n\nnumeric vector of length two, representing probabilities of reference line used.\n\n\n\n\nscale\n\n\ncharacter. Scale on which the quantile residuals will be shown: “uniform” (default) for uniform scale or “normal” for normal scale. Used for the reference line which goes through the first and third quartile of theoretical distributions.\n\n\n\n\ntype\n\n\ncharacter. Method for creating the confidence intervals. There are two methods for pointwise confidence intervals: Based on the ‘\"beta\"’ or ‘\"normal\"’ distribution, yielding very similar results. And there are two methods for simultaneous confidence intervals: Based on the Kolmogorov-Smirnov test (‘\"ks\"’) or equal local levels (‘\"ell\"’), where the latter has much better properties but requires the qqconf package to be installed ([qqconf::get_qq_band()]). Finally, the methods ‘\"pointwise\"’ and ‘\"simultaneous\"’ are simply aliases for the preferred corresponding methods ‘\"beta\"’ and ‘\"ell\"’, respectively.\n\n\n\n\nlevel\n\n\nnumeric. The confidence level required, defaults to 0.95.\n\n\n\n\nstyle\n\n\ncharacter. Style for plotting confidence intervals. Either “polygon” (default) or “line”).\n\n\n\nAn object of class GeomQqrplotConfint (inherits from Geom, ggproto, gg) of length 6.\n\n\nlibrary(\"topmodels\")\n\nif (require(\"ggplot2\")) {\n  ## Fit model\n  data(\"CrabSatellites\", package = \"countreg\")\n  m1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n  m2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n  \n  ## Compute qqrplot\n  q1 &lt;- qqrplot(m1_pois, plot = FALSE)\n  q2 &lt;- qqrplot(m2_pois, plot = FALSE)\n  \n  d &lt;- c(q1, q2) \n  \n  ## Get label names\n  xlab &lt;- unique(attr(d, \"xlab\"))\n  ylab &lt;- unique(attr(d, \"ylab\"))\n  main &lt;- attr(d, \"main\")\n  main &lt;- make.names(main, unique = TRUE)\n  d$group &lt;- factor(d$group, labels = main)\n  \n  ## Polygon CI around identity line used as reference \n  gg1 &lt;- ggplot(data = d, aes(x = expected, y = observed, na.rm = TRUE)) + \n    geom_qqrplot_ref() + \n    geom_qqrplot_confint(fill = \"red\") + \n    geom_qqrplot() + \n    geom_qqrplot_simint(\n      aes(\n        x = simint_expected, \n        ymin = simint_observed_lwr, \n        ymax = simint_observed_upr,\n        group = group\n      )\n    ) + \n    xlab(xlab) + ylab(ylab)\n\n  gg1\n  gg1 + facet_wrap(~group)\n  \n  ## Polygon CI around robust reference line\n  gg2 &lt;- ggplot(data = d, aes(x = expected, y = observed, na.rm = TRUE)) + \n    geom_qqrplot_ref(identity = FALSE, scale = attr(d, \"scale\")) + \n    geom_qqrplot_confint(identity = FALSE, scale = attr(d, \"scale\"), style = \"line\") + \n    geom_qqrplot() + \n    geom_qqrplot_simint(\n      aes(\n        x = simint_expected, \n        ymin = simint_observed_lwr, \n        ymax = simint_observed_upr,\n        group = group\n      )\n    ) + \n    xlab(xlab) + ylab(ylab)\n\n  gg2\n  gg2 + facet_wrap(~group)\n\n  ## Use different `scale`s with confidence intervals\n  q1 &lt;- qqrplot(m1_pois, scale = \"uniform\", plot = FALSE)\n  q2 &lt;- qqrplot(m2_pois, plot = FALSE)\n  \n  gg3 &lt;- ggplot(data = q1, aes(x = expected, y = observed, na.rm = TRUE)) +\n    geom_qqrplot_ref() +\n    geom_qqrplot_confint(fill = \"red\", scale = \"uniform\") +\n    geom_qqrplot()\n  gg3\n  \n  gg4 &lt;- ggplot(data = q2, aes(x = expected, y = observed, na.rm = TRUE)) +\n    geom_qqrplot_ref() +\n    geom_qqrplot_confint(fill = \"red\", scale = \"uniform\") +\n    geom_qqrplot()\n  gg4\n}",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "geom_qqrplot"
    ]
  },
  {
    "objectID": "man/geom_qqrplot.html#geom_-and-stat_-for-producing-quantile-residual-q-q-plots-with-ggplot2",
    "href": "man/geom_qqrplot.html#geom_-and-stat_-for-producing-quantile-residual-q-q-plots-with-ggplot2",
    "title": "topmodels",
    "section": "",
    "text": "Various geom_ and stat_ used within autoplot for producing quantile residual Q-Q plots.\n\ngeom_qqrplot(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\nstat_qqrplot_simint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"qqrplot_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\ngeom_qqrplot_simint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"qqrplot_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  ...\n)\n\nstat_qqrplot_ref(\n  mapping = NULL,\n  data = NULL,\n  geom = \"qqrplot_ref\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  detrend = FALSE,\n  identity = TRUE,\n  probs = c(0.25, 0.75),\n  scale = c(\"normal\", \"uniform\"),\n  ...\n)\n\ngeom_qqrplot_ref(\n  mapping = NULL,\n  data = NULL,\n  stat = \"qqrplot_ref\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  detrend = FALSE,\n  identity = TRUE,\n  probs = c(0.25, 0.75),\n  scale = c(\"normal\", \"uniform\"),\n  ...\n)\n\ngeom_qqrplot_confint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"qqrplot_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  detrend = FALSE,\n  type = c(\"pointwise\", \"simultaneous\", \"beta\", \"normal\", \"ks\", \"ell\"),\n  level = 0.95,\n  identity = TRUE,\n  probs = c(0.25, 0.75),\n  scale = c(\"normal\", \"uniform\"),\n  style = c(\"polygon\", \"line\"),\n  ...\n)\n\nGeomQqrplotConfint\n\n\n\n\n\nmapping\n\n\nSet of aesthetic mappings created by aes(). If specified and inherit.aes = TRUE (the default), it is combined with the default mapping at the top level of the plot. You must supply mapping if there is no plot mapping.\n\n\n\n\ndata\n\n\nThe data to be displayed in this layer. There are three options:\nIf NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\nA data.frame, or other object, will override the plot data. All objects will be fortified to produce a data frame. See fortify() for which variables will be created.\nA function will be called with a single argument, the plot data. The return value must be a data.frame, and will be used as the layer data. A function can be created from a formula (e.g. ~ head(.x, 10)).\n\n\n\n\nstat\n\n\nThe statistical transformation to use on the data for this layer. When using a geom_*() function to construct a layer, the stat argument can be used the override the default coupling between geoms and stats. The stat argument accepts the following:\n\n\nA Stat ggproto subclass, for example StatCount.\n\n\nA string naming the stat. To give the stat as a string, strip the function name of the stat_ prefix. For example, to use stat_count(), give the stat as “count”.\n\n\nFor more information and other ways to specify the stat, see the layer stat documentation.\n\n\n\n\n\n\nposition\n\n\nA position adjustment to use on the data for this layer. This can be used in various ways, including to prevent overplotting and improving the display. The position argument accepts the following:\n\n\nThe result of calling a position function, such as position_jitter(). This method allows for passing extra arguments to the position.\n\n\nA string naming the position adjustment. To give the position as a string, strip the function name of the position_ prefix. For example, to use position_jitter(), give the position as “jitter”.\n\n\nFor more information and other ways to specify the position, see the layer position documentation.\n\n\n\n\n\n\nna.rm\n\n\nIf FALSE, the default, missing values are removed with a warning. If TRUE, missing values are silently removed.\n\n\n\n\nshow.legend\n\n\nlogical. Should this layer be included in the legends? NA, the default, includes if any aesthetics are mapped. FALSE never includes, and TRUE always includes. It can also be a named logical vector to finely select the aesthetics to display.\n\n\n\n\ninherit.aes\n\n\nIf FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\n\n\n\n…\n\n\nOther arguments passed on to layer()’s params argument. These arguments broadly fall into one of 4 categories below. Notably, further arguments to the position argument, or aesthetics that are required can not be passed through …. Unknown arguments that are not part of the 4 categories below are ignored.\n\n\nStatic aesthetics that are not mapped to a scale, but are at a fixed value and apply to the layer as a whole. For example, colour = “red” or linewidth = 3. The geom’s documentation has an Aesthetics section that lists the available options. The ‘required’ aesthetics cannot be passed on to the params. Please note that while passing unmapped aesthetics as vectors is technically possible, the order and required length is not guaranteed to be parallel to the input data.\n\n\nWhen constructing a layer using a stat_*() function, the … argument can be used to pass on parameters to the geom part of the layer. An example of this is stat_density(geom = “area”, outline.type = “both”). The geom’s documentation lists which parameters it can accept.\n\n\nInversely, when constructing a layer using a geom_*() function, the … argument can be used to pass on parameters to the stat part of the layer. An example of this is geom_area(stat = “density”, adjust = 0.5). The stat’s documentation lists which parameters it can accept.\n\n\nThe key_glyph argument of layer() may also be passed on through …. This can be one of the functions described as key glyphs, to change the display of the layer in the legend.\n\n\n\n\n\n\ngeom\n\n\nThe geometric object to use to display the data for this layer. When using a stat_*() function to construct a layer, the geom argument can be used to override the default coupling between stats and geoms. The geom argument accepts the following:\n\n\nA Geom ggproto subclass, for example GeomPoint.\n\n\nA string naming the geom. To give the geom as a string, strip the function name of the geom_ prefix. For example, to use geom_point(), give the geom as “point”.\n\n\nFor more information and other ways to specify the geom, see the layer geom documentation.\n\n\n\n\n\n\ndetrend\n\n\nlogical, default FALSE. If set to TRUE the qqrplot is detrended, i.e, plotted as a wormplot.\n\n\n\n\nidentity\n\n\nlogical. Should the identity line be plotted or a theoretical line which passes through probs quantiles on the “uniform” or “normal” scale.\n\n\n\n\nprobs\n\n\nnumeric vector of length two, representing probabilities of reference line used.\n\n\n\n\nscale\n\n\ncharacter. Scale on which the quantile residuals will be shown: “uniform” (default) for uniform scale or “normal” for normal scale. Used for the reference line which goes through the first and third quartile of theoretical distributions.\n\n\n\n\ntype\n\n\ncharacter. Method for creating the confidence intervals. There are two methods for pointwise confidence intervals: Based on the ‘\"beta\"’ or ‘\"normal\"’ distribution, yielding very similar results. And there are two methods for simultaneous confidence intervals: Based on the Kolmogorov-Smirnov test (‘\"ks\"’) or equal local levels (‘\"ell\"’), where the latter has much better properties but requires the qqconf package to be installed ([qqconf::get_qq_band()]). Finally, the methods ‘\"pointwise\"’ and ‘\"simultaneous\"’ are simply aliases for the preferred corresponding methods ‘\"beta\"’ and ‘\"ell\"’, respectively.\n\n\n\n\nlevel\n\n\nnumeric. The confidence level required, defaults to 0.95.\n\n\n\n\nstyle\n\n\ncharacter. Style for plotting confidence intervals. Either “polygon” (default) or “line”).\n\n\n\nAn object of class GeomQqrplotConfint (inherits from Geom, ggproto, gg) of length 6.\n\n\nlibrary(\"topmodels\")\n\nif (require(\"ggplot2\")) {\n  ## Fit model\n  data(\"CrabSatellites\", package = \"countreg\")\n  m1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n  m2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n  \n  ## Compute qqrplot\n  q1 &lt;- qqrplot(m1_pois, plot = FALSE)\n  q2 &lt;- qqrplot(m2_pois, plot = FALSE)\n  \n  d &lt;- c(q1, q2) \n  \n  ## Get label names\n  xlab &lt;- unique(attr(d, \"xlab\"))\n  ylab &lt;- unique(attr(d, \"ylab\"))\n  main &lt;- attr(d, \"main\")\n  main &lt;- make.names(main, unique = TRUE)\n  d$group &lt;- factor(d$group, labels = main)\n  \n  ## Polygon CI around identity line used as reference \n  gg1 &lt;- ggplot(data = d, aes(x = expected, y = observed, na.rm = TRUE)) + \n    geom_qqrplot_ref() + \n    geom_qqrplot_confint(fill = \"red\") + \n    geom_qqrplot() + \n    geom_qqrplot_simint(\n      aes(\n        x = simint_expected, \n        ymin = simint_observed_lwr, \n        ymax = simint_observed_upr,\n        group = group\n      )\n    ) + \n    xlab(xlab) + ylab(ylab)\n\n  gg1\n  gg1 + facet_wrap(~group)\n  \n  ## Polygon CI around robust reference line\n  gg2 &lt;- ggplot(data = d, aes(x = expected, y = observed, na.rm = TRUE)) + \n    geom_qqrplot_ref(identity = FALSE, scale = attr(d, \"scale\")) + \n    geom_qqrplot_confint(identity = FALSE, scale = attr(d, \"scale\"), style = \"line\") + \n    geom_qqrplot() + \n    geom_qqrplot_simint(\n      aes(\n        x = simint_expected, \n        ymin = simint_observed_lwr, \n        ymax = simint_observed_upr,\n        group = group\n      )\n    ) + \n    xlab(xlab) + ylab(ylab)\n\n  gg2\n  gg2 + facet_wrap(~group)\n\n  ## Use different `scale`s with confidence intervals\n  q1 &lt;- qqrplot(m1_pois, scale = \"uniform\", plot = FALSE)\n  q2 &lt;- qqrplot(m2_pois, plot = FALSE)\n  \n  gg3 &lt;- ggplot(data = q1, aes(x = expected, y = observed, na.rm = TRUE)) +\n    geom_qqrplot_ref() +\n    geom_qqrplot_confint(fill = \"red\", scale = \"uniform\") +\n    geom_qqrplot()\n  gg3\n  \n  gg4 &lt;- ggplot(data = q2, aes(x = expected, y = observed, na.rm = TRUE)) +\n    geom_qqrplot_ref() +\n    geom_qqrplot_confint(fill = \"red\", scale = \"uniform\") +\n    geom_qqrplot()\n  gg4\n}",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "geom_qqrplot"
    ]
  },
  {
    "objectID": "man/newresponse.html",
    "href": "man/newresponse.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and methods for extracting response variables from new data based on fitted model objects.\n\nnewresponse(object, ...)\n\n## Default S3 method:\nnewresponse(object, newdata, na.action = na.pass, ...)\n\n## S3 method for class 'glm'\nnewresponse(object, newdata, na.action = na.pass, initialize = NULL, ...)\n\n## S3 method for class 'distribution'\nnewresponse(object, newdata, ...)\n\n\n\n\n\nobject\n\n\na fitted model object. For the default method this needs to needs to be formula-based so that model.frame can be used to extract the response from the original data the model was fitted to or terms can be used to set up the response on newdata.\n\n\n\n\n…\n\n\nfurther arguments passed to methods.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nna.action\n\n\nfunction determining how to handle missing values in newdata, by default these are preserved.\n\n\n\n\ninitialize\n\n\nlogical. Should the response variable from glm objects be initialized using the corresponding expression from the family? If NULL (the default), the initialization is only used for binomial and quasibinomial families.\n\n\n\nnewresponse is a convenience function that supports functions like proscore or proresiduals which assess discrepancies between predictions/forecasts on new data and the corresponding observed response variables.\nThe default method takes an approach that is similar to many predict methods which rebuild the model.frame after dropping the response from the terms of a model object. However, here only the response variable is preserved and all explanatory variables are dropped. Missing values values are typically preserved (i.e., using na.pass).\nIf the new model.frame contains a variable “(weights)”, it is preserved along with the response variable(s).\nA method for distribution objects is provided which expects that newdata is essentially already the corresponding new response. Thus, it needs to be a vector (or data frame) of the same length as distribution. If it is not a data frame, yet, it is transformed to one but no further modifications are made.\n\nA data.frame (model.frame) containing the response variable (and optionally a variable with “(weights)”).\n\nterms, model.frame\n\n\nlibrary(\"topmodels\")\n\n## linear regression model\nm &lt;- lm(dist ~ speed, data = cars)\n\n## extract response variable on data used for model fitting \nnewresponse(m)\n\n   dist\n1     2\n2    10\n3     4\n4    22\n5    16\n6    10\n7    18\n8    26\n9    34\n10   17\n11   28\n12   14\n13   20\n14   24\n15   28\n16   26\n17   34\n18   34\n19   46\n20   26\n21   36\n22   60\n23   80\n24   20\n25   26\n26   54\n27   32\n28   40\n29   32\n30   40\n31   50\n32   42\n33   56\n34   76\n35   84\n36   36\n37   46\n38   68\n39   32\n40   48\n41   52\n42   56\n43   64\n44   66\n45   54\n46   70\n47   92\n48   93\n49  120\n50   85\n\n## extract response variable on \"new\" data\nnewresponse(m, newdata = cars[1:3, ])\n\n  dist\n1    2\n2   10\n3    4",
    "crumbs": [
      "Procast infrastructure",
      "newresponse"
    ]
  },
  {
    "objectID": "man/newresponse.html#extract-observed-responses-from-new-data",
    "href": "man/newresponse.html#extract-observed-responses-from-new-data",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and methods for extracting response variables from new data based on fitted model objects.\n\nnewresponse(object, ...)\n\n## Default S3 method:\nnewresponse(object, newdata, na.action = na.pass, ...)\n\n## S3 method for class 'glm'\nnewresponse(object, newdata, na.action = na.pass, initialize = NULL, ...)\n\n## S3 method for class 'distribution'\nnewresponse(object, newdata, ...)\n\n\n\n\n\nobject\n\n\na fitted model object. For the default method this needs to needs to be formula-based so that model.frame can be used to extract the response from the original data the model was fitted to or terms can be used to set up the response on newdata.\n\n\n\n\n…\n\n\nfurther arguments passed to methods.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nna.action\n\n\nfunction determining how to handle missing values in newdata, by default these are preserved.\n\n\n\n\ninitialize\n\n\nlogical. Should the response variable from glm objects be initialized using the corresponding expression from the family? If NULL (the default), the initialization is only used for binomial and quasibinomial families.\n\n\n\nnewresponse is a convenience function that supports functions like proscore or proresiduals which assess discrepancies between predictions/forecasts on new data and the corresponding observed response variables.\nThe default method takes an approach that is similar to many predict methods which rebuild the model.frame after dropping the response from the terms of a model object. However, here only the response variable is preserved and all explanatory variables are dropped. Missing values values are typically preserved (i.e., using na.pass).\nIf the new model.frame contains a variable “(weights)”, it is preserved along with the response variable(s).\nA method for distribution objects is provided which expects that newdata is essentially already the corresponding new response. Thus, it needs to be a vector (or data frame) of the same length as distribution. If it is not a data frame, yet, it is transformed to one but no further modifications are made.\n\nA data.frame (model.frame) containing the response variable (and optionally a variable with “(weights)”).\n\nterms, model.frame\n\n\nlibrary(\"topmodels\")\n\n## linear regression model\nm &lt;- lm(dist ~ speed, data = cars)\n\n## extract response variable on data used for model fitting \nnewresponse(m)\n\n   dist\n1     2\n2    10\n3     4\n4    22\n5    16\n6    10\n7    18\n8    26\n9    34\n10   17\n11   28\n12   14\n13   20\n14   24\n15   28\n16   26\n17   34\n18   34\n19   46\n20   26\n21   36\n22   60\n23   80\n24   20\n25   26\n26   54\n27   32\n28   40\n29   32\n30   40\n31   50\n32   42\n33   56\n34   76\n35   84\n36   36\n37   46\n38   68\n39   32\n40   48\n41   52\n42   56\n43   64\n44   66\n45   54\n46   70\n47   92\n48   93\n49  120\n50   85\n\n## extract response variable on \"new\" data\nnewresponse(m, newdata = cars[1:3, ])\n\n  dist\n1    2\n2   10\n3    4",
    "crumbs": [
      "Procast infrastructure",
      "newresponse"
    ]
  },
  {
    "objectID": "man/crps.distribution.html",
    "href": "man/crps.distribution.html",
    "title": "topmodels",
    "section": "",
    "text": "Method to the crps generic function from the scoringRules package for numerically evaluating the (continuous) ranked probability score (CRPS) of any probability distributions3 object.\n\ncrps.distribution(\n  y,\n  x,\n  drop = TRUE,\n  elementwise = NULL,\n  gridsize = 500L,\n  batchsize = 10000L,\n  applyfun = NULL,\n  cores = NULL,\n  method = NULL,\n  ...\n)\n\ncrps.Beta(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Bernoulli(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Binomial(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Erlang(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Exponential(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Gamma(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.GEV(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Geometric(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Gumbel(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.HyperGeometric(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Logistic(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.LogNormal(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.NegativeBinomial(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Normal(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Poisson(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.StudentsT(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Uniform(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.XBetaX(y, x, drop = TRUE, elementwise = NULL, method = \"cdf\", ...)\n\ncrps.GAMLSS(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.BAMLSS(y, x, drop = TRUE, elementwise = NULL, ...)\n\n\n\n\n\ny\n\n\nA distribution object, e.g., as created by Normal or Binomial.\n\n\n\n\nx\n\n\nA vector of elements whose CRPS should be determined given the distribution y.\n\n\n\n\ndrop\n\n\nlogical. Should the result be simplified to a vector if possible?\n\n\n\n\nelementwise\n\n\nlogical. Should each distribution in y be evaluated at all elements of x (elementwise = FALSE, yielding a matrix)? Or, if y and x have the same length, should the evaluation be done element by element (elementwise = TRUE, yielding a vector)? The default of NULL means that elementwise = TRUE is used if the lengths match and otherwise elementwise = FALSE is used.\n\n\n\n\ngridsize\n\n\npositive size of the grid used to approximate the CDF for the numerical calculation of the CRPS.\n\n\n\n\nbatchsize\n\n\nmaximum batch size. Used to split the input into batches. Lower values reduce required memory but may increase computation time.\n\n\n\n\napplyfun\n\n\nan optional lapply-style function with arguments function(X, FUN, …). It is used to compute the CRPS for each element of y. The default is to use the basic lapply function unless the cores argument is specified (see below).\n\n\n\n\ncores\n\n\nnumeric. If set to an integer the applyfun is set to mclapply with the desired number of cores, except on Windows where parLapply with makeCluster(cores) is used.\n\n\n\n\nmethod\n\n\ncharacter. Should the grid be set up on the observation scale and method = “cdf” be used to compute the corresponding probabilities? Or should the grid be set up on the probability scale and method = “quantile” be used to compute the corresponding observations? By default, “cdf” is used for discrete observations whose range is smaller than the gridsize and “quantile” otherwise.\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\nThe (continuous) ranked probability score (CRPS) for (univariate) probability distributions can be computed based on the the object-oriented infrastructure provided by the distributions3 package. The general crps.distribution method does so by using numeric integration based on the cdf and/or quantile methods (for more details see below). Additionally, if dedicated closed-form CRPS computations are provided by the scoringRules package for the specified distribution, then these are used because they are both computationally faster and numerically more precise. For example, the crps method for Normal objects leverages crps_norm rather than relying on numeric integration.\nThe general method for any distribution object uses the following strategy for numerical CRPS computation. By default (if the method argument is NULL), it distinguishes distributions whose entire support is continuous, or whose entire support is discrete, or mixed discrete-continuous distribution using is_continuous and is_discrete, respectively.\nFor continuous and mixed distributions, an equidistant grid of gridsize + 5 probabilities is drawn for which the corresponding quantiles for each distribution y are calculated (including the observation x). The calculation of the CRPS then uses a trapezoidal approximation for the numeric integration. For discrete distributions, gridsize equidistant quantiles (in steps of 1) are drawn and the corresponding probabilities from the cdf are calculated for each distribution y (including the observation x) and the CRPS calculated using numeric integration. If the gridsize in steps of 1 is not sufficient to cover the required range, the method falls back to the procedure used for continuous and mixed distributions to approximate the CRPS.\nIf the method argument is set to either “cdf” or “quantile”, then the specific strategy for setting up the grid of observations and corresponding probabilities can be enforced. This can be useful if for a certain distribution class, only a cdf or only a quantile method is available or only one of them is numerically stable or computationally efficient etc.\nThe numeric approximation requires to set up a matrix of dimension length(y) * (gridsize + 5) (or length(y) * (gridsize + 1)) which may be very memory intensive if length(y) and/or gridsize are large. Thus, the data is split batches of (approximately) equal size, not larger than batchsize. Thus, the memory requirement is reduced to batchsize * (gridsize + 5) in each step. Hence, a smaller value of batchsize will reduce memory footprint but will slightly increase computation time.\nThe error (deviation between numerical approximation and analytic solution) has been shown to be in the order of 1e-2 for a series of distributions tested. Accuracy can be increased by increasing gridsize and will be lower for a smaller gridsize.\nFor parallelization of the numeric computations, a suitable applyfun can be provided that carries out the integration for each element of y. To facilitate setting up a suitable applyfun using the basic parallel package, the argument cores is provided for convenience. When used, y is split into B equidistant batches; at least B = cores batches or a multiple of cores with a maximum size of batchsize. On systems running Windows parlapply is used, else mclapply.\n\nIn case of a single distribution object, either a numeric vector of length(x) (if drop = TRUE, default) or a matrix with length(x) columns (if drop = FALSE). In case of a vectorized distribution object, a matrix with length(x) columns containing all possible combinations.\n\n\nlibrary(\"topmodels\")\n\n\nset.seed(6020)\n\n## three normal distributions X and observations x\nlibrary(\"distributions3\")\nX &lt;- Normal(mu = c(0, 1, 2), sigma = c(2, 1, 1))\nx &lt;- c(0, 0, 1)\n\n## evaluate crps\n## using infrastructure from scoringRules (based on closed-form analytic equations)\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.4673900 0.6024414 0.6024414\n\n## using general distribution method explicitly (based on numeric integration)\ncrps.distribution(X, x)\n\n[1] 0.4674058 0.6024482 0.6024482\n\n## analogously for Poisson distribution\nY &lt;- Poisson(c(0.5, 1, 2))\ncrps(Y, x)\n\n[1] 0.1631650 0.4762224 0.4991650\n\ncrps.distribution(Y, x)\n\n[1] 0.1631650 0.4762224 0.4991650",
    "crumbs": [
      "Procast infrastructure",
      "crps.distribution"
    ]
  },
  {
    "objectID": "man/crps.distribution.html#method-for-numerically-evaluating-the-crps-of-probability-distributions",
    "href": "man/crps.distribution.html#method-for-numerically-evaluating-the-crps-of-probability-distributions",
    "title": "topmodels",
    "section": "",
    "text": "Method to the crps generic function from the scoringRules package for numerically evaluating the (continuous) ranked probability score (CRPS) of any probability distributions3 object.\n\ncrps.distribution(\n  y,\n  x,\n  drop = TRUE,\n  elementwise = NULL,\n  gridsize = 500L,\n  batchsize = 10000L,\n  applyfun = NULL,\n  cores = NULL,\n  method = NULL,\n  ...\n)\n\ncrps.Beta(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Bernoulli(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Binomial(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Erlang(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Exponential(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Gamma(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.GEV(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Geometric(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Gumbel(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.HyperGeometric(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Logistic(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.LogNormal(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.NegativeBinomial(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Normal(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Poisson(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.StudentsT(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.Uniform(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.XBetaX(y, x, drop = TRUE, elementwise = NULL, method = \"cdf\", ...)\n\ncrps.GAMLSS(y, x, drop = TRUE, elementwise = NULL, ...)\n\ncrps.BAMLSS(y, x, drop = TRUE, elementwise = NULL, ...)\n\n\n\n\n\ny\n\n\nA distribution object, e.g., as created by Normal or Binomial.\n\n\n\n\nx\n\n\nA vector of elements whose CRPS should be determined given the distribution y.\n\n\n\n\ndrop\n\n\nlogical. Should the result be simplified to a vector if possible?\n\n\n\n\nelementwise\n\n\nlogical. Should each distribution in y be evaluated at all elements of x (elementwise = FALSE, yielding a matrix)? Or, if y and x have the same length, should the evaluation be done element by element (elementwise = TRUE, yielding a vector)? The default of NULL means that elementwise = TRUE is used if the lengths match and otherwise elementwise = FALSE is used.\n\n\n\n\ngridsize\n\n\npositive size of the grid used to approximate the CDF for the numerical calculation of the CRPS.\n\n\n\n\nbatchsize\n\n\nmaximum batch size. Used to split the input into batches. Lower values reduce required memory but may increase computation time.\n\n\n\n\napplyfun\n\n\nan optional lapply-style function with arguments function(X, FUN, …). It is used to compute the CRPS for each element of y. The default is to use the basic lapply function unless the cores argument is specified (see below).\n\n\n\n\ncores\n\n\nnumeric. If set to an integer the applyfun is set to mclapply with the desired number of cores, except on Windows where parLapply with makeCluster(cores) is used.\n\n\n\n\nmethod\n\n\ncharacter. Should the grid be set up on the observation scale and method = “cdf” be used to compute the corresponding probabilities? Or should the grid be set up on the probability scale and method = “quantile” be used to compute the corresponding observations? By default, “cdf” is used for discrete observations whose range is smaller than the gridsize and “quantile” otherwise.\n\n\n\n\n…\n\n\ncurrently not used.\n\n\n\nThe (continuous) ranked probability score (CRPS) for (univariate) probability distributions can be computed based on the the object-oriented infrastructure provided by the distributions3 package. The general crps.distribution method does so by using numeric integration based on the cdf and/or quantile methods (for more details see below). Additionally, if dedicated closed-form CRPS computations are provided by the scoringRules package for the specified distribution, then these are used because they are both computationally faster and numerically more precise. For example, the crps method for Normal objects leverages crps_norm rather than relying on numeric integration.\nThe general method for any distribution object uses the following strategy for numerical CRPS computation. By default (if the method argument is NULL), it distinguishes distributions whose entire support is continuous, or whose entire support is discrete, or mixed discrete-continuous distribution using is_continuous and is_discrete, respectively.\nFor continuous and mixed distributions, an equidistant grid of gridsize + 5 probabilities is drawn for which the corresponding quantiles for each distribution y are calculated (including the observation x). The calculation of the CRPS then uses a trapezoidal approximation for the numeric integration. For discrete distributions, gridsize equidistant quantiles (in steps of 1) are drawn and the corresponding probabilities from the cdf are calculated for each distribution y (including the observation x) and the CRPS calculated using numeric integration. If the gridsize in steps of 1 is not sufficient to cover the required range, the method falls back to the procedure used for continuous and mixed distributions to approximate the CRPS.\nIf the method argument is set to either “cdf” or “quantile”, then the specific strategy for setting up the grid of observations and corresponding probabilities can be enforced. This can be useful if for a certain distribution class, only a cdf or only a quantile method is available or only one of them is numerically stable or computationally efficient etc.\nThe numeric approximation requires to set up a matrix of dimension length(y) * (gridsize + 5) (or length(y) * (gridsize + 1)) which may be very memory intensive if length(y) and/or gridsize are large. Thus, the data is split batches of (approximately) equal size, not larger than batchsize. Thus, the memory requirement is reduced to batchsize * (gridsize + 5) in each step. Hence, a smaller value of batchsize will reduce memory footprint but will slightly increase computation time.\nThe error (deviation between numerical approximation and analytic solution) has been shown to be in the order of 1e-2 for a series of distributions tested. Accuracy can be increased by increasing gridsize and will be lower for a smaller gridsize.\nFor parallelization of the numeric computations, a suitable applyfun can be provided that carries out the integration for each element of y. To facilitate setting up a suitable applyfun using the basic parallel package, the argument cores is provided for convenience. When used, y is split into B equidistant batches; at least B = cores batches or a multiple of cores with a maximum size of batchsize. On systems running Windows parlapply is used, else mclapply.\n\nIn case of a single distribution object, either a numeric vector of length(x) (if drop = TRUE, default) or a matrix with length(x) columns (if drop = FALSE). In case of a vectorized distribution object, a matrix with length(x) columns containing all possible combinations.\n\n\nlibrary(\"topmodels\")\n\n\nset.seed(6020)\n\n## three normal distributions X and observations x\nlibrary(\"distributions3\")\nX &lt;- Normal(mu = c(0, 1, 2), sigma = c(2, 1, 1))\nx &lt;- c(0, 0, 1)\n\n## evaluate crps\n## using infrastructure from scoringRules (based on closed-form analytic equations)\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.4673900 0.6024414 0.6024414\n\n## using general distribution method explicitly (based on numeric integration)\ncrps.distribution(X, x)\n\n[1] 0.4674058 0.6024482 0.6024482\n\n## analogously for Poisson distribution\nY &lt;- Poisson(c(0.5, 1, 2))\ncrps(Y, x)\n\n[1] 0.1631650 0.4762224 0.4991650\n\ncrps.distribution(Y, x)\n\n[1] 0.1631650 0.4762224 0.4991650",
    "crumbs": [
      "Procast infrastructure",
      "crps.distribution"
    ]
  },
  {
    "objectID": "man/plot.rootogram.html",
    "href": "man/plot.rootogram.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for rootograms of the class “rootogram” computed by link{rootogram}.\n\n## S3 method for class 'rootogram'\nplot(\n  x,\n  style = NULL,\n  scale = NULL,\n  expected = NULL,\n  ref = NULL,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  confint_nrep = 1000,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  axes = TRUE,\n  box = FALSE,\n  col = \"darkgray\",\n  border = \"black\",\n  lwd = 1,\n  lty = 1,\n  alpha_min = 0.8,\n  expected_col = 2,\n  expected_pch = 19,\n  expected_lty = 1,\n  expected_lwd = 2,\n  confint_col = \"black\",\n  confint_lty = 2,\n  confint_lwd = 1.75,\n  ref_col = \"black\",\n  ref_lty = 1,\n  ref_lwd = 1.25,\n  ...\n)\n\n## S3 method for class 'rootogram'\nautoplot(\n  object,\n  style = NULL,\n  scale = NULL,\n  expected = NULL,\n  ref = NULL,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  confint_nrep = 1000,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  legend = FALSE,\n  theme = NULL,\n  colour = \"black\",\n  fill = \"darkgray\",\n  size = 0.5,\n  linetype = 1,\n  alpha = NA,\n  expected_colour = 2,\n  expected_size = 1,\n  expected_linetype = 1,\n  expected_alpha = 1,\n  expected_fill = NA,\n  expected_stroke = 0.5,\n  expected_shape = 19,\n  confint_colour = \"black\",\n  confint_size = 0.5,\n  confint_linetype = 2,\n  confint_alpha = NA,\n  ref_colour = \"black\",\n  ref_size = 0.5,\n  ref_linetype = 1,\n  ref_alpha = NA,\n  ...\n)\n\n\n\n\n\nx, object\n\n\nan object of class rootogram.\n\n\n\n\nstyle\n\n\ncharacter specifying the syle of rootogram.\n\n\n\n\nscale\n\n\ncharacter specifying whether raw frequencies or their square roots (default) should be drawn.\n\n\n\n\nexpected\n\n\nShould the expected (fitted) frequencies be plotted?\n\n\n\n\nref\n\n\nlogical. Should a reference line be plotted?\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be drawn?\n\n\n\n\nconfint_level\n\n\nnumeric. The confidence level required.\n\n\n\n\nconfint_type\n\n\ncharacter. Should “tukey”, “pointwise”, or “simultaneous” confidence intervals be visualized?\n\n\n\n\nconfint_nrep\n\n\nnumeric. The repetition number of simulation for computing the confidence intervals.\n\n\n\n\nxlim, ylim, xlab, ylab, main, axes, box\n\n\ngraphical parameters.\n\n\n\n\ncol, border, lwd, lty, alpha_min\n\n\ngraphical parameters for the histogram style part of the base plot.\n\n\n\n\nexpected_col, expected_pch, expected_lty, expected_lwd, ref_col, ref_lty, ref_lwd, expected_colour, expected_size, expected_linetype, expected_alpha, expected_fill, expected_stroke, expected_shape, ref_colour, ref_size, ref_linetype, ref_alpha, confint_col, confint_lty, confint_lwd, confint_colour, confint_size, confint_linetype, confint_alpha\n\n\nFurther graphical parameters for the ‘expected’ and ‘ref’ line using either autoplot or plot.\n\n\n\n\n…\n\n\nfurther graphical parameters passed to the plotting function.\n\n\n\n\nlegend\n\n\nlogical. Should a legend be added in the ggplot2 style graphic?\n\n\n\n\ntheme\n\n\nWhich ‘ggplot2’ theme should be used. If not set, theme_bw is employed.\n\n\n\n\ncolour, fill, size, linetype, alpha\n\n\ngraphical parameters for the histogram style part in the autoplot.\n\n\n\nRootograms graphically compare (square roots) of empirical frequencies with expected (fitted) frequencies from a probability model. For the observed distribution the histogram is drawn on a square root scale (hence the name) and superimposed with a line for the expected frequencies. The histogram can be “standing” on the x-axis (as usual), or “hanging” from the expected (fitted) curve, or a “suspended” histogram of deviations can be drawn.\nRootograms are associated with the work of John W. Tukey (see Tukey 1977) and were originally proposed for assessing the goodness of fit of univariate distributions and extended by Kleiber and Zeileis (2016) to regression setups.\nAs the expected distribution is typically a sum of different conditional distributions in regression models, the “pointwise” confidence intervals for each bin can be computed from mid-quantiles of a Poisson-Binomial distribution (Wilson and Einbeck 2021). Corresponding “simultaneous” confidence intervals for all bins can be obtained via simulation from the Poisson-Binomial distributions. As the pointwise confidence intervals are typically not substantially different from the warning limits of Tukey (1972, p. 61), set at +/- 1, these “tukey” intervals are used by default.\nNote that for computing the exact “pointwise” intervals from the Poisson-Binomial distribution, the PoissonBinomial needs to be installed. Otherwise, a warning is issueed and a normal approximation is used.\n\nKleiber C, Zeileis A (2016). “Visualizing Count Data Regressions Using Rootograms.” The American Statistician, 70(3), 296–303. doi:10.1080/00031305.2016.1173590\nTukey JW (1972), “Some Graphic and Semigraphic Displays,” in Statistical Papers in Honor of George W. Snedecor, pp.293–316. Bancroft TA (Ed.). Iowa State University Press, Ames. Reprinted in William S. Cleveland (Ed.) (1988). The Collected Works of John W. Tukey, Volume V. Graphics: 1965–1985, Wadsworth & Brooks/Cole, Pacific Grove.\nTukey JW (1977). Exploratory Data Analysis. Addison-Wesley, Reading.\nWilson P, Einbeck J (2021). “A Graphical Tool for Assessing the Suitability of a Count Regression Model”, Austrian Journal of Statistics, 50(1), 1–23. doi:10.17713/ajs.v50i1.921\n\nrootogram, procast\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot rootogram\nrootogram(m1_lm)\n\n\n\n\n\n\n## customize colors\nrootogram(m1_lm, ref_col = \"blue\", lty = 2, pch = 20)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model\n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ### compute rootograms FIXME\n  #r2_lm &lt;- rootogram(m2_lm, plot = FALSE)\n  #r2_crch &lt;- rootogram(m2_crch, plot = FALSE)\n\n  ### plot in single graph\n  #plot(c(r2_lm, r2_crch), col = c(1, 2))\n}\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot rootogram as \"ggplot2\" graphic\nrootogram(m3_pois, plot = \"ggplot2\")\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## artificial data from negative binomial (mu = 3, theta = 2)\n## and Poisson (mu = 3) distribution\nset.seed(1090)\ny &lt;- rnbinom(100, mu = 3, size = 2)\nx &lt;- rpois(100, lambda = 3)\n\n## glm method: fitted values via glm()\nm4_pois &lt;- glm(y ~ x, family = poisson)\n\n## correctly specified Poisson model fit\npar(mfrow = c(1, 3))\nr4a_pois &lt;- rootogram(m4_pois, style = \"standing\", ylim = c(-2.2, 4.8), main = \"Standing\")\nr4b_pois &lt;- rootogram(m4_pois, style = \"hanging\", ylim = c(-2.2, 4.8), main = \"Hanging\")\nr4c_pois &lt;- rootogram(m4_pois, style = \"suspended\", ylim = c(-2.2, 4.8), main = \"Suspended\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.rootogram"
    ]
  },
  {
    "objectID": "man/plot.rootogram.html#s3-methods-for-plotting-rootograms",
    "href": "man/plot.rootogram.html#s3-methods-for-plotting-rootograms",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for rootograms of the class “rootogram” computed by link{rootogram}.\n\n## S3 method for class 'rootogram'\nplot(\n  x,\n  style = NULL,\n  scale = NULL,\n  expected = NULL,\n  ref = NULL,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  confint_nrep = 1000,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  axes = TRUE,\n  box = FALSE,\n  col = \"darkgray\",\n  border = \"black\",\n  lwd = 1,\n  lty = 1,\n  alpha_min = 0.8,\n  expected_col = 2,\n  expected_pch = 19,\n  expected_lty = 1,\n  expected_lwd = 2,\n  confint_col = \"black\",\n  confint_lty = 2,\n  confint_lwd = 1.75,\n  ref_col = \"black\",\n  ref_lty = 1,\n  ref_lwd = 1.25,\n  ...\n)\n\n## S3 method for class 'rootogram'\nautoplot(\n  object,\n  style = NULL,\n  scale = NULL,\n  expected = NULL,\n  ref = NULL,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"tukey\", \"pointwise\", \"simultaneous\"),\n  confint_nrep = 1000,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  legend = FALSE,\n  theme = NULL,\n  colour = \"black\",\n  fill = \"darkgray\",\n  size = 0.5,\n  linetype = 1,\n  alpha = NA,\n  expected_colour = 2,\n  expected_size = 1,\n  expected_linetype = 1,\n  expected_alpha = 1,\n  expected_fill = NA,\n  expected_stroke = 0.5,\n  expected_shape = 19,\n  confint_colour = \"black\",\n  confint_size = 0.5,\n  confint_linetype = 2,\n  confint_alpha = NA,\n  ref_colour = \"black\",\n  ref_size = 0.5,\n  ref_linetype = 1,\n  ref_alpha = NA,\n  ...\n)\n\n\n\n\n\nx, object\n\n\nan object of class rootogram.\n\n\n\n\nstyle\n\n\ncharacter specifying the syle of rootogram.\n\n\n\n\nscale\n\n\ncharacter specifying whether raw frequencies or their square roots (default) should be drawn.\n\n\n\n\nexpected\n\n\nShould the expected (fitted) frequencies be plotted?\n\n\n\n\nref\n\n\nlogical. Should a reference line be plotted?\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be drawn?\n\n\n\n\nconfint_level\n\n\nnumeric. The confidence level required.\n\n\n\n\nconfint_type\n\n\ncharacter. Should “tukey”, “pointwise”, or “simultaneous” confidence intervals be visualized?\n\n\n\n\nconfint_nrep\n\n\nnumeric. The repetition number of simulation for computing the confidence intervals.\n\n\n\n\nxlim, ylim, xlab, ylab, main, axes, box\n\n\ngraphical parameters.\n\n\n\n\ncol, border, lwd, lty, alpha_min\n\n\ngraphical parameters for the histogram style part of the base plot.\n\n\n\n\nexpected_col, expected_pch, expected_lty, expected_lwd, ref_col, ref_lty, ref_lwd, expected_colour, expected_size, expected_linetype, expected_alpha, expected_fill, expected_stroke, expected_shape, ref_colour, ref_size, ref_linetype, ref_alpha, confint_col, confint_lty, confint_lwd, confint_colour, confint_size, confint_linetype, confint_alpha\n\n\nFurther graphical parameters for the ‘expected’ and ‘ref’ line using either autoplot or plot.\n\n\n\n\n…\n\n\nfurther graphical parameters passed to the plotting function.\n\n\n\n\nlegend\n\n\nlogical. Should a legend be added in the ggplot2 style graphic?\n\n\n\n\ntheme\n\n\nWhich ‘ggplot2’ theme should be used. If not set, theme_bw is employed.\n\n\n\n\ncolour, fill, size, linetype, alpha\n\n\ngraphical parameters for the histogram style part in the autoplot.\n\n\n\nRootograms graphically compare (square roots) of empirical frequencies with expected (fitted) frequencies from a probability model. For the observed distribution the histogram is drawn on a square root scale (hence the name) and superimposed with a line for the expected frequencies. The histogram can be “standing” on the x-axis (as usual), or “hanging” from the expected (fitted) curve, or a “suspended” histogram of deviations can be drawn.\nRootograms are associated with the work of John W. Tukey (see Tukey 1977) and were originally proposed for assessing the goodness of fit of univariate distributions and extended by Kleiber and Zeileis (2016) to regression setups.\nAs the expected distribution is typically a sum of different conditional distributions in regression models, the “pointwise” confidence intervals for each bin can be computed from mid-quantiles of a Poisson-Binomial distribution (Wilson and Einbeck 2021). Corresponding “simultaneous” confidence intervals for all bins can be obtained via simulation from the Poisson-Binomial distributions. As the pointwise confidence intervals are typically not substantially different from the warning limits of Tukey (1972, p. 61), set at +/- 1, these “tukey” intervals are used by default.\nNote that for computing the exact “pointwise” intervals from the Poisson-Binomial distribution, the PoissonBinomial needs to be installed. Otherwise, a warning is issueed and a normal approximation is used.\n\nKleiber C, Zeileis A (2016). “Visualizing Count Data Regressions Using Rootograms.” The American Statistician, 70(3), 296–303. doi:10.1080/00031305.2016.1173590\nTukey JW (1972), “Some Graphic and Semigraphic Displays,” in Statistical Papers in Honor of George W. Snedecor, pp.293–316. Bancroft TA (Ed.). Iowa State University Press, Ames. Reprinted in William S. Cleveland (Ed.) (1988). The Collected Works of John W. Tukey, Volume V. Graphics: 1965–1985, Wadsworth & Brooks/Cole, Pacific Grove.\nTukey JW (1977). Exploratory Data Analysis. Addison-Wesley, Reading.\nWilson P, Einbeck J (2021). “A Graphical Tool for Assessing the Suitability of a Count Regression Model”, Austrian Journal of Statistics, 50(1), 1–23. doi:10.17713/ajs.v50i1.921\n\nrootogram, procast\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot rootogram\nrootogram(m1_lm)\n\n\n\n\n\n\n## customize colors\nrootogram(m1_lm, ref_col = \"blue\", lty = 2, pch = 20)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model\n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ### compute rootograms FIXME\n  #r2_lm &lt;- rootogram(m2_lm, plot = FALSE)\n  #r2_crch &lt;- rootogram(m2_crch, plot = FALSE)\n\n  ### plot in single graph\n  #plot(c(r2_lm, r2_crch), col = c(1, 2))\n}\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot rootogram as \"ggplot2\" graphic\nrootogram(m3_pois, plot = \"ggplot2\")\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## artificial data from negative binomial (mu = 3, theta = 2)\n## and Poisson (mu = 3) distribution\nset.seed(1090)\ny &lt;- rnbinom(100, mu = 3, size = 2)\nx &lt;- rpois(100, lambda = 3)\n\n## glm method: fitted values via glm()\nm4_pois &lt;- glm(y ~ x, family = poisson)\n\n## correctly specified Poisson model fit\npar(mfrow = c(1, 3))\nr4a_pois &lt;- rootogram(m4_pois, style = \"standing\", ylim = c(-2.2, 4.8), main = \"Standing\")\nr4b_pois &lt;- rootogram(m4_pois, style = \"hanging\", ylim = c(-2.2, 4.8), main = \"Hanging\")\nr4c_pois &lt;- rootogram(m4_pois, style = \"suspended\", ylim = c(-2.2, 4.8), main = \"Suspended\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.rootogram"
    ]
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "topmodels 0.3-0",
    "section": "",
    "text": "topmodels 0.3-0\n\nEntire package now leverages distributions3 for object-oriented computations on distributions fitted/predicted by various kinds of models.\nIn particular, procast() first obtains prodist() (probability distribution) and then applies the standard methods for computing densities, probabilities, quantiles, and moments.\nSimilarly, proresiduals() obtains the predicted distributions and compares with the newresponse() to obtain (randomized) quantile residuals by default. Alternatively, PIT residuals or Pearson residuals as well as raw response residuals are available. The function proresiduals() also replaces both pitresiduals() and qresiduals() which were provided by earler versions of topmodels.\nVia the same approach proscore() implements various kinds of scoring rules, in particular log-score (negative log-likelihood), (continuous) ranked probability score (CRPS), mean absolute error (MAE), mean squared error (MSE), and the Dawid-Sebastiani-Score (DSS). The standard log-likelihood (without sign change) is also available.\nFor the CRPS one can either leverage the functions from the scoringRules package (if available) or the new crps.distribution() method for numeric approximation/numeric integration to calculate the CRPS for univariate distributions. This is also used when no analytic solution is available in the scoringRules package.\nThe graphical functions rootogram(), pithist(), qqrplot(), wormplot(), and reliagram() are also switched to the new infrastructure based on distributions3, notably via procast() and proresiduals().\nThe pointwise and simultaneous confidence intervals in rootogram() now rely on the exact PoissonBinomial() distribution (now available in distributions3) rather than its binomial approximation.\nIn addition to pointwise and simultaneous confidence intervals for rootogram(), \"tukey\" confidence intervals are now available (and the default) which simply correspond to limits of -1 and 1 for hanging or suspended rootograms. For other flavors of rootograms these limits are transformed correspondingly.\nFor Q-Q residual plots in qqrplot() there are two methods for pointwise confidence intervals (\"beta\" and \"normal\") and two for simultaneous intervals (\"ks\" and \"ell\", the latter requiring package qqconf). Additionally, \"pointwise\" and \"simultaneous\" are simply aliases for the preferred corresponding methods \"beta\" and \"ell\", respectively.\nNew distribution/model interfaces were added first in topmodels but some subsequently moved to other packages: GAMLSS() is now in gamlss.dist, BAMLSS() is now in bamlss, and Empirical() is still in topmodels for now.\nNew wrapper function promodel() that adds the class \"promodel\" (for probabilistic model) to an existing model object so that predict() dispatches to procast() and residuals() dispatches to proresiduals(). This facilitates using model functionality based on the standard predict() and residuals() methods like marginaleffects.\n\n\n\ntopmodels 0.2-0\n\nNew version, presented at DAGStat 2022 and at useR! 2022 (together with distributions3).\nSome conceptual changes in the generation of graphical evaluation tools for both base R and ggplot2 style graphics.\nautoplot() builds now on newly written geom_*() and stat_*() functions.\n\n\n\ntopmodels 0.1-0\n\nFirst version, presented at useR! 2021.\nDiagnostic graphics for Q-Q plots of randomized residuals, PIT (probability integral transform) histograms, reliability diagrams, wormplots, and rootograms. All graphical evaluations can be rendered both in base R graphics and ggplot2.\nBasic probabilistic forecasting infrastructure for lm, crch, disttree and glm model classes. Not all families and forecasting types are fully supported yet."
  },
  {
    "objectID": "vignettes/illustration_artificial.html#summary",
    "href": "vignettes/illustration_artificial.html#summary",
    "title": "Illustration: Artificial Data",
    "section": "\n1 Summary",
    "text": "1 Summary\n\n\nWarning in qqrplot_plot(x[x$group == i, ], ...): infinite sample quantile\ndrawn; limited to +/- 100 for plotting\nWarning in qqrplot_plot(x[x$group == i, ], ...): infinite sample quantile\ndrawn; limited to +/- 100 for plotting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredictive distribution\nwell calibrated\ntoo skew to the left\ntoo skew to the right\ntails too light\ntails too heavy\nunderdispersed (underestimated variance)\noverdispersed (overestimated variance)\n\n\n\nResdiuals\nnormal\nright skewed\nleft skewed\nheavy tailed\nlight tailed\noverdispersed\nunderdispersed\n\n\nQ-Q plot\nbisecting line\npositive curvature (bends up the line at both ends)\nnegative curvature (bends down at both ends)\nreverse S-shape (dips below the line at the low end and rises above it at the high end)\nS-shape\ncrossing qqline from below (?)\ncrossing qqline from above ?\n\n\nWorm plot\nhorizontal line\nU-shape\ninverse U-shape\nS-shape on the left bent down\nS-shape on the left bent up\npositive slope\nnegative slope\n\n\nPIT histogram\nuniform\nskewed\nskewed\nsuperimposed U-shape\nsuperimposed inverse U-shape”\nU-shape\ninverse U-shape\n\n\nRootogram\nno deviations\n?\n?\nwave-like (underfitting in the tails and the center)\n?\n?\n?\n\n\nInterpretation\nno misspecifications\n?\n?\nvalues more extrem as expected\nvalues less extrem as expected\n?\n?"
  },
  {
    "objectID": "vignettes/illustration_artificial.html#artifical-data",
    "href": "vignettes/illustration_artificial.html#artifical-data",
    "title": "Illustration: Artificial Data",
    "section": "\n2 Artifical data",
    "text": "2 Artifical data\nThe following artificial data sets are simulated, with response values always depending on regressor variables, in order to obtain a realistic scenario for regression models:\n\nmake_residuals_plot &lt;- function(object, breaks = breaks) {\n\n  name &lt;- deparse(substitute(object))\n\n  set.seed(1)\n  pithist(object, breaks = c(0, 0.01, 1:9 / 10, 0.99, 1), main = name)\n\n  set.seed(1)\n  hist(qq &lt;- proresiduals(object), freq = FALSE,\n    main = sprintf(\"Histogram of proresiduals(%s)\", name), xlab = \"Q-Q residuals\")\n  curve(dnorm, from = min(qq), to = max(qq), col = 2, add = TRUE)\n  legend(\"topright\", \"std. norm\", lty = 1, col = 2, bty = \"n\")\n\n  set.seed(1)\n  boxplot(data.frame(\"Q-Q residuals\" = proresiduals(object), \"std. norm\" = rnorm(length(proresiduals(object)))))\n}\n\nmake_topmodels_plot &lt;- function(object) {\n  topmodels(object, which = c(1:2, 4:5), ask = FALSE, spar = FALSE)\n}\n\nset.seed(0)\n\n## regressors\nd &lt;- data.frame( \n  x = runif(500, -1, 1),\n  z = runif(500, -1, 1)\n)\n\n## parameters\nd &lt;- transform(d,\n  lambda = exp(1 + 0.5 * x),\n  theta = 2,\n  mu = 50 + 22 * x,\n  sigma = 22,\n  sigmaz = exp(3 + 1 * z)\n)\n\n## responses\nd &lt;- transform(d,\n  ynorm = rnorm(500, mean = mu, sd = sigma),\n\n  yhnorm = rnorm(500, mean = mu, sd = sigmaz),\n  ytnorm = crch::rtnorm(500, mean = mu, sd = sigma, left = 0),\n  ycnorm = crch::rcnorm(500, mean = mu, sd = sigma, left = 0, right = 100),\n\n  yt = mu + sigma * rt(500, df = 4),\n  ylaplace = mu + rmutil::rlaplace(500, s = sigma),\n  yrskew = sn::rsn(500, xi = mu, omega = sigma, alpha = 5, tau = 0),\n  ylskew = sn::rsn(500, xi = mu, omega = sigma, alpha = -5, tau = 0),\n  yunif = mu + sigma * runif(500, min = -1, max = 1),\n\n  ypois = rpois(500, lambda = lambda),\n  ynegbin = rnbinom(500, mu = lambda, size = theta),\n  yzip = ifelse(runif(500) &lt; 0.25, 0, rpois(500, lambda = lambda))\n)"
  },
  {
    "objectID": "vignettes/illustration_artificial.html#continuous-data",
    "href": "vignettes/illustration_artificial.html#continuous-data",
    "title": "Illustration: Artificial Data",
    "section": "\n3 Continuous data",
    "text": "3 Continuous data\n\n3.1 Homoscedastic normal\nAs a reference, a linear normal model is fitted to simulated normally distributed data without conditional heteroscedasticity.\n\n## correct model fit\nm1 &lt;- lm(ynorm ~ x, data = d)\n\n\n\n\n\n\n\n\n\nThe model fit experiences no misspecifications resulting in a well calibrated predictive distribution (compare the case “well calibrated” in the summary plot of Graphical Evaluation: Methodology):\n\nThe rootogram shows that the observed and expected frequencies match rather well, without any clear patterns of departure, hence, the deviations between observed and predicted frequences are very small for most values.\nThe PIT histogram is uniform, corresponding to a well calibrated predicitve distribution.\nThe Q-Q residuals plot shows most points are located along the bisecting line.\nThe worm plot is within its confidence intervals and shows only slight deviations from a horizontal line (FIXME: why not completely horizontal).\n\n3.2 Conditional heteroscedasticity\nIn the “conditional heteroscedasticity” example, two models are fitted to simulated data from the normal distribution where both the location and scale parameters depend on a regressor. The model m2 estimated with lm() cannot account for conditional heteroscedasticity, unlike the model m3 which is fitted with crch().\n\n## not accounting for heteroscedasticity\nm2 &lt;- lm(yhnorm ~ x, data = d)\n\n### accounting for heteroscedasticity\nm3 &lt;- crch(yhnorm ~ x | z, data = d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot accounting for conditional heteroscedasticity results here in a model fit where the tails of the distribution are too light (compare the case “tails too light” in the summary plot of Graphical Evaluation: Methodology):\n\nThis leads to underfitting the observed values in the tails and the center of the predictive distribution, whereas the values in between are overfitted, which is visible as a typical wave-like pattern in the rootogram. This indicates some overdispersion in the data wich is not accounted for in the model.\nIn the PIT histogram, only the underfitting in the middle of the predictive distribution is observed, indicating that more values occur here than expected. A possibly expected U-shaped PIT histogram, typically corresponding to a underdispersive model fit, is not visible here; hence, the PIT histogram is obviously not well suited with the usual number of bins to detect the significant probability mass in the outermost tails of the distribution.\nIn the Q-Q residuals plot, due to a transformation to the normal distribution, the tails are more widely spread, whereby the deviations correctly show that the observed values are more extreme than expected. This leads to a so-call reverse S-shape of the Q-Q plot.\nIn the wormplot, the misshape is further emphasized by plotting the deviation between the empirical and theoretical quantiles on the Y-axis, which results in a S-shape pattern bending down towards the left.\n\n3.3 Censoring (0, 100)\nTo investigate the graphical evaluation tools under the misspecification of not accounting for censoring in the estimation, homoscedastic normally distributed data are simulated with censoring at 0 and 100. The model m4 fitted with lm() cannot account for the censored data, contrary to the model m5 estimated with crch().\n\n## not accounting for censoring\nm4 &lt;- lm(ycnorm ~ x, data = d)\n\n## accounting for censoring\nm5 &lt;- crch(ycnorm ~ x | 1, data = d, left = 0, right = 100)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot accounting for the censoring at 0 and 100 leads to an incorrect distributional assumption in the tails of the predictive distribution, similar to the case “tails too heavy” discussed in Graphical Evaluation: Methodology:\n\nIn the rootogram, this can be seen by the clear lack of fit for low and high values due to not accounting for the point masses at the censoring points; hence, the values at the censoring points are both underfitted (FIXME: Right censoring in the rootogram, adapt default breaks).\nIn contrast to the rootogram, the misspecification is barely visible in the PIT histogram and only weakly visible in the Q-Q residual plot in the form of some deviations at both ends, indicating that the values are a bit less extrem than expected.\nIn the worm plot, the drift at both ends towards the upper left corner and the lower right corner, respectively, indicates that the observed values are not as extreme as expected. This is in agreement with the pattern “tails too heavy” discussed in Graphical Evaluation: Methodology, but without the typical S-shape pattern in the worm plot.\n\n3.4 Truncation (&gt; 0)\nHere, the homoscedastic normally distributed response values are truncated at zero. The model m6 fitted with lm() cannot account correctly for this, contrary to the model m7 estimated with crch().\n\n## not accounting for truncation\nm6 &lt;- lm(ytnorm ~ x, data = d)\n\n# not accounting for truncation\nm7 &lt;- trch(ytnorm ~ x | 1, data = d, left = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot accounting for the truncation at 0 leads to an incorrect distributional assumption in the lower tail of the predictive distribution:\n\nIn the rootogram, the lower values within the two first bins are clearly underfitted by the model. Howeverr, for the model correctly accounting for the truncation, some underfitting is also present, indicating a slight misfit of the model (FIXME: Check again if all correct).\nAs for the example with censored data, the incorrect model fit due to not accounting for truncation is not visible in the PIT histogram and only weakly visible in the Q-Q residuals plot.\nIn the worm plot, there is a weak S-shaped pattern bending upward towards the left, suggesting that the tails of the predictive distribution are too heavy. At least for for the lower tail, this is in line with the misspecification due to truncation. (FIXME: Why is it in the right part?)\n\n3.5 Student-t distribution (df = 4)\nIn the following example, data is simulated from the student-t distribution with 4 degrees of freedom. The model m8 incorrectly assumes normally distributed data, while the model m9 correctly incorporates t-distributed data.\n\n## not accounting for t_4 distributed data\nm8 &lt;- lm(yt ~ x, data = d)\n\n## accounting for t_4 distributed data\nm9 &lt;- crch(yt ~ x | 1, data = d, dist = \"student\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot accounting for the underlying student-t response distribution (df = 4), which is characterized by heavier tails than the normal distribution, leads to a model fit where the tails of the predictive distribution are to light (compare the previous example with “conditional heteroscedasticity” and the case “tails too light” in the summary plot of Graphical Evaluation: Methodology):\n\nThis leads to underfitting the values in the tails and the center of the predictive distribution, whereas the values in between are overfitted, which is visible as a typical wave-like pattern in the rootogram. This indicates some overdispersion in the data wich is not accounted for in the model.\nIn the PIT histogram, even if the first bin is slightly higher, mostly the underfitting in the middle of the predictive distribution is observed, indicating that more values occur here than expected. A possibly expected U-shaped PIT histogram, corresponding to a underdispersive model fit, is not detectable, since the heavier tails concern only few values, which are not sufficiently resolved by the usual bin width within the PIT.\nIn the Q-Q residuals plot, due to a transformation to the normal distribution, the values in the tails are more widely spread, correctly showing that the observed values are more extreme than expected. This leads to a so-call reverse S-shape of the Q-Q plot.\nIn the wormplot, the misshape is further emphasized by plotting the deviation between the empirical and theoretical quantiles on the Y-axis, which results in a S-shape pattern bending down towards the left.\n\n3.6 Skewness\nIn the example “skewness”, both right-skewed and left-skewed data are simulated, which are not correctly accounted for by the linear models m10 and m11.\n\n## not accounting for right skewed data\nm10 &lt;- lm(yrskew ~ x, data = d)\n\n## not accounting for left skewed data\nm11 &lt;- lm(ylskew ~ x, data = d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot accounting for right-skewed or left-skewed data leads to a estimated model with a predictive distribution which is too skewed to the left or right, respectively (compare the cases “too skew to the left/right” in the summary plot of Graphical Evaluation: Methodology):\n\nIn the rootogram for the right-skewed and left-skewed data, a clear underfitting of higher and lower values at the ends can be observed, respectively. In other words, the freqeuncies of the observed values are higher than the expected frequencies resulting from estimating a normal distribution without accounting for skewness.\nIn the PIT histogram the misspecification is not clearly detectable, but generally a skewed PIT histograms, as seen here, indicates that the central tendencies of the fit must be biased.\nThe Q-Q residual plots are positively and negatively curved for right-skewed and left-skewed data, respectively. For right-skewed data, corresponding to a model fit that is too skewed to the left, due to the high frequency of low values in the lower range, the empirical quantile residuals increase more slowly than the standard normal quantiles. However, at the upper end of the distribution, the empirical quantiles increase faster than the standard quantiles. In total, the Q-Q residual plot must be positively curved. For the left-skewed data, corresponding to a model fit that is too skewed to the right, the opposite is true.\nThe worm plot shows the typical U-shape or reverse U-shape for the model fits that are too skewed to the left or right, corresponding to right and left skewed response values.\n\n3.7 Other misspecified distribution: uniform, laplace\nIn the following, two further examples are shown, one with simulated data from a uniform distribution, the second with simulated data from a Laplace distribution. For both data sets, a linear model is estimated without considering the true underlying response distribution.\n\n## not accounting for uniform distributed data\nm12 &lt;- lm(yunif ~ x, data = d)\n\n## not accounting for laplace distributed data\nm13 &lt;- lm(ylaplace ~ x, data = d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniformly distributed data generally have lighter tails than the normal distribution (depending on the lower and upper bounds, of course), while the Laplace distribution here is characterized by heavier tails and a higher probability mass in the center of the distribution than in the normal distribution. Therefore, the uniformly and Laplace distributed data lead to misspecified predictive distributions where the tails are either too heavy or too light, respectively (compare the previous examples “conditional heteroscedasticity” and “Student-t distribution”, where the tails are too light, as well aa the cases “tails too light/heavy” in the summary plot of Graphical Evaluation: Methodology).\nHere, uniformly distributed data result in a misspecifed model where the tails of the predictive distribution are too heavy:\n\nIn the rootogram, the overfitting of the values at both ends of the predictive distribution is clearly visible. Here, the observed frequencies are much lower than the expected frequencies, which is consistent with the light tailed distributed data fitted by a linear normal model. The present underfitting of intermediate values in the rootogram likely relates to values drawn from the uniform distribution, where a higher probability mass exists than in the normal distribution.\nIn the PIT histogram, the misspecifications at the tails of the underlying distribution are are not visible. In addition, the PIT focuses on the difference between the probability masses of the uniform distribution and the normal distribution located in the middle on both tails. This superimposes a perhaps expected inverted U-shape, which would match the underdispersion in the data corresponding to the overdispersed model fit.\nAs before in the Q-Q residuals plot, the transformation of the values to the normal distribution spreads the tails further, correctly showing that the observed values are less extreme than expected. This leads to a pronounced S-shape of the Q-Q plot.\nIn the wormplot, the misshape is further emphasized by plotting the deviation between the empirical and theoretical quantiles on the Y-axis, resulting in a distinct S-shape pattern, bending upwards on the left side.\n\nHere, Laplace distributed data result in a misspecifed model where the tails of the predictive distribution are too light:\n\nThe values in the tails and the center of the predictive distribution are underfitted, whereas the values in between are overfitted. This is visible as a typical wave-like pattern in the rootogram.\nIn the PIT histogram, even if the last bin is in this example slightly higher, mostly the underfitting in the middle of the predictive distribution is observed, indicating that more values occur here than expected. A possibly expected U-shaped PIT histogram is not detectable, since the heavier tails concern only few values, which are not sufficiently resolved by the usual bin width within the PIT histogram.\nIn the Q-Q residuals plot, due to a transformation to the normal distribution, the tails are more widely spread, correctly showing that the observed values are more extreme than expected. This leads to a pronounced reverse S-shape of the Q-Q plot.\nIn the wormplot, the misshape is further emphasized by plotting the deviation between the empirical and theoretical quantiles on the Y-axis, which results in a clear S-shape pattern, bending down towards the left."
  },
  {
    "objectID": "vignettes/illustration_artificial.html#count-data",
    "href": "vignettes/illustration_artificial.html#count-data",
    "title": "Illustration: Artificial Data",
    "section": "\n4 Count data",
    "text": "4 Count data\n\n4.1 Poisson\nAs a reference, first a Poisson model is fitted to Poisson distributed data.\n\n## correct model fit\nm14 &lt;- glm(ypois ~ x, data = d, family = poisson)\n\n\n\n\n\n\n\n\n\nThe model fit experiences no misspecifications resulting in a well calibrated predictive distribution (compare the case “well calibrated” in the summary plot of Graphical Evaluation: Methodology):\n\nThe rootogram shows that the observed and expected frequencies match rather well, without any clear patterns of departure indicating a rather good fit.\nThe PIT histogram is uniform, correspoding to a well calibrated predicitve distribution.\nThe Q-Q residuals plot shows most points are located along the bisecting line.\nThe worm plot is within its confidence intervals and shows only slight deviations from a horizontal line (FIXME: why not completely horizontal).\n\n4.2 Negative binomial\nTwo models are fitted to simulated data from a negative binomial distribution. In model m15 an underlying Poisson distribution is incorrectly assumed, in model m16 the negative binomial distribution is correctly accounted for by using glm.nb().\n\n## misspecified distribution leading to an overdispersed predictive distribution\nm15 &lt;- glm(ynegbin ~ x, data = d, family = poisson)\n\n## correct distributional assumption\nm16 &lt;- MASS::glm.nb(ynegbin ~ x, data = d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe wrong distribution assumption results in not accounting for the overdispersion in the data, which corresponds to an underdispersed predictive disitriubtion (compare the case “underdispersed” in the summary plot of Graphical Evaluation: Methodology):\n\nIn the rootogram, the wave-like pattern around the horizontal reference line indicates that low and higher values are clearly underfitted, while the values in between are overfitted. This is in agreement with an uderdispersed model, underestimating the underlying variance. The significant lack of fit for 0 could be an additional indication of excess zeros.\nThe typical U-shape in the PIT histogram supports that the model is underdispersed: The values attained by the predictive CDF at the observations are located with increased frequency at both ends of the CDF.\nThe Q-Q residuals plot shows that many observed values are more extreme than expected, i.e., the data exhibit considerable overdispersion that is not accounted for in the model fit. Probably due to using positive count data, this is more ponounced for positive quantile residuals shown in the upper right part of the Q-Q plot.\nIn the worm plot, the positive slope corresponds to the underdispersed predictive distribution.\n\n4.3 Zero-inflation\nTwo models are fitted to simulated count data with excess zeros; the model m17 is unable to account for zero inflation, while model m18 fits a zero-inflation regression model that combines a point mass at zero with a Poisson model for higher counts and therefore fits the excess zeros perfectly.\n\n## not accouting for zero inflation\nm17 &lt;- glm(yzip ~ x, data = d, family = poisson)\n\n## accouting for zero inflation\nm18 &lt;- pscl::zeroinfl(yzip ~ x | 1, data = d, dist = \"poisson\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExcess zeros are inevitably linked to overdispersion, so the misspecified model fit without accounting for zero inflation has similar patterns to an underdispersive predictive distribution (compare the previous example with “negative binomial” distributed data and “underdispersed” in the summary plot of Graphical Evaluation: Methodology):\n\nIn the rootogram, the wave-like pattern indicates that excess zeros are clearly underfitted, high values are slightly underfitted and values in between are overfitted. The significant lack of fit for 0 corresponds well with the excess zeros.\nThe typical U-shape in the PIT histogram supports that the model is underdispersed.\nThe Q-Q residuals plot indicates that some observed values are more extreme than expected, i.e., the data exhibit overdispersion that is not accounted for in the model fit.\nIn the worm plot, the positive slope corresponds to the underdispersed predictive distribution. The reverse trends at the outer tails of the wormplot are due to (FIXME: why?)."
  },
  {
    "objectID": "vignettes/illustration_artificial.html#references",
    "href": "vignettes/illustration_artificial.html#references",
    "title": "Illustration: Artificial Data",
    "section": "\n5 References",
    "text": "5 References"
  },
  {
    "objectID": "vignettes/graphics.html#overview",
    "href": "vignettes/graphics.html#overview",
    "title": "Graphics for Assessing Goodness of Fit",
    "section": "\n1 Overview",
    "text": "1 Overview\nMarginal: Rootogram\nConditional: PIT histogram, Q-Q plot of randomized residuals, worm plot.\nNotation: Previous section\nApplication: FIFA 2018 goals\n\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)"
  },
  {
    "objectID": "vignettes/graphics.html#rootogram",
    "href": "vignettes/graphics.html#rootogram",
    "title": "Graphics for Assessing Goodness of Fit",
    "section": "\n2 Rootogram",
    "text": "2 Rootogram\nThe rootogram is a graphical tool for assessing the goodness of fit in terms of mariginal calibration of a parametric univariate distributional model, with estimated parameters \\(\\hat{\\boldsymbol{\\theta}}_{i} = (\\hat{\\theta}_{i1},\n\\ldots, \\hat{\\theta}_{iK})^\\top\\) and \\(f( \\cdot )\\) desribing the density or probability mass function. Rootograms evaluate graphically whether observed frequencies \\(\\text{obs}_j\\) match the expected frequencies \\(\\text{exp}_j\\) by plotting histogram-like rectangles or bars for the observed frequencies and a curve for the fitted frequencies, both on a square-root scale. In the form presented here, it was implemented by Kleiber and Zeileis (2016) building on work of Tukey (1977).\nIn the most general form, given an observational vector of a random variable \\(y_i (i = 1, \\ldots, n)\\) which is divided into subsets by a set of breakpoints \\(b_0,\nb_1, b_2, \\dots~\\), the observed and expected frequencies are given by\n\\[\\text{obs}_j = \\sum_{i=1}^{n}w_{i} I(y_i \\in (b_j, b_{j+1}]),\\] \\[\\text{exp}_j = \\sum_{i=1}^{n}w\\{F(b_{j+1} |\n  \\hat{\\boldsymbol{\\theta}}_{i}) - F(b_{j} | \\hat{\\boldsymbol{\\theta}}_{i})\\},\\]\nwith \\(F( \\cdot )\\) being the CDF of the modeled distributional model \\(f( \\cdot )\\) and \\(w_i\\) being optional observation-specific weights. Whereby, the weights are typically needed either for survey data or for situations with model-based weights (Kleiber and Zeileis 2016).\nFor a discrete variable \\(y_i\\), the observed and expected frequencies can be simplified and are given for each integer \\(j\\) by\n\\[\\text{obs}_j = \\sum_{i=1}^{n}I(y_i = j),\\] \\[\\text{exp}_j = \\sum_{i=1}^{n}f(j | \\hat{\\boldsymbol{\\theta}}_{i}),\\]\nwith the indicator variable \\(I( \\cdot )\\) (Kleiber and Zeileis 2016). As rootograms are best known for count data, the latter form is quite common.\nDifferent styles of rootograms have been proposed and are extensively discussed in Kleiber and Zeileis (2016). As default, they propose a so called “hanging” rootogram, which aligns all deviations along the horizontal axis, as the rectangles are drawn from \\(\\sqrt{exp_j}\\) to \\(\\sqrt{exp_j} - \\sqrt{obs_j}\\), so that they “hang” from the curve with the expected frequencies \\(\\sqrt{exp_j}\\).\nThe concept of comparing observed and expected frequencies graphically was also introduced in the seminal work on assessing calibration and sharpness for a predictive probalilty model by Gneiting, Balabdaoui, and Raftery (2007) and, building on this, applied to count data by Czado, Gneiting, and Held (2009). However, since in both cases either the deviations or the expected and observed frequencies are presented only as lines connecting the respective frequencies, deviations are more difficult to detect compared to the rootograms introduced by Tukey (1977) and further enhanced by Kleiber and Zeileis (2016).\n\nrootogram(m)"
  },
  {
    "objectID": "vignettes/graphics.html#pit-histogram",
    "href": "vignettes/graphics.html#pit-histogram",
    "title": "Graphics for Assessing Goodness of Fit",
    "section": "\n3 PIT histogram",
    "text": "3 PIT histogram\nAs described in the introduction, to check for probabilistic calibration of a regression model, Dawid (1984) proposed the use of the probability integral transform (PIT) which is simply the predictive cumulative distribution function (CDF) evaluated at the observations. PIT values have been used under various names (e.g., Smith 1985; Dunn and Smyth 1996; Brockwell 2007) , to emphasize their similar properties to residuals we follow Warton, Thibaut, and Wang (2017) and refer to them as PIT residuals from now on.\nFor a continuous random variable \\(y_i (i = 1, \\ldots, n)\\), PIT residuals are defined as\n\\[u_i = F(y_i | \\, \\hat{\\boldsymbol{\\theta}}_i)\\]\nwhere \\(F( \\cdot )\\) denotes the CDF of the modeled distribution \\(f( \\cdot )\\) with estimated parameters \\(\\hat{\\boldsymbol{\\theta}}_{i} = (\\hat{\\theta}_{i1},\n\\ldots, \\hat{\\theta}_{iK})^\\top\\). If the estimated model is a good approximation to the true data generating process, the observation will be drawn from the predictive distribution and the PIT residuals \\(u_i\\) are approximately uniformly distributed on \\([0, 1]\\). Plotting the histogram of the PIT residuals and checking for uniformity is therefore a common empirical way of checking for calibration (Diebold, Gunther, and Tay 1998; Gneiting, Balabdaoui, and Raftery 2007). Whereas, deviations from uniformity point to underlying forecast errors and model deficiencies: U-shaped histograms refer to underdispersed predictive distributions, inverted U-shaped histograms to overdispersion, and skewed histograms suggest that central tendencies must be biased (Gneiting, Balabdaoui, and Raftery 2007; Czado, Gneiting, and Held 2009).\nWhen considering discrete response distributions or distributions with a discrete component, e.g., in case of censoring, for a random discrete variable \\(y_i\\) the PIT \\(u_i\\) can be generated as a random draw from the interval \\([F(y_i\n- 1 | \\, \\hat{\\boldsymbol{\\theta}}_i), F(y_i | \\,\n  \\hat{\\boldsymbol{\\theta}}_i)]\\). Even if this leads to some randomness in the graphical representation of PIT residuals, for cases with a high number of observations the impact on the graphical evaluation when repeating the calculations (i.e. drawing new values \\(u_i\\)) is typically rather small. For small data sets, we recommend to increase the number of random draws which significantly reduces the randomness in the graphical display.\nAlternatively, a nonrandom PIT histogram was introduced by Czado, Gneiting, and Held (2009), where rather than building on randomized pointwise PIT resdiuals \\(u_i\\) the expected fraction of the CDF along the interval \\([F(y_i\n- 1 | \\, \\hat{\\boldsymbol{\\theta}}_i), F(y_i | \\,\n  \\hat{\\boldsymbol{\\theta}}_i)]\\) is used. This is asympotically equivalent to drawing an infinite number of random PIT residuals.\n\npithist(m)"
  },
  {
    "objectID": "vignettes/graphics.html#q-q-residuals-plot",
    "href": "vignettes/graphics.html#q-q-residuals-plot",
    "title": "Graphics for Assessing Goodness of Fit",
    "section": "\n4 Q-Q residuals plot",
    "text": "4 Q-Q residuals plot\nQuantile residuals are simply the inverse cumulative distribution function of a standard normal distribution \\(\\Phi^{-1}\\) evaluated at the PIT residuals \\(u_i (i\n= 1, \\ldots, n)\\), hence, they can be defined as\n\\[\\hat{r}_i = \\Phi^{-1}(F(y_i | \\, \\hat{\\boldsymbol{\\theta}}_{i})) =\n  \\Phi^{-1}(u_i),\\]\nwhere \\(F( \\cdot )\\) again denotes the cumulative distribution function (CDF) of the modeled distribution \\(f( \\cdot )\\) with estimated parameters \\(\\hat{\\boldsymbol{\\theta}}_{i} = (\\hat{\\theta}_{i1},\n\\ldots, \\hat{\\theta}_{iK})^\\top\\) (Dunn and Smyth 1996). As before, for discrete or partly discrete responses, the approach includes some randomization to achieve continuous \\(u_i\\) values; quantile residuals are therefore often referred to as randomized quantile residuals in the literature (Dunn and Smyth 1996).\nIn case of a correct model fit, the values \\(u_i\\) are uniformly distributed on the unit interval and the Q-Q residuals should at least approximately be standard normally distributed. Hence, to check for normality, quantile residuals can be graphically compared to theoretical quantiles of the standard normal distribution, where strong deviations from the bisecting line indicate a misspecified model fit.\nMathematically, Q-Q plot consists of the tuples\n\\[(z_{(1)},  \\hat{r}_{(1)}), \\ldots,  (z_{(n)},  \\hat{r}_{(n)}),\\]\nwhere \\(\\hat{r}_{(i)}\\) denotes the \\(i\\)th order statistic of the quantile residuals, so that \\(\\hat{r}_{(1)} \\leq \\hat{r}_{(2)} \\cdot \\leq \\hat{r}_{(n)}\\), and \\(z_{(i)}\\) is the ordered statistics from the respective standard normal quantiles \\(\\Phi^{-1}( p_i)\\), evaluated at the cumulative proportion \\(p_i = (i -\n0.5) / n\\) for \\(n\\) greater \\(10\\). This graphical evaluation is well known as normal probability plot or normal Q-Q plot (Hoaglin 2006). Due to the transformation of the PIT residuals \\(u_i\\) to the normal scale, their extreme values are more widely spread, so that normal Q-Q diagrams are better suited than, for example, PIT histograms to detect violations of the distribution assumption within its tails. An additional possible advantage of Q-Q plots is that they avoid the necessity of defining breakpoints as typically needed for histogram style evaluations (Klein et al. 2015).\nBut Q-Q plots can also be applied to check if residuals follow any other known distribution, by employing any other inverse cumulative distribution function of interest instead of \\(\\Phi^{-1}\\) in the computation and comparing the quantile residuals \\(\\hat{r}_i\\) to the respective theoretical quantiles. This is called than a theoretical quantile-quantile plot or Q-Q plot for short (Friendly 1991).\n\nqqrplot(m, confint = \"line\")"
  },
  {
    "objectID": "vignettes/graphics.html#worm-plot",
    "href": "vignettes/graphics.html#worm-plot",
    "title": "Graphics for Assessing Goodness of Fit",
    "section": "\n5 Worm plot",
    "text": "5 Worm plot\nAs in Q-Q plots, small too medium deviations can be quite hard to detect, untilting the plot by subtracting the theoretical quantiles, makes detecting pattern of departure from a now horizontal line much easier. Mathematically, therefore, the tuples in the plot are\n\\[(z_{(1)},  \\hat{r}_{(1)} - z_{(1)}), \\ldots,  (z_{(n)},  \\hat{r}_{(n)} - z_{(n)}),\\]\nwhere as before, where \\(\\hat{r}_{(i)}\\) denotes the order statistic of the empirical quantile residuals and \\(z_{(i)}\\) the ordered statistics of the respective standard normal quantiles. This so-called de-trended Q-Q plot (Friendly 1991) is best known by the application of Buuren and Fredriks (2001), and is therefore usually referred to as worm plot according to their naming.\n\nwormplot(m, confint = \"line\")"
  },
  {
    "objectID": "vignettes/goodness_of_fit.html#introduction",
    "href": "vignettes/goodness_of_fit.html#introduction",
    "title": "Goodness of Fit of Probabilistic Regression Models",
    "section": "\n1 Introduction",
    "text": "1 Introduction\nOver the last decades there has been an increasing interest in regression models that not only capture the mean of a dependent variable but model its entire probability distribution (Stasinopoulos and Rigby 2007; Klein et al. 2015; Hothorn, Kneib, and Bühlmann 2014). In the simplest case this could be a generalized linear model (GLM, Nelder and Wedderburn 1972; McCullagh and Nelder 1989) where higher moments of the probability distribution co-vary with the expectation. Instead, multiple distribution parameters could also be linked to explanatory variables as in distributional regression (Klein et al. 2015) or generalized additive models of location, scale, and shape (Stasinopoulos and Rigby 2007). Moreover, many other flexible modeling techniques yield fitted distributions, including transformation models (Hothorn, Kneib, and Bühlmann 2014), Bayesian modeling (Umlauf, Klein, and Zeileis 2018), machine learning approaches (e.g., Rasp and Lerch 2018), and many others.\nFor assessing the goodness of fit of such probabilistic regression models, (proper) scoring rules (Gneiting and Raftery 2007) are widely used, e.g., using the log-likelihood (also known as the log-score) or the continuous ranked probability score (CRPS, Gneiting and Raftery 2007). In addition to such numerical summaries, visualizations capturing the goodness of fit are also of interest as they may also be able to shed some more light on the sources of a potential lack of fit.\nWhile various visualizations have been suggested in the literature and implemented in software packages, a unified framework for these visualizations has not yet been established. Therefore, we investigate the following questions:\n\nWhat are useful elements of such visualizations?\nWhat are relative (dis)advantages?\n\nThe insights help us to establish a unified framework that facilitates:\n\nAdoption of these visualizations for a broad range of models/distributions.\nUnderstanding what the graphics have in common and what sets them apart.\nDemonstration of strengths and weaknesses in uncovering sources of lack of fit.\nFine-tuning the graphics for certain models or data sets."
  },
  {
    "objectID": "vignettes/goodness_of_fit.html#notation",
    "href": "vignettes/goodness_of_fit.html#notation",
    "title": "Goodness of Fit of Probabilistic Regression Models",
    "section": "\n2 Notation",
    "text": "2 Notation\nIn this article, we focus on several graphical diagnostic tools to assess the calibration of a probabilistic forecast \\(F( \\cdot | \\boldsymbol{\\theta}_{i})\\), issued in form of a predictive distribution \\(f( \\cdot |\n\\boldsymbol{\\theta}_{i})\\). Given observations \\(y_i (i = 1, \\ldots, n)\\), we assume a set of observation-specific fitted parameters \\(\\hat{\\boldsymbol{\\theta}}_{i}\n= (\\hat{\\theta}_{i1}, \\ldots, \\hat{\\theta}_{iK})^\\top\\), where the estimation may have been performed on the same observations \\(i = 1, \\ldots, n\\) (i.e., corresponding to an in-sample assessment) or on a different data set (i.e., corresponding to an out-of-sample evaluation). The estimation procedure itself can be either fully parametric or semi-parametric, as long as fitted parameters \\(\\hat{\\boldsymbol{\\theta}}_{i}\\) exist for all observations of interest. However, since the uncertainty in the estimation of the parameters is not accounted for, small deviations from asymptotic theoretical properties will be apparent in all graphical displays due to some sampling variation.\nAccording to the seminal work of Gneiting, Balabdaoui, and Raftery (2007), probabilistic forecasts aim to maximize the sharpness of the predictive distributions subject to calibration. Calibration here refers to the statistical concordance between the forecast and the observation, and is thus a joint property of the forecast and observation. Sharpness, on the other hand, is a property of the forecast only and indicates how concentrated a predictive distribution is. In general, the more concentrated the sharper the forecast. In the assessment whether probabilistic predictions are calibrated, we further distinguish between marginal and probabilistic calibration.\n\nlibrary(\"topmodels\")\nlibrary(\"ggplot2\")\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\nrootogram(m, style = \"standing\", scale = \"raw\", fitted = FALSE, xlab = \"Goals\")\nset.seed(0)\npithist(m, type = \"random\", nsim = 10,\n  ref = FALSE, confint = FALSE, simint = FALSE, fill = \"darkgray\", alpha = 1, col = \"black\")\nset.seed(0)\npithist(m, type = \"random\", nsim = 10, trafo = qnorm,\n  xlim = c(-3, 3), xlab = \"Randomized quantile residuals\",\n  ref = FALSE, confint = FALSE, simint = FALSE, fill = \"darkgray\", alpha = 1, col = \"black\")"
  },
  {
    "objectID": "vignettes/goodness_of_fit.html#marginal-calibration-observed-vs.-expected-frequencies",
    "href": "vignettes/goodness_of_fit.html#marginal-calibration-observed-vs.-expected-frequencies",
    "title": "Goodness of Fit of Probabilistic Regression Models",
    "section": "\n3 Marginal calibration: Observed vs. expected frequencies",
    "text": "3 Marginal calibration: Observed vs. expected frequencies\nAdvantage: Scale of observations is natural, direct interpretation.\nDisadvantage: Needs to be compared with a combination of distributions.\nMarginal calibration is generally concerned with whether the oberseved frequencies match the frequencies expected by the model. For discrete observations, frequencies for the observations themselves can be considered; for continuous observations or more generally, frequencies for intevals of observations are being used. Here, the expected frequencies are computed by differences between the predictive CDFs \\(F( \\cdot )\\), evaluated at the interval breaks. Hence, mariginal calibration is always obtained on the observation scale compared to the probabilistic calibration performed on the probability scale. Although there are some previous studies that display observation points rather than intervals (e.g., Gneiting, Balabdaoui, and Raftery 2007), here we stick to the former and discuss only the so-called rootograms which are histogram-style plots (Kleiber and Zeileis 2016).\nFor the special case of a binary event, the observed event frequency is typically plotted against the predictive probability in a so-called reliability diagram (Wilks 2011; Bröcker and Smith 2007). Here, the predicted probability for a binary event is partitioned into a certain number of bins and the averaged forecast probability within each bin is plotted against the observerd relative frequency. Typically, equidistant binning is employed, but here the rather arbitrary number of bins can be quite sensible. A simple and common enhancement is therefore to use evenly populated bins, though even here instabilities can be a major issue (Dimitriadis, Gneiting, and Jordan 2021)."
  },
  {
    "objectID": "vignettes/goodness_of_fit.html#probabilistic-calibration-pit-and-randomized-quantile-residuals",
    "href": "vignettes/goodness_of_fit.html#probabilistic-calibration-pit-and-randomized-quantile-residuals",
    "title": "Goodness of Fit of Probabilistic Regression Models",
    "section": "\n4 Probabilistic calibration: PIT and (randomized) quantile residuals",
    "text": "4 Probabilistic calibration: PIT and (randomized) quantile residuals\nAdvantage: Needs to be compared with only one distribution (uniform or normal).\nDisadvantage: Scale is not so natural. May require randomization for discrete distributions.\nAccording to Gneiting, Balabdaoui, and Raftery (2007), model calibration can be further distinguished between probabilistic calibration and marginal calibration. Probabilistic calibration is usually assessed using probability integral transform (PIT) values (Dawid 1984; Diebold, Gunther, and Tay 1998; Gneiting, Balabdaoui, and Raftery 2007) or so-called PIT residuals (Warton, Thibaut, and Wang 2017). These are simply the predictive cumulative distribution function (CDF) evaluated at the observations\n\\[u_i = F(y_i | \\, \\hat{\\boldsymbol{\\theta}}_i),\\]\nwhere \\(F( \\cdot )\\) denotes the CDF of the modeled distribution \\(f( \\cdot )\\) with estimated parameters \\(\\hat{\\boldsymbol{\\theta}}_{i}\\). PIT residuals have the desirable property, that if the model is a good approximation to the true data-generating process, i.e., the observation is drawn from the predictive distribution, the PIT residuals \\(u_i\\) are approximately uniformly distributed on \\([0, 1]\\) for continous predictive distributions \\(F( \\cdot )\\). PIT residuals or variants have therefore been used extensively for model diagnosis and depending on their implementation are known under various names, among them forecast distribution transformed residuals (Smith 1985), randomized quantile residuals (Dunn and Smyth 1996), and universal residuals (Brockwell 2007).\nIn case of a discrete predictive distribution or a distribution with a discrete component, e.g., in case of censoring, \\(u_i\\) can be generated as a random draw \\(\\text{U}\\) from the interval:\n\\[u_i = \\text{U}[F(y_i - 1 | \\, \\hat{\\boldsymbol{\\theta}}_i), F(y_i | \\,\n\\hat{\\boldsymbol{\\theta}}_i)].\\]\nHere, we follow the definition by Dunn and Smyth (1996), but similar approaches have also been proposed in, e.g., Brockwell (2007) and Smith (1985). Again \\(u_i\\) is uniformally distributed, apart from sampling variability.\nSince the PIT residuals are an iid sample from the standard uniform distribution, the PIT residuals can also be mapped to other distribution scales, e.g. to the standard normal scale, and should follow a standard normal distribution here. In the simplest case, the PIT residuals \\(u_i\\) can be plotted against the probabilities of a uniform distribution in so-called P-P plots (Wilk and Gnanadesikan 1968; Handcock and Morris 1999). However, it is far more common to transform the PIT residuals to the normal scale and compare them to the standard normal quantiles in a normal Q-Q plot (Hoaglin 2006). Alternatively, in a PIT histogram, the uniformally distributed PIT residuals are divided into intervals by a certain number of breakpoints and plotted in a histogram-style plot. Regardless of the graphical display, the PIT residuals are always on the probability scale, which might be transformed to the normal scale or another scale if preferred."
  },
  {
    "objectID": "vignettes/goodness_of_fit.html#similarities-and-differences",
    "href": "vignettes/goodness_of_fit.html#similarities-and-differences",
    "title": "Goodness of Fit of Probabilistic Regression Models",
    "section": "\n5 Similarities and differences",
    "text": "5 Similarities and differences\nIn the graphical displays for assessing the goodness of fit, several recurring elements can be seen:\n\nPIT residuals are asymptotically uniformly distributed or transformed to another probability scale: The PIT histogram is on the uniform probability scale versus the normal Q-Q plot on the normal scale. Whereas, the transformation to the normal scale spreads the values in the tails further apart and thus better highlights possible discrepancies in the distribuional tails.\nThe marginal calibration is usually evaluated on the observation scale by checking whether observed and expected frequencies match. The rootogram, on the observation scale, is therefore especially useful for count data with values close to zero.\nDiscretization: Instead of plotting the raw values, e.g. PIT residuals, often some discretization improves readability of the graphical displays. The disadvantage here is that the breakpoint are often kind of arbitrary and certain misspecification might therefore be masked by plotting the values as intervals. For example, misscpecifications in the outer tails of the distribution are often not visible in PIT histograms, as the intervals are averaving over many data points; here, Q-Q plots are clearly superior. Another example is the reliabitiliy diagram, which can be quite instable when using equidistant binning.\nThe uncertainty due to the estimation of the parameters is not taken into account. Therefore, some sampling variation is seen in all graphical displays."
  },
  {
    "objectID": "vignettes/illustration_rain_ibk.html",
    "href": "vignettes/illustration_rain_ibk.html",
    "title": "Illustration: Precipitation Forecasts in Innsbruck",
    "section": "",
    "text": "The second example models 3 day-accumulated precipitation sums using a Logistic distribution censored at zero accounting for non-negative precipitation sums. The use case builds heavily on the vignette Heteroscedastic Censored and Truncated Regression with crch given in crch by Messner, Mayr, and Zeileis (2016)."
  },
  {
    "objectID": "vignettes/illustration_rain_ibk.html#precipitation-forecasts",
    "href": "vignettes/illustration_rain_ibk.html#precipitation-forecasts",
    "title": "Illustration: Precipitation Forecasts in Innsbruck",
    "section": "\n1 Precipitation forecasts",
    "text": "1 Precipitation forecasts\nThis use-case discusses a weather forecast example application of censored regression models. The example is taken from the vignette Heteroscedastic Censored and Truncated Regression with crch provided for the package crch by Messner, Mayr, and Zeileis (2016).\nWeather forecasts are usually based on numerical weather prediction (NWP) models, which take the current state of the atmosphere and calculate future weather by numerically simulating the main atmospheric processes. However, due to uncertain initial conditions and unknown or unresolved processes, these numerical predictions are always subject to errors. To estimate these errors, many weather centers produce what are called ensemble forecasts: multiple NWP runs that use different initial conditions and model formulations. Unfortunately, these ensemble forecasts cannot account for all sources of error, so they are often still biased and uncalibrated. Therefore, they are often calibrated and corrected for systematic errors through statistical post-processing.\nOne popular post-processing method is heteroscedastic linear regression where the ensemble mean is used as regressor for the location and the ensemble standard deviation or variance is used as regressor for the scale (Gneiting et al. 2005). The following example applies heteroscedastic censored regression with a logistic distribution assumption to precipitation data in Innsbruck (Austria).\nThe RainIbk data set contains observed 3 day-accumulated precipitation amounts (rain) and the corresponding 11 member ensemble forecasts of total accumulated precipitation amount between 5 and 8 days in advance (rainfc.1, rainfc.2, … rainfc.11). In previous studies it has been shown that it is of advantage to model the square root of precipitation rather than precipitation itself. Thus all precipitation amounts are square rooted before ensemble mean and standard deviation are derived. Furthermore, events with no variation in the ensemble are omitted:\n\ndata(\"RainIbk\", package = \"crch\")\nRainIbk &lt;- sqrt(RainIbk)\nRainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, mean)\nRainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, sd)\nRainIbk &lt;- subset(RainIbk, enssd &gt; 0)"
  },
  {
    "objectID": "vignettes/illustration_rain_ibk.html#from-linear-regression-to-distributional-regression-models",
    "href": "vignettes/illustration_rain_ibk.html#from-linear-regression-to-distributional-regression-models",
    "title": "Illustration: Precipitation Forecasts in Innsbruck",
    "section": "\n2 From linear regression to distributional regression models",
    "text": "2 From linear regression to distributional regression models\nFor comparison we fit a homoscedastic linear regression model using the least squares approach for rain with ensmean as regressor. As a more appropriate model for rain accounting for non-negative precipitation sums, we fit a hetereoscedastic censored model assuming an underlying logistic response distribution with ensmean as regressor for the location and log(enssd) as regressor for the scale:\n\n## linear model\nm_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n## heteroscedastic censored regression with a logistic distribution assumption\nm_hclog &lt;- crch::crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0,\n  dist = \"logistic\")\n\nIn the scatterplot of rain against ensmean it can be seen, that precipitation is clearly non-negative with many zero observations. Thus the censored regression model m_hclog is more suitable than the linear regression model to estimate the underlying relationship:\n\nplot(rain ~ ensmean, data = RainIbk, pch = 19, col = gray(0, alpha = 0.2))\nabline(coef(m_lm)[1:2], col = 3, lwd = 2)\nabline(coef(m_hclog)[1:2], col = 4, lwd = 2)\n\nlegend(\"topright\", lwd = c(2, 1), lty = c(1, 1), col = c(3, 4), \n  c(\"m_lm\", \"m_hclog\"), bty = \"n\")"
  },
  {
    "objectID": "vignettes/illustration_rain_ibk.html#model-evaluation-marginal-calibration",
    "href": "vignettes/illustration_rain_ibk.html#model-evaluation-marginal-calibration",
    "title": "Illustration: Precipitation Forecasts in Innsbruck",
    "section": "\n3 Model evaluation: Marginal calibration",
    "text": "3 Model evaluation: Marginal calibration\nThe significant underfitting of zero observations is also very apparent in the rootogramm of the linear model, as it does not correctly account for the point mass at zero. Additionally, a weak wavelike pattern indicates a slight overfitting of precipitation sums between zero and 5mm and an underfitting of precipitation sums above. In contrast, the censored logistic regression m_hclog provides a pretty good marginal fit, where the expected squared frequencies closely match the squared observed frequencies:\n\nr1 &lt;- rootogram(m_lm, plot = FALSE)\nr2 &lt;- rootogram(m_hclog, plot = FALSE)\n\nggplot2::autoplot(c(r1, r2))"
  },
  {
    "objectID": "vignettes/illustration_rain_ibk.html#model-evaluation-probabilistic-calibration",
    "href": "vignettes/illustration_rain_ibk.html#model-evaluation-probabilistic-calibration",
    "title": "Illustration: Precipitation Forecasts in Innsbruck",
    "section": "\n4 Model evaluation: Probabilistic calibration",
    "text": "4 Model evaluation: Probabilistic calibration\nThe PIT histogram of the linear model m_lm is skewed, indicating a misfit in terms of the probabilistic calibration, whereas the PIT histogram of the linear model is rather uniformly distributed.\n\np1 &lt;- pithist(m_lm, plot = FALSE)\np2 &lt;- pithist(m_hclog, plot = FALSE)\n\nggplot2::autoplot(c(p1, p2))\n\n\n\n\n\n\n\nFor a better comparison of the two model fits, alternatively a line-style PIT histogram can also be shown:\n\nggplot2::autoplot(c(p1, p2), colour = c(3, 4), style = \"line\", single_graph = TRUE, confint_col = 1, confint = \"line\", ref = FALSE)\n\n\n\n\n\n\n\nTo further analyse the misfit of the linear model in terms of probabilistic calibration, we transform the PIT residuals to the normal scale and increase the number of breaks in the PIT histogram. Transforming to the normal scale spreads the values at the tails of the distribution further apart, and increasing the breaks prevents potential masking of small scale patterns.\nWe can see that the distribution of PIT residuals is right skewed with more values between -2 and 0, but less values between 0 and 2 compared to the standard normal distribution:\n\npithist(m_lm, breaks = 50, trafo = qnorm, xlim = c(-3, 3))\n\n\n\n\n\n\n\nThis is also reflected in the pattern of the Q-Q plot of the linear model: Due to the high frequency in values between -2 and 0, the observed quantile residuals increase slower in this region relative to the standard normal quantiles. However, the low frequency of quantile residuals above zero leads to an higher increase in quantile residuals compared to the standard normal quantiles.\nIn summary, the Q-Q plot of the linear model has a positive curvature, bending up at both ends of the distributional tails. The censored logistic regression m_hclog follows more or less the reference line indicating normally distributed quantile residuals:\n\nq1 &lt;- qqrplot(m_lm, plot = FALSE)\nq2 &lt;- qqrplot(m_hclog, plot = FALSE)\nggplot2::autoplot(c(q1, q2), colour = c(3, 4), alpha = 0.8, single_graph = TRUE, simint = FALSE, confint =\"line\")\n\n\n\n\n\n\n\nConsistent with the pattern of right-skewed PIT residuals corresponding to a “too left-skewed” fitted distribution, a U-shaped pattern is evident in the worm plot of the linear model; the censored logistic is more or less flat around zero.\n\nw1 &lt;- wormplot(m_lm, plot = FALSE)\nw2 &lt;- wormplot(m_hclog, plot = FALSE)\nggplot2::autoplot(c(w1, w2), colour = c(3, 4), alpha = 0.8, single_graph = TRUE, simint = FALSE, confint =\"line\")"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "To report bugs please send a simple e-mail to the package maintainer:\nAchim.Zeileis at R-project dot org\nFor inquiries you can also reach out on social media:\n@zeileis@fosstodon.org (Mastodon)\n@AchimZeileis (X/Twitter)\n\n\n\n\nAchim Zeileis  \nMoritz N. Lang  \nReto Stauffer  \nChristian Kleiber  \nIoannis Kosmidis  \nJakob W. Messner"
  },
  {
    "objectID": "contact.html#reporting-bugs",
    "href": "contact.html#reporting-bugs",
    "title": "Contact",
    "section": "",
    "text": "To report bugs please send a simple e-mail to the package maintainer:\nAchim.Zeileis at R-project dot org\nFor inquiries you can also reach out on social media:\n@zeileis@fosstodon.org (Mastodon)\n@AchimZeileis (X/Twitter)"
  },
  {
    "objectID": "contact.html#authors-and-contributors",
    "href": "contact.html#authors-and-contributors",
    "title": "Contact",
    "section": "",
    "text": "Achim Zeileis  \nMoritz N. Lang  \nReto Stauffer  \nChristian Kleiber  \nIoannis Kosmidis  \nJakob W. Messner"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Infrastructure for Forecasting and Assessment of Probabilistic Models",
    "section": "",
    "text": "Infrastructure for Forecasting and Assessment of Probabilistic Models\nThe R package topmodels provides unified infrastructure for probabilistic models and distributional regressions: Probabilistic forecasting, in-sample and out-of-sample, of probabilities, densities, quantiles, and moments. Probabilistic residuals and scoring via log-score (or log-likelihood), (continuous) ranked probability score, etc. Diagnostic graphics like rootograms, PIT histograms, (randomized) quantile residual Q-Q plots, and reliagrams (reliability diagrams).\nModular object-oriented implementation with support for many model objects, including lm, glm, glm.nb, gamlss, bamlss, hurdle, zeroinfl, zerotrunc, nbreg, crch, betareg, and more to come."
  },
  {
    "objectID": "vignettes/topmodels.html",
    "href": "vignettes/topmodels.html",
    "title": "topmodels: Infrastructure for Inference and Forecasting in Probabilistic Models",
    "section": "",
    "text": "Moritz Lang, Reto Stauffer, Achim Zeileis"
  },
  {
    "objectID": "vignettes/topmodels.html#overview",
    "href": "vignettes/topmodels.html#overview",
    "title": "topmodels: Infrastructure for Inference and Forecasting in Probabilistic Models",
    "section": "\n1 Overview",
    "text": "1 Overview\nProbabilistic predictions have been receiving increasing interest in various application fields over the last decades due to necessary functional risk management and strategy. Consequently, there is an increasing demand for appropriate probabilistic models and corresponding evaluations of the goodness of fit. Besides proper probabilistic scores (Gneiting and Raftery 2007), which evaluate not only the expectation but the entire predictive distribution, graphical assessment methods are particularly advantageous to diagnose possible model misspecification problems.\nProbabilistic predictions are often based on distributional regression models, for which a wide range of different packages is readily available: from basic models like lm() and glm() in base R (which can be interpreted as probabilistic models and not just mean regression models), over general packages for distributional regression like gamlss (Stasinopoulos and Rigby 2007) or bamlss Umlauf et al. (2021) to more specific packages for certain purposes. Examples for the latter include pscl or countreg (Zeileis, Kleiber, and Jackman 2008) for count regression, crch (Messner, Mayr, and Zeileis 2016) for certain censored regression models, or betareg (Cribari-Neto and Zeileis 2010) for beta regression, among many others. However, there is no unified and object-oriented approach available for all these different models/packages that allows to compute predictive distributions, probabilities, and quantiles. Therefore, routines to evaluate probabilistic models either graphically or via scoring rules are not always available or may be specific to certain packages. An easy-to-use unified infrastructure for graphically assessing and comparing different probabilistic models is not available, yet.\nThe topmodels package is designed to fill this gap and provide such an unifiying infrastructure to obtain predictions of probabilities, densities, etc. for probabilistic models. The unifying prediction infrastructure is the basis for numerous graphical evaluation tools, such as rootograms (Kleiber and Zeileis 2016), PIT histograms (Gneiting, Balabdaoui, and Raftery 2007), reliagrams (reliability diagrams, Wilks 2011), randomized quantile Q-Q plots (Dunn and Smyth 1996), and worm plots (Buuren and Fredriks 2001).\nTo be able to use the object-oriented framework of topmodels, solely a procast() method must exist for the model class of interest. Currently the package provides generic procast methods for the model classes lm, glm, crch (Messner, Mayr, and Zeileis 2016), and disttree (Schlosser et al. 2019)."
  },
  {
    "objectID": "vignettes/topmodels.html#installation",
    "href": "vignettes/topmodels.html#installation",
    "title": "topmodels: Infrastructure for Inference and Forecasting in Probabilistic Models",
    "section": "\n2 Installation",
    "text": "2 Installation\nFor the package topmodels so far only a development version is available, which is hosted on R-Forge at https://R-Forge.R-project.org/projects/topmodels/ in a Subversion (SVN) repository. The package can be installed via\n\ninstall.packages(\"topmodels\", repos = \"https://R-Forge.R-project.org\")\n\nor via\n\nremotes::install_svn(\"svn://R-Forge.R-project.org/svnroot/topmodels/pkg/topmodels\")\n\nwhere a specific revision can be installed by setting the optional argument revision."
  },
  {
    "objectID": "vignettes/topmodels.html#usage",
    "href": "vignettes/topmodels.html#usage",
    "title": "topmodels: Infrastructure for Inference and Forecasting in Probabilistic Models",
    "section": "\n3 Usage",
    "text": "3 Usage\nThe package topmodels provides various routines to easily graphically assess and compare different probabilistic models and model types using ggplot2 (Wickham 2016) and base R graphics:\n\nlibrary(\"topmodels\")\nm &lt;- lm(dist ~ speed, data = cars)\n\n\nrootogram(m)\n\n\n\n\n\n\n\n\npithist(m)\n\n\n\n\n\n\n\n\nqqrplot(m)\n\n\n\n\n\n\n\n\nwormplot(m)\n\n\n\n\n\n\n\n\nreliagram(m)"
  },
  {
    "objectID": "vignettes/implementation.html#methods",
    "href": "vignettes/implementation.html#methods",
    "title": "Implementation Overview",
    "section": "\n1 Methods",
    "text": "1 Methods\n\n\nmethod\ncomputation arguments\nplotting arguments\noutput\n\n\n\nrootogram()\n\nobject, newdata, plot, class, response_type, breaks, width\n\n\nstyle1, scale1, expected1, ref1, xlab1, ylab1, main1, ...\n\n\nobserved, expected, mid, width\n\n\n\npithist()\n\nobject, newdata, plot, class, trafo1, breaks, type1, nsim, delta, simint1,2, simint_level, simint_nrep\n\n\nsimint1,2, style1, freq1, expected1, confint1, xlab1, ylab1, main1, ...\n\n\nobserved, expected, mid, width, simint_lwr, simint_upr\n\n\n\nqqrplot()\n\nobject, newdata, plot, class, detrend1, trafo1, nsim, delta, simint1,2, simint_level, simint_nrep\n\n\nsimint1,2, confint1, ref1, xlab1, ylab1, main1, ...\n\n\nobserved, expected, simint_observed_lwr, simint_observed_upr, simint_expected\n\n\n\n\n1: Setting is saved within attributes of the returned object. Hence, plot(&lt;object&gt;) renders a graphic with the arguments saved in the attributes.\n2: Argument is used both for computation and plotting.\n\n\ncombine\nvector of attribute values\nsingle attribute value\n\n\n\nc.rootogram()\n\nexpected, ref, xlab, ylab, main\n\n\nstyle, scale\n\n\n\nc.pithist()\n\ntype, simint, expected, confint, counts, xlab, ylab, main\n\n\ntrafo3, style, freq\n\n\n\nc.qqrplot()\n\nsimint, confint, ref, xlab, ylab, main\n\n\ndetrend, trafo3\n\n\n\n\n3: Non-unique attribute values can’t be comined.\n\n\n\n\n\n\n\n\nsummary\narguments\nreturn values\nextended return values\n\n\n\nsummary.rootogram()\n\nobject, scale, style, extend\n\n\nobserved, expected, mid, width\n\n\nymin, ymax\n\n\n\nsummary.pithist()\n\nobject, freq, confint_level, confint_type, extend\n\n\nobserved, expected, mid, width, simint_upr, simint_lwr\n\n\nconfint_lwr, confint_upr\n\n\n\nsummary.qqrplot()\n\nobject, detrend\n\n\nobserved, expected, simint_observed_lwr, simint_observed_upr, simint_expected\n\n–"
  },
  {
    "objectID": "vignettes/implementation.html#plotting-with-base-r",
    "href": "vignettes/implementation.html#plotting-with-base-r",
    "title": "Implementation Overview",
    "section": "\n2 Plotting with base R",
    "text": "2 Plotting with base R\n\n\n\n\n\n\n\nplot\narguments (main)\narguments (add ons)\n\n\n\nplot.rootogram()\n\nx, style, scale, expected, ref, xlim, ylim, xlab, ylab, main, axes, box, col, border, lwd, lty, alpha_min, ...\n\n\nexpected_col, expected_pch, expected_lty, expected_lwd, ref_col, ref_lty, ref_lwd\n\n\n\nplot.pithist()\n\nx, single_graph, style, freq, expected, confint, confint_level, confint_type, simint, xlim, ylim, xlab, ylab, main, axes, box, col, border, lwd, lty, alpha_min, ...\n\n\nexpected_lty, expected_lwd, confint_col, confint_lty, confint_lwd, expected_col, simint_col, simint_lty, simint_lwd\n\n\n\nplot.qqrplot()\n\nx, single_graph, detrend, simint, confint, confint_level, ref, ref_identity, ref_probs, xlim, ylim, xlab, ylab, main, axes, box, col, border, pch, ...\n\n\nsimint_col, simint_alpha, confint_col, confint_lty, confint_lwd, ref_col, ref_lty, ref_lwd"
  },
  {
    "objectID": "vignettes/implementation.html#plotting-with-ggplot2",
    "href": "vignettes/implementation.html#plotting-with-ggplot2",
    "title": "Implementation Overview",
    "section": "\n3 Plotting with ggplot2",
    "text": "3 Plotting with ggplot2\n\n\n\n\n\n\n\nautoplot\narguments (main)\narguments (add ons)\n\n\n\nautoplot.rootogram()\n\nobject, style, scale, expected, ref, xlim, ylim, xlab, ylab, main, legend, theme, colour, fill, size, linetype, alpha, ...\n\n\nexpected_colour, expected_size, expected_linetype, expected_alpha, expected_fill, expected_stroke, expected_shape, ref_colour, ref_size, ref_linetype, ref_alpha\n\n\n\nautoplot.pithist()\n\nobject, single_graph, style, freq, expected, confint, confint_level, confint_type, simint, xlim, ylim, xlab, ylab, main, legend, theme, colour, fill, size, linetype, alpha\n\n\nexpected_colour, expected_size, expected_linetype, expected_alpha, confint_colour, confint_fill, confint_size, confint_linetype, confint_alpha, simint_colour, simint_size, simint_linetype, simint_alpha\n\n\n\nautoplot.qqrplot()\n\nobject, single_graph, detrend, simint, confint, confint_level, ref, ref_identity, ref_probs, xlim, ylim, xlab, ylab, main, legend, theme, colour, fill, shape, size, stroke, ...\n\n\nsimint_fill, simint_alpha, confint_colour, confint_fill, confint_size, confnt_linetype, confint_alpha, ref_colour, ref_size, ref_linetype\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_&lt;…&gt;\ninherits\ngeom aes\nstat_&lt;…&gt;\nstat aes\n\n\n\ngeom_rootogram()\nGeomRect\n\nxmin, xmax, ymin, ymax\n\nstat_rootogram()\n\nobserved, expected, mid, width\n\n\n\ngeom_rootogram_expected()\nGeomPath\n\nx, y\n\nstat_rootogram_expected()\n\nexpected, mid\n\n\n\ngeom_rootogram_ref()\nGeomHline\nyintercept = 0\nIdentity\n–\n\n\n\ngeom_pithist() with style = \"bar\" or style = \"line\"\n\n\nGeomTile or GeomStep\n\n\nx, y or x, y, width, height\n\nstat_pithist()\n\nx, y, width\n\n\n\ngeom_pithist_expected()\nGeomStep\n\nx, y\n\nstat_pithist_expected()\n\nx, y, width\n\n\n\n\ngeom_pithist_confint() with style = \"polygon\" or style = \"line\"\n\n\nGeomRect or GeomStep\n\n\nxmin, xmax, ymin, ymax or x, ymin, ymax\n\nstat_pithist_confint()\n\nx, y, width\n\n\n\ngeom_pithist_simint()\nGeomLinerange\n\nx, ymin, ymax\n\nstat_pithist_simint()\n\nx, ymin, ymax plus y and width required for freq = FALSE\n\n\n\ngeom_qqrplot()\nGeom\n\nx, y\n\nIdentity\n–\n\n\ngeom_qqrplot_simint()\nGeomPolygon\n\nx, y\n\nstat_qqrplot_simint()\n\nx, ymin, ymax\n\n\n\ngeom_qqrplot_ref()\nGeomAbline\n\nslope, intercept\n\nstat_qqrplot_expected()\n\nx, y\n\n\n\n\ngeom_qqrplot_confint() with style = \"polygon\" or style = \"line\"\n\n\nGeomPolygon or GeomPath\n\n\nx_noaes, y_noaes\n\nstat_qqrplot_confint()\n\nx, `y"
  },
  {
    "objectID": "vignettes/implementation.html#references",
    "href": "vignettes/implementation.html#references",
    "title": "Implementation Overview",
    "section": "\n4 References",
    "text": "4 References"
  },
  {
    "objectID": "vignettes/illustration_fifa_2018.html",
    "href": "vignettes/illustration_fifa_2018.html",
    "title": "Illustration: Goals in the 2018 FIFA World Cup",
    "section": "",
    "text": "This vignette provides two real cases discussing the graphical evaluation of the marginal and probabilistic calibration of probabilistic regression models. The first example provides a short case study modeling the goals at the 2018 FIFA World Cup employing a Poisson distribution. It is a direct extension of the vignette The Poisson Distribution: From Basic Probability Theory to Regression Models given in distributions3."
  },
  {
    "objectID": "vignettes/illustration_fifa_2018.html#goals-in-the-2018-fifa-world-cup",
    "href": "vignettes/illustration_fifa_2018.html#goals-in-the-2018-fifa-world-cup",
    "title": "Illustration: Goals in the 2018 FIFA World Cup",
    "section": "\n1 Goals in the 2018 FIFA World Cup",
    "text": "1 Goals in the 2018 FIFA World Cup\nThis use-case employs the Poisson distribution for modeling count data along predicted probabilities for the number of goals in soccer matches from the 2018 FIFA World Cup. The full analysis with an illustrative introduction from basic probability theory to regression models using the R package distributions3 is given here.\nTo investigate the number of goals scored per match in the 2018 FIFA World Cup, the FIFA2018 data set provides two rows, one for each team, for each of the 64 matches during the tournament. In the following, we treat the goals scored by the two teams in the same match as independent which is a realistic assumption for this particular data set. We just remark briefly that there are also bivariate generalizations of the Poisson distribution that would allow for correlated observations but which are not considered here.\nIn addition to the goals, the data set provides some basic meta-information for the matches (an ID, team name abbreviations, type of match, group vs. knockout stage) as well as some further covariates that we will revisit later in this document. The data looks like this:\n\ndata(\"FIFA2018\", package = \"distributions3\")\nhead(FIFA2018)\n\n  goals team match type stage logability difference\n1     5  RUS     1    A group  0.1530732  0.8638406\n2     0  KSA     1    A group -0.7107673 -0.8638406\n3     0  EGY     2    A group -0.2066409 -0.4438080\n4     1  URU     2    A group  0.2371671  0.4438080\n5     3  RUS     3    A group  0.1530732  0.3597142\n6     1  EGY     3    A group -0.2066409 -0.3597142\n\n\nFor now, we will focus on the goals variable only. A brief summary yields\n\nsummary(FIFA2018$goals)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   1.000   1.297   2.000   6.000 \n\n\nshowing that the teams scored between \\(0\\) and \\(6\\) goals per match with an average of \\(\\bar y = 1.297\\) from the observations \\(y_i\\) (\\(i = 1, \\dots, 128\\)). The corresponding table of observed relative frequencies are:\n\nprop.table(table(FIFA2018$goals))\n\n\n        0         1         2         3         4         5         6 \n0.2578125 0.3750000 0.2500000 0.0781250 0.0156250 0.0156250 0.0078125 \n\n\n(Note that in recent versions of R using proportions() rather than prop.table() is recommended.)\nThis confirms that goals are relatively rare events in a soccer game with each team scoring zero to two goals per match in almost 90 percent of the matches. Below we show that this observed frequency distribution can be approximated very well by a Poisson distribution which can subsequently be used to obtain predicted probabilities for the goals scored in a match."
  },
  {
    "objectID": "vignettes/illustration_fifa_2018.html#from-basic-probability-theory-to-regression-models",
    "href": "vignettes/illustration_fifa_2018.html#from-basic-probability-theory-to-regression-models",
    "title": "Illustration: Goals in the 2018 FIFA World Cup",
    "section": "\n2 From basic probability theory to regression models",
    "text": "2 From basic probability theory to regression models\nIn a first step, we simply assume that goals are scored with a constant mean over all teams and fit a single Poisson distribution for the number of goals. To do so, we obtain a point estimate of the Poisson parameter by using the empirical mean \\(\\hat \\lambda = \\bar y = 1.297\\) and set up the corresponding distribution object:\n\np_const &lt;- distributions3::Poisson(lambda = mean(FIFA2018$goals))\np_const\n\n[1] \"Poisson(lambda = 1.297)\"\n\n\nThis actually corresponds to the maximum likelihood estimator for this distribution fitting a generalized linear model (GLM) to the data that links the expected number of goals per team/match \\(\\lambda_i\\) to the linear predictor \\(x_i^\\top \\beta\\) with regressor vector \\(x_i^\\top\\) and corresponding coefficient vector \\(\\beta\\) using a log-link: \\(\\log(\\lambda_i) = x_i^\\top \\beta\\).\nHere, in the simplest case fitting an intercept-only model without further regressors, the regressor vector can be written as \\(x_i^\\top = 1\\) and the maximum likelihood estimator \\(\\hat \\beta\\) with corresponding inference, predictions, residuals, etc. can be obtained using the glm() function from base R with family = poisson:\n\nm_ic &lt;- glm(goals ~ 1, data = FIFA2018, family = poisson)\nm_ic\n\n\nCall:  glm(formula = goals ~ 1, family = poisson, data = FIFA2018)\n\nCoefficients:\n(Intercept)  \n       0.26  \n\nDegrees of Freedom: 127 Total (i.e. Null);  127 Residual\nNull Deviance:      144.2 \nResidual Deviance: 144.2    AIC: 372.9\n\n\nThe corresponding prediction for the number of goals can be obtained manually from the extracted coef() by applying exp() (as the inverse of the log-link).\n\nlambda_zero &lt;- exp(coef(m_ic)[1])\nlambda_zero\n\n(Intercept) \n   1.296875 \n\n\nOr equivalently the predict() function can be used with type = \"response\" in order to get the expected \\(\\hat \\lambda_i\\) (rather than just the linear predictor \\(x_i^\\top \\hat \\beta\\) that is predicted by default).\n\npredict(m_ic, newdata = data.frame(difference = 0), type = \"response\")\n\n       1 \n1.296875 \n\n\nThis yields the same predicted Poisson distribution, identical to \\(p_const\\), for all teams and matches in this tournament – most likely an incorrect assumption:\n\np_ic &lt;- distributions3::Poisson(lambda = fitted(m_ic))\nhead(p_ic)\n\n                        1                         2                         3 \n\"Poisson(lambda = 1.297)\" \"Poisson(lambda = 1.297)\" \"Poisson(lambda = 1.297)\" \n                        4                         5                         6 \n\"Poisson(lambda = 1.297)\" \"Poisson(lambda = 1.297)\" \"Poisson(lambda = 1.297)\" \n\n\nTo account for different expected performances from the teams in the 2018 FIFA World Cup, the FIFA2018 data provides an estimated logability for each team. These have been estimated by Zeileis, Leitner, and Hornik (2018) prior to the start of the tournament (2018-05-20) based on quoted odds from 26 online bookmakers using the bookmaker consensus model of Leitner, Zeileis, and Hornik (2010). The difference in logability between a team and its opponent is a useful predictor for the number of goals scored.\nHence, the intercept-only model m_ic can be extended by using the regressor vector \\(x_i^\\top = (1, \\mathtt{difference}_i)\\):\n\nm_reg &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\nm_reg\n\n\nCall:  glm(formula = goals ~ difference, family = poisson, data = FIFA2018)\n\nCoefficients:\n(Intercept)   difference  \n     0.2127       0.4134  \n\nDegrees of Freedom: 127 Total (i.e. Null);  126 Residual\nNull Deviance:      144.2 \nResidual Deviance: 128.7    AIC: 359.4\n\n\nHere, the slope of \\(0.413\\) can be interpreted as an ability elasticity of the number of goals scored. This is because the difference of the log-abilities can also be understood as the log of the ability ratio. Thus, when the ability ratio increases by \\(1\\) percent, the expected number of goals increases approximately by \\(0.413\\) percent.\nIn comparison to the intercept-only model m_ic, this yields a more realistic outcome providing a different predicted Poisson distribution for each team/match in the tournament. We can set up the vector of all \\(128\\) Poisson() distribution objects by extracting the vector of all fitted point estimates \\((\\hat \\lambda_1, \\dots, \\hat \\lambda_{128})^\\top\\):\n\np_reg &lt;- distributions3::Poisson(lambda = fitted(m_reg))\nhead(p_reg)\n\n                         1                          2 \n\"Poisson(lambda = 1.7680)\" \"Poisson(lambda = 0.8655)\" \n                         3                          4 \n\"Poisson(lambda = 1.0297)\" \"Poisson(lambda = 1.4862)\" \n                         5                          6 \n\"Poisson(lambda = 1.4354)\" \"Poisson(lambda = 1.0661)\""
  },
  {
    "objectID": "vignettes/illustration_fifa_2018.html#model-evaluation-marginal-calibration",
    "href": "vignettes/illustration_fifa_2018.html#model-evaluation-marginal-calibration",
    "title": "Illustration: Goals in the 2018 FIFA World Cup",
    "section": "\n3 Model evaluation: Marginal calibration",
    "text": "3 Model evaluation: Marginal calibration\nMarginal calibration is generally concerned with whether the observed frequencies match the frequencies expected by the model. For discrete observations, frequencies for the observations themselves can be considered; for continuous observations or more generally, frequencies for intervals of observations are being used. Here, the expected frequencies are computed by differences between the predictive CDFs \\(F( \\cdot )\\), evaluated at the interval breaks. Hence, marginal calibration is always obtained on the observation scale compared to the probabilistic calibration performed on the probability scale. This makes it especially useful for evaluating count data models which predictions are often close to zero.\nFor evaluating the marginal calibration of the Poisson models for the number of goals scored, we compute the expected absolute frequencies by averaging across the expectations per team/match from both regression model and compare these with the observed absolute frequencies:\n\nobserved &lt;- table(FIFA2018$goals)\nexpected_ic &lt;- distributions3::pdf(p_ic, 0:6)\nexpected_ic &lt;- colMeans(expected_ic) * sum(observed)\nexpected_reg &lt;- distributions3::pdf(p_reg, 0:6)\nexpected_reg &lt;- colMeans(expected_reg) * sum(observed)\ncbind(observed, expected_ic, expected_reg) \n\n  observed expected_ic expected_reg\n0       33  34.9932527    37.679930\n1       48  45.3818746    43.541948\n2       32  29.4273093    27.450378\n3       10  12.7211806    12.574218\n4        2   4.1244453     4.684102\n5        2   1.0697780     1.501012\n6        1   0.2312281     0.426588\n\n\nGraphically, this comparison can be shown as a so-called rootogram (Kleiber and Zeileis 2016) where the gray bars represent the observed frequencies overlayed by the expected frequencies as a red line. By using the function rootogram(), we can reproduce the previous results plugging in the model objects m_ic and m_reg:\n\nr1 &lt;- rootogram(m_ic, fitted = TRUE, style = \"standing\", scale = \"raw\", ref = FALSE, plot = FALSE)\nr2 &lt;- rootogram(m_reg, fitted = TRUE, style = \"standing\", scale = \"raw\", ref = FALSE, plot = FALSE)\nc(r1, r2)\n\nA `rootogram` object with `scale = \"raw\"` and `style = \"standing\"`\n(column `distribution` not shown)\n\n   observed   expected mid width group\n1        33 34.9932527   0   0.9     1\n2        48 45.3818746   1   0.9     1\n3        32 29.4273093   2   0.9     1\n4        10 12.7211806   3   0.9     1\n5         2  4.1244453   4   0.9     1\n6         2  1.0697780   5   0.9     1\n7         1  0.2312281   6   0.9     1\n8        33 37.6799296   0   0.9     2\n9        48 43.5419481   1   0.9     2\n10       32 27.4503775   2   0.9     2\n11       10 12.5742178   3   0.9     2\n12        2  4.6841019   4   0.9     2\n13        2  1.5010116   5   0.9     2\n14        1  0.4265880   6   0.9     2\n15        0  0.1094064   7   0.9     2\n\nggplot2::autoplot(c(r1, r2))\n\n\n\n\n\n\n\nFurther, in order to stabilize the variances of the discrepancies, i.e., putting more focus on discrepancies for small frequencies, we can show the frequencies on a square root scale:\n\nggplot2::autoplot(c(r1, r2), scale = \"sqrt\")  # FIXME: (ML) names got lost\n\n\n\n\n\n\n\nIn a second step, we employ a so-called hanging rootogram where bars representing the square-root of the observed frequencies are “hanging” from the square-root of the expected frequencies in the red line. Here, the offset around the x-axis compared to a reference line clearly shows the difference between the two frequencies for the intercept-only model m_ic and the full probabilistic model m_reg. For both models the differences are reasonably close to zero indicating a rather good marginal fit:\n\nggplot2::autoplot(c(r1, r2), scale = \"sqrt\", style = \"hanging\", ref = TRUE)  # FIXME: (ML) names got lost\n\n\n\n\n\n\n\nSo far we have only evaluated the marginal calibration comparing whether the observed frequencies match the frequencies expected by estimated model on the observational scale. In the next step we will evaluate the probabilistic calibration which is performed on the probability scale."
  },
  {
    "objectID": "vignettes/illustration_fifa_2018.html#model-evaluation-probabilistic-calibration",
    "href": "vignettes/illustration_fifa_2018.html#model-evaluation-probabilistic-calibration",
    "title": "Illustration: Goals in the 2018 FIFA World Cup",
    "section": "\n4 Model evaluation: Probabilistic calibration",
    "text": "4 Model evaluation: Probabilistic calibration\nProbabilistic calibration is usually assessed using probability integral transform (PIT) values (Dawid 1984; Diebold, Gunther, and Tay 1998; Gneiting, Balabdaoui, and Raftery 2007) or so-called PIT residuals (Warton, Thibaut, and Wang 2017). These are simply the predictive cumulative distribution function (CDF) evaluated at the observations\n\\[u_i = F(y_i | \\, \\hat{\\boldsymbol{\\theta}}_i),\\]\nwhere \\(F( \\cdot )\\) denotes the CDF of the modeled distribution \\(f( \\cdot )\\) with estimated parameters \\(\\hat{\\boldsymbol{\\theta}}_{i}\\). PIT residuals have the desirable property, that if the model is a good approximation to the true data-generating process, i.e., the observation is drawn from the predictive distribution, the PIT residuals \\(u_i\\) are approximately uniformly distributed on \\([0, 1]\\) for continuous predictive distributions \\(F( \\cdot )\\). Plotting the histogram of the PIT residuals and checking for uniformity is therefore a common empirical way of checking for calibration:\n\np1 &lt;- pithist(m_reg)\n\n\n\n\n\n\n\nTo focus more on violations of the distributional assumption in the tails of the distribution, PIT residuals can also be transformed to the normal scale or another scale if preferred. This allows the extreme values to be spread more widely, so that less values are included in the outer intervals. However, this has the drawback that detecting misspecification is more complicated than checking for uniformity:\n\np2 &lt;- pithist(m_reg, trafo = qnorm, type = \"random\", simint = FALSE) # `type = \"expected\"` does not work, check!\n\n\n\n\n\n\n\nDiscretization, i.e., the representation of values in intervals, has the advantage that it usually improves the readability of graphical representations. However, discretization can also hide certain misspecifications: breakpoints are often quite arbitrary and can mask misspecifications of relatively few but extreme values in the outer tails of the distribution. Here, classical Q-Q plots are clearly superior to PIT histograms:\n\nq1 &lt;- qqrplot(m_reg, confint = \"line\", simint = FALSE)\n\n\n\n\n\n\n\nSince small to medium deviations are nevertheless difficult to detect in Q-Q plots, untilting the plot makes detecting pattern of departure from a now horizontal line much easier. Here, expected quantiles are subtracted from the observed quantiles:\n\nw1 &lt;- wormplot(m_reg, confint = \"line\", simint = FALSE)\n\n\n\n\n\n\n\nThis so-called de-trended Q-Q plot is best known as worm plot (Buuren and Fredriks 2001)."
  },
  {
    "objectID": "vignettes/procast.html#overview",
    "href": "vignettes/procast.html#overview",
    "title": "Probabilistic Forecasting Infrastructure",
    "section": "\n1 Overview",
    "text": "1 Overview\nThe functionality provided by the topmodels package can be broadly placed into three groups:\n\n\nNumeric quantities: Functions which, based on fitted model objects (like lm, glm, etc.), compute quantities of interest, such as predicted probabilities, quantiles, residuals, etc.\n\nVisualizations: Functions which can help assess goodness of fit for fitted model objects, leveraging the numeric quantities from above.\n\nUnder the hood: Functions which can extract/predict probability distributions as proper S3 objects and provide standard methods for working with these distributions.\n\nThe S3 framework for probability distributions (3. above) is actually set up in the distributions3 package that topmodels builds upon. Actually, all numeric and graphical functions (1. and 2. above) have “smart” default methods. This means that if necessary methods can be defined for them but all the default methods work out of the box if the distributions3 functionality from 3. is provided. The table below shows all of the functions that become directly available when interfacing the distributions3 infrastructure.\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nNumeric quantities\n\n\n\nprocast()\nProbabilistic forecasts (probabilities, quantiles, etc.) based on model objects\n\n\nproscore()\nEvaluate scoring rules for procasts\n\n\nproresiduals()\nResiduals for probabilistic regression models (quantile, PIT, Pearson, …)\n\n\nVisualizations\n\n\n\npithist()\nPIT histograms\n\n\nqqrplot()\nQ-Q plots for quantile residuals\n\n\nwormplot()\nWorm plots for quantile residuals\n\n\nrootogram()\nRootograms of observed and fitted frequencies\n\n\nreliagram()\n(Extended) reliability diagrams\n\n\nUnder the hood\n\n\n\nprodist()\nFitted and predicated probability distributions based on model objects\n\n\n\nNormal(),\nProbability distribution objects\n\n\n\nPoisson(), …\nWith methods pdf(), cdf(), quantile(), mean(), …\n\n\n\nThus, to connect a new class of models to the topmodels tools the following building blocks need to be provided:\n\nA class with all necessary methods for the probability distribution of the response variable.\nA prodist() method for the model object, which typically first predicts the parameters and then sets up the distribution object from a.\n\nBelow we illustrate both steps by setting up a so-called “Tobit” model (Tobin 1958). This is a model with a normally-distributed response, left-censored at zero, which can in R be fitted with the crch() function (Messner, Mayr, and Zeileis 2016) from the package of the same name (among other packages). For illustration we first set up a new Tobit() distributions object (which is a special case of the CensoredNormal() class provided in crch). Subsequently, we add a prodist() method for crch objects."
  },
  {
    "objectID": "vignettes/procast.html#adding-a-new-distribution",
    "href": "vignettes/procast.html#adding-a-new-distribution",
    "title": "Probabilistic Forecasting Infrastructure",
    "section": "\n2 Adding a new distribution",
    "text": "2 Adding a new distribution\nTo illustrate how to set up a distributions3 constructor function, we employ the “Tobit” model, i.e., a normal distribution, left-censored at zero. Note that in practice we could just use the CensoredNormal() distribution provided by the crch() package (with arbitrary left and/or right censoring) as well as the underlying dcnorm(), pcnorm(), qcnorm(), and rcnorm() functions. However, here we avoid doing so and set up the Tobit() class constructor and accompanying methods from scratch, just for illustration.\n\n2.1 Class constructor\nFirst, the constructor (or generator) function for the distribution object should set up a data frame, containing the distribution’s parameters, with a custom class \"Tobit\" inheriting from \"distribution\". In case of the Tobit distribution, the parameters are the mean mu \\(= \\mu\\) and standard deviation sigma \\(= \\sigma\\) of the underlying uncensored normal distribution.\n\nTobit &lt;- function(mu = 0, sigma = 1) {\n  n &lt;- c(length(mu), length(sigma))\n  stopifnot(\"parameter lengths do not match (only scalars are allowed to be recycled)\" =\n    all(n %in% c(1L, max(n))))\n  d &lt;- data.frame(mu = mu, sigma = sigma)\n  class(d) &lt;- c(\"Tobit\", \"distribution\")\n  return(d)\n}\n\nThis is already sufficient for setting up a vector Y containing three different Tobit distributions:\n\nY &lt;- Tobit(mu = 1:3, sigma = c(1, 1, 4))\nY\n\n[1] \"Tobit(mu = 1, sigma = 1)\" \"Tobit(mu = 2, sigma = 1)\"\n[3] \"Tobit(mu = 3, sigma = 4)\"\n\n\nPrinting, subsetting, and some coercion functions already work due to suitable, flexible methods for \"distribution\" objects in general.\n\nlength(Y)\n\n[1] 3\n\nY[-2]\n\n[1] \"Tobit(mu = 1, sigma = 1)\" \"Tobit(mu = 3, sigma = 4)\"\n\nas.matrix(Y)\n\n     mu sigma\n[1,]  1     1\n[2,]  2     1\n[3,]  3     4\n\n\n\n2.2 Methods\nHaving constructed a distributions object like the \"Tobit\" object Y above, the next step is to perform standard tasks on it, such as computing densities, probabilities, moments, etc. While in base R the familiar functions of type ddist() (density), pdist() (cumulative probability), qdist() (quantile), and rdist() (random numbers) are typically used (e.g., where dist = norm or pois etc.), the distributions3 employs an object-oriented approach. Thus, rather than having the specification of the distribution as part of the function name, it is captured in the class of the object. Based on that suitable generic functions like pdf() (density), cdf() (cumulative probability), etc. can be provided for each distribution class. See the table below for an overview of generic functions and their purpose.\n\n\n\n\n\n\n\nFunction\nPackage\nDescription\n\n\n\nDistributional\n\n\n\n\npdf()\ndistributions3\nProbability density function (or probability mass function, typically via ddist())\n\n\nlog_pdf()\ndistributions3\nLog-density (or log-likelihood, typically via ddist(..., log = TRUE))\n\n\ncdf()\ndistributions3\nCumulative distribution function (typically via pdist())\n\n\nquantile()\nstats\nCompute quantiles (typically via qdist())\n\n\nrandom()\ndistributions3\nSimulate random samples (typically via rdist())\n\n\ncrps()\nscoringRules\n(Continuous) ranked probability scored (typically via crps_dist())\n\n\nMoments\n\n\n\n\nmean()\nbase\nExpectation\n\n\nvariance()\ndistributions3\nVariance\n\n\nskewness()\ndistributions3\nSkewness\n\n\nkurtosis()\ndistributions3\nExcess kurtosis\n\n\nSupport\n\n\n\n\nsupport()\ndistributions3\nMaximum and minimum of the support of the probability distribution\n\n\nis_discrete()\ndistributions3\nDetermine whether a distribution is discrete on its support\n\n\nis_continuous()\ndistributions3\nDetermine whether a distribution is continuous on its support\n\n\n\nIn the following we just show how the mean() and the cdf() method can be set up and applied. Some further details are provided at the end of this section, see also the underlying source code in the packages.\nFirst, the extractor functions for moments of the distribution can be typically be defined as functions of the list of parameters stored in the object:\n\nmean.Tobit &lt;- function(x, ...) {\n  m &lt;- x$mu * pnorm(x$mu/x$sigma) + x$sigma * dnorm(x$mu/x$sigma)\n  setNames(m, names(x))\n}\n\nIn a Tobit distribution the expectation is that of the underlying uncensored normal distribution (mu), suitably adjusted with the cumulative distribution function and probability density function of the uncensored distribution. For the three distributions in Y this yields:\n\nmean(Y)\n\n[1] 1.083 2.008 3.525\n\n\nIn the first two the effect of censoring is rather small, while in the third distribution it is more pronounced (due to the higher variance).\nFor evaluating the usual d/p/q/r functions in a standardized way, taking care of dimensions and naming etc., the distributions3 package provides the auxiliary function apply_dpqr():\n\ncdf.Tobit &lt;- function(d, x, drop = TRUE, elementwise = NULL, lower.tail = TRUE, log.p = FALSE, ...) {\n  FUN &lt;- function(at, d) {\n    p &lt;- pnorm(at, mean = d$mu, sd = d$sigma, lower.tail = lower.tail, log.p = log.p)\n    p[rep_len(at, length(p)) &lt; 0] &lt;- if(lower.tail) {\n      if(log.p) -Inf else 0\n    } else {\n      if(log.p) 0 else 1\n    }\n    p\n  }\n  apply_dpqr(d = d, FUN = FUN, at = x, type = \"probability\", elementwise = elementwise, drop = drop)\n}\n\nThis can be used to evaluate all distribution functions at the same argument (returning a vector by default):\n\ncdf(Y, 0)\n\n[1] 0.15866 0.02275 0.22663\n\n\nOr to evaluate all distribution functions at several arguments (returning a matrix by default):\n\ncdf(Y, c(0, 5))\n\n         p_0    p_5\n[1,] 0.15866 1.0000\n[2,] 0.02275 0.9987\n[3,] 0.22663 0.6915\n\n\nFinally, if the distribution and the argument have the same length, the default is to do the evaluating elementwise (always returning a vector):\n\ncdf(Y, 2:0)\n\n[1] 0.8413 0.1587 0.2266\n\ncdf(Y, 2:0, elementwise = TRUE)\n\n[1] 0.8413 0.1587 0.2266\n\n\nBut the evaluation can also be forced to be carried out for each combination of distribution and argument (always returning a matrix):\n\ncdf(Y, 2:0, elementwise = FALSE)\n\n        p_2    p_1     p_0\n[1,] 0.8413 0.5000 0.15866\n[2,] 0.5000 0.1587 0.02275\n[3,] 0.4013 0.3085 0.22663\n\n\nThese two additional methods are sufficient for the following illustrations. More details are provided below at the end of this section."
  },
  {
    "objectID": "vignettes/procast.html#adding-a-new-model",
    "href": "vignettes/procast.html#adding-a-new-model",
    "title": "Probabilistic Forecasting Infrastructure",
    "section": "\n3 Adding a new model",
    "text": "3 Adding a new model\nWhen setting up the procasting infrastructure, the heavy lifting is done with the creation of a suitable distribution class and methods. Interfacing a new model requires only a new prodist() method for setting up the probability distribution object based on a fitted model (and potentially a newdata set). The idea is to extract or predict the distribution parameters (mu and sigma in case of the Tobit distribution) and subsequently call the distribution class constructor (preserving observation names, if any).\n\nprodist.crch &lt;- function(object, newdata = NULL, na.action = na.pass, ...) {\n  par &lt;- predict(object, newdata = newdata, na.action = na.action, type = \"parameter\", ...)\n  Tobit(mu = setNames(par$location, rownames(par)), sigma = par$scale)\n}\n\nTo illustrate how this can be used in practice we fit a heteroscedastic Tobit model using the crch() function to a precipitation dataset from Innsbruck, Austria. As precipitation is often zero and never can become negative, a Tobit model is typically a good starting point for probabilistic modeling and forecasting. (See FIXME for more details.)\nThe data can be preprocessed in the following way:\n\ndata(\"RainIbk\", package = \"crch\")\nRainIbk &lt;- sqrt(RainIbk)\nRainIbk$ensmean &lt;- apply(RainIbk[, grep('^rainfc', names(RainIbk))], 1, mean)\nRainIbk$enssd   &lt;- apply(RainIbk[, grep('^rainfc', names(RainIbk))], 1, sd)\nRainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\nAnd the model is fitted via:\n\nlibrary(\"crch\")\nm &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0)\n\nThen, the predicted Tobit distributions for the first two observations can be obtained with the prodist() method obtained above:\n\nRainIbk2 &lt;- head(RainIbk, 2)\nprodist(m, newdata = RainIbk2)\n\n                       2000-01-04                        2000-01-05 \n\"Tobit(mu = 1.205, sigma = 2.16)\" \"Tobit(mu = 0.565, sigma = 1.98)\" \n\n\nThen, the mean() or cdf() method could be applied to this distribution vector. Alternatively, instead of calling these methods “by hand”, we can use the convenience procast() method to do so:\n\nprocast(m, newdata = RainIbk2, type = \"mean\")\n\n            mean\n2000-01-04 1.597\n2000-01-05 1.105\n\nprocast(m, newdata = RainIbk2, type = \"cdf\", at = 0)\n\n           probability\n2000-01-04      0.2888\n2000-01-05      0.3878\n\n\nInstead of \"mean\" and \"cdf\", we could also use the aliases \"response\" and \"probability\", respectively.\nSimilarly, other functions such as proscore(), proresiduals(), pithist(), or rootogram() can be used once all of the methods from the table above are defined."
  },
  {
    "objectID": "vignettes/procast.html#further-details",
    "href": "vignettes/procast.html#further-details",
    "title": "Probabilistic Forecasting Infrastructure",
    "section": "\n4 Further details",
    "text": "4 Further details\nMost of the remaining methods for the distribution objects follow the same structure as the mean() and cdf() method above, respectively. However, the random() and the support-related methods are slightly different. Hence, these are also briefly illustrated in the following.\nDrawing random() samples also uses apply_dpqr() with the argument n which is assured to always be a positive integer.\n\nrandom.Tobit &lt;- function(x, n = 1L, drop = TRUE, ...) {\n  n &lt;- make_positive_integer(n)\n  if (n == 0L) {\n    return(numeric(0L))\n  }\n  FUN &lt;- function(at, d) {\n    y &lt;- rnorm(n = at, mean = d$mu, sd = d$sigma)\n    y[y &lt; 0] &lt;- 0\n    y\n  }\n  apply_dpqr(d = x, FUN = FUN, at = n, type = \"random\", drop = drop)\n}\n\nIf drop = TRUE (the default), then one random sample for each distribution yields a vector, while several random samples for each distribution yields a matrix:\n\nrandom(Y, 1)\n\n[1] 0.03797 1.18499 5.94178\n\nrandom(Y, 3)\n\n       r_1   r_2    r_3\n[1,] 1.487 1.593 0.6649\n[2,] 2.136 2.136 0.3355\n[3,] 1.784 7.920 0.4718\n\n\nThe support() method should return a matrix of \"min\" and \"max\" for the distribution. The make_support() function helps to set the right names and dimension.\n\nsupport.Tobit &lt;- function(d, drop = TRUE, ...) {\n  min &lt;- rep(0, length(d))\n  max &lt;- rep(Inf, length(d))\n  make_support(min, max, d, drop = drop)\n}\nsupport(Y)\n\n     min max\n[1,]   0 Inf\n[2,]   0 Inf\n[3,]   0 Inf\n\n\nFinally, the is_discrete() and is_continuous() methods should return TRUE for distributions that are discrete or continuous, respectively, on the entire support. Thus, for mixed discrete-continuous distributions like the Tobit, both methods should return FALSE:\n\nis_discrete.Tobit &lt;- function(d, ...) {\n  setNames(rep.int(FALSE, length(d)), names(d))\n}\nis_continuous.Tobit &lt;- function(d, ...) {\n  setNames(rep.int(TRUE, length(d)), names(d))\n}\nis_discrete(Y)\n\n[1] FALSE FALSE FALSE\n\nis_continuous(Y)\n\n[1] TRUE TRUE TRUE"
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite topmodels in publications use:\n\nZeileis A, Lang MN, Stauffer R (2024). topmodels: Infrastructure for Forecasting and Assessment of Probabilistic Models. R package version 0.3-0, https://R-Forge.R-project.org/projects/topmodels/."
  },
  {
    "objectID": "man/geom_pithist.html",
    "href": "man/geom_pithist.html",
    "title": "topmodels",
    "section": "",
    "text": "Various geom_ and stat_ used within autoplot for producing PIT histograms.\n\nstat_pithist(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  style = c(\"bar\", \"line\"),\n  ...\n)\n\ngeom_pithist(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  style = c(\"bar\", \"line\"),\n  ...\n)\n\nstat_pithist_expected(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  freq = FALSE,\n  ...\n)\n\ngeom_pithist_expected(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  freq = FALSE,\n  ...\n)\n\nstat_pithist_confint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  level = 0.95,\n  type = \"approximation\",\n  freq = FALSE,\n  style = c(\"polygon\", \"line\"),\n  ...\n)\n\ngeom_pithist_confint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  level = 0.95,\n  type = \"approximation\",\n  freq = FALSE,\n  style = c(\"polygon\", \"line\"),\n  ...\n)\n\nstat_pithist_simint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  ...\n)\n\ngeom_pithist_simint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  ...\n)\n\n\n\n\n\nmapping\n\n\nSet of aesthetic mappings created by aes(). If specified and inherit.aes = TRUE (the default), it is combined with the default mapping at the top level of the plot. You must supply mapping if there is no plot mapping.\n\n\n\n\ndata\n\n\nThe data to be displayed in this layer. There are three options:\nIf NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\nA data.frame, or other object, will override the plot data. All objects will be fortified to produce a data frame. See fortify() for which variables will be created.\nA function will be called with a single argument, the plot data. The return value must be a data.frame, and will be used as the layer data. A function can be created from a formula (e.g. ~ head(.x, 10)).\n\n\n\n\ngeom\n\n\nThe geometric object to use to display the data for this layer. When using a stat_*() function to construct a layer, the geom argument can be used to override the default coupling between stats and geoms. The geom argument accepts the following:\n\n\nA Geom ggproto subclass, for example GeomPoint.\n\n\nA string naming the geom. To give the geom as a string, strip the function name of the geom_ prefix. For example, to use geom_point(), give the geom as “point”.\n\n\nFor more information and other ways to specify the geom, see the layer geom documentation.\n\n\n\n\n\n\nposition\n\n\nA position adjustment to use on the data for this layer. This can be used in various ways, including to prevent overplotting and improving the display. The position argument accepts the following:\n\n\nThe result of calling a position function, such as position_jitter(). This method allows for passing extra arguments to the position.\n\n\nA string naming the position adjustment. To give the position as a string, strip the function name of the position_ prefix. For example, to use position_jitter(), give the position as “jitter”.\n\n\nFor more information and other ways to specify the position, see the layer position documentation.\n\n\n\n\n\n\nna.rm\n\n\nIf FALSE, the default, missing values are removed with a warning. If TRUE, missing values are silently removed.\n\n\n\n\nshow.legend\n\n\nlogical. Should this layer be included in the legends? NA, the default, includes if any aesthetics are mapped. FALSE never includes, and TRUE always includes. It can also be a named logical vector to finely select the aesthetics to display.\n\n\n\n\ninherit.aes\n\n\nIf FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\n\n\n\nfreq\n\n\nlogical. If TRUE, the PIT histogram is represented by frequencies, the counts component of the result; if FALSE, probability densities, component density, are plotted (so that the histogram has a total area of one).\n\n\n\n\nstyle\n\n\ncharacter specifying the style of pithist. For style = “bar” a traditional PIT hisogram is drawn, for style = “line” solely the upper border line is plotted.\n\n\n\n\n…\n\n\nOther arguments passed on to layer()’s params argument. These arguments broadly fall into one of 4 categories below. Notably, further arguments to the position argument, or aesthetics that are required can not be passed through …. Unknown arguments that are not part of the 4 categories below are ignored.\n\n\nStatic aesthetics that are not mapped to a scale, but are at a fixed value and apply to the layer as a whole. For example, colour = “red” or linewidth = 3. The geom’s documentation has an Aesthetics section that lists the available options. The ‘required’ aesthetics cannot be passed on to the params. Please note that while passing unmapped aesthetics as vectors is technically possible, the order and required length is not guaranteed to be parallel to the input data.\n\n\nWhen constructing a layer using a stat_*() function, the … argument can be used to pass on parameters to the geom part of the layer. An example of this is stat_density(geom = “area”, outline.type = “both”). The geom’s documentation lists which parameters it can accept.\n\n\nInversely, when constructing a layer using a geom_*() function, the … argument can be used to pass on parameters to the stat part of the layer. An example of this is geom_area(stat = “density”, adjust = 0.5). The stat’s documentation lists which parameters it can accept.\n\n\nThe key_glyph argument of layer() may also be passed on through …. This can be one of the functions described as key glyphs, to change the display of the layer in the legend.\n\n\n\n\n\n\nstat\n\n\nThe statistical transformation to use on the data for this layer. When using a geom_*() function to construct a layer, the stat argument can be used the override the default coupling between geoms and stats. The stat argument accepts the following:\n\n\nA Stat ggproto subclass, for example StatCount.\n\n\nA string naming the stat. To give the stat as a string, strip the function name of the stat_ prefix. For example, to use stat_count(), give the stat as “count”.\n\n\nFor more information and other ways to specify the stat, see the layer stat documentation.\n\n\n\n\n\n\nscale\n\n\nOn which scale should the PIT residuals be computed: on the probability scale (“uniform”) or on the normal scale (“normal”).\n\n\n\n\nlevel\n\n\nnumeric. The confidence level required.\n\n\n\n\ntype\n\n\ncharacter. Which type of confidence interval should be plotted: ‘\"exact\"’ or ‘\"approximation\"’. According to Agresti and Coull (1998), for interval estimation of binomial proportions an approximation can be better than exact.\n\n\n\n\nlibrary(\"topmodels\")\n\nif (require(\"ggplot2\")) {\n  ## Fit model\n  data(\"CrabSatellites\", package = \"countreg\")\n  m1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n  m2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n  ## Compute pithist\n  p1 &lt;- pithist(m1_pois, type = \"random\", plot = FALSE)\n  p2 &lt;- pithist(m2_pois, type = \"random\", plot = FALSE)\n\n  d &lt;- c(p1, p2)\n\n  ## Create factor\n  main &lt;- attr(d, \"main\")\n  main &lt;- make.names(main, unique = TRUE)\n  d$group &lt;- factor(d$group, labels = main)\n\n  ## Plot bar style PIT histogram\n  gg1 &lt;- ggplot(data = d) +\n    geom_pithist(aes(x = mid, y = observed, width = width, group = group), freq = TRUE) +\n    geom_pithist_simint(aes(x = mid, ymin = simint_lwr, ymax = simint_upr), freq = TRUE) +\n    geom_pithist_confint(aes(x = mid, y = observed, width = width), style = \"line\", freq = TRUE) +\n    geom_pithist_expected(aes(x = mid, y = observed, width = width), freq = TRUE) +\n    facet_grid(group ~ .) +\n    xlab(\"PIT\") +\n    ylab(\"Frequency\")\n  gg1\n\n  gg2 &lt;- ggplot(data = d) +\n    geom_pithist(aes(x = mid, y = observed, width = width, group = group), freq = FALSE) +\n    geom_pithist_simint(aes(\n      x = mid, ymin = simint_lwr, ymax = simint_upr, y = observed,\n      width = width\n    ), freq = FALSE) +\n    geom_pithist_confint(aes(x = mid, y = observed, width = width), style = \"line\", freq = FALSE) +\n    geom_pithist_expected(aes(x = mid, y = observed, width = width), freq = FALSE) +\n    facet_grid(group ~ .) +\n    xlab(\"PIT\") +\n    ylab(\"Density\")\n  gg2\n\n  ## Plot line style PIT histogram\n  gg3 &lt;- ggplot(data = d) +\n    geom_pithist(aes(x = mid, y = observed, width = width, group = group), style = \"line\") +\n    geom_pithist_confint(aes(x = mid, y = observed, width = width), style = \"polygon\") +\n    facet_grid(group ~ .) +\n    xlab(\"PIT\") +\n    ylab(\"Density\")\n  gg3\n}",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "geom_pithist"
    ]
  },
  {
    "objectID": "man/geom_pithist.html#geom_-and-stat_-for-producing-pit-histograms-with-ggplot2",
    "href": "man/geom_pithist.html#geom_-and-stat_-for-producing-pit-histograms-with-ggplot2",
    "title": "topmodels",
    "section": "",
    "text": "Various geom_ and stat_ used within autoplot for producing PIT histograms.\n\nstat_pithist(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  style = c(\"bar\", \"line\"),\n  ...\n)\n\ngeom_pithist(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  style = c(\"bar\", \"line\"),\n  ...\n)\n\nstat_pithist_expected(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  freq = FALSE,\n  ...\n)\n\ngeom_pithist_expected(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist_expected\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  freq = FALSE,\n  ...\n)\n\nstat_pithist_confint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  level = 0.95,\n  type = \"approximation\",\n  freq = FALSE,\n  style = c(\"polygon\", \"line\"),\n  ...\n)\n\ngeom_pithist_confint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist_confint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  scale = c(\"uniform\", \"normal\"),\n  level = 0.95,\n  type = \"approximation\",\n  freq = FALSE,\n  style = c(\"polygon\", \"line\"),\n  ...\n)\n\nstat_pithist_simint(\n  mapping = NULL,\n  data = NULL,\n  geom = \"pithist_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  ...\n)\n\ngeom_pithist_simint(\n  mapping = NULL,\n  data = NULL,\n  stat = \"pithist_simint\",\n  position = \"identity\",\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  freq = FALSE,\n  ...\n)\n\n\n\n\n\nmapping\n\n\nSet of aesthetic mappings created by aes(). If specified and inherit.aes = TRUE (the default), it is combined with the default mapping at the top level of the plot. You must supply mapping if there is no plot mapping.\n\n\n\n\ndata\n\n\nThe data to be displayed in this layer. There are three options:\nIf NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\nA data.frame, or other object, will override the plot data. All objects will be fortified to produce a data frame. See fortify() for which variables will be created.\nA function will be called with a single argument, the plot data. The return value must be a data.frame, and will be used as the layer data. A function can be created from a formula (e.g. ~ head(.x, 10)).\n\n\n\n\ngeom\n\n\nThe geometric object to use to display the data for this layer. When using a stat_*() function to construct a layer, the geom argument can be used to override the default coupling between stats and geoms. The geom argument accepts the following:\n\n\nA Geom ggproto subclass, for example GeomPoint.\n\n\nA string naming the geom. To give the geom as a string, strip the function name of the geom_ prefix. For example, to use geom_point(), give the geom as “point”.\n\n\nFor more information and other ways to specify the geom, see the layer geom documentation.\n\n\n\n\n\n\nposition\n\n\nA position adjustment to use on the data for this layer. This can be used in various ways, including to prevent overplotting and improving the display. The position argument accepts the following:\n\n\nThe result of calling a position function, such as position_jitter(). This method allows for passing extra arguments to the position.\n\n\nA string naming the position adjustment. To give the position as a string, strip the function name of the position_ prefix. For example, to use position_jitter(), give the position as “jitter”.\n\n\nFor more information and other ways to specify the position, see the layer position documentation.\n\n\n\n\n\n\nna.rm\n\n\nIf FALSE, the default, missing values are removed with a warning. If TRUE, missing values are silently removed.\n\n\n\n\nshow.legend\n\n\nlogical. Should this layer be included in the legends? NA, the default, includes if any aesthetics are mapped. FALSE never includes, and TRUE always includes. It can also be a named logical vector to finely select the aesthetics to display.\n\n\n\n\ninherit.aes\n\n\nIf FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\n\n\n\nfreq\n\n\nlogical. If TRUE, the PIT histogram is represented by frequencies, the counts component of the result; if FALSE, probability densities, component density, are plotted (so that the histogram has a total area of one).\n\n\n\n\nstyle\n\n\ncharacter specifying the style of pithist. For style = “bar” a traditional PIT hisogram is drawn, for style = “line” solely the upper border line is plotted.\n\n\n\n\n…\n\n\nOther arguments passed on to layer()’s params argument. These arguments broadly fall into one of 4 categories below. Notably, further arguments to the position argument, or aesthetics that are required can not be passed through …. Unknown arguments that are not part of the 4 categories below are ignored.\n\n\nStatic aesthetics that are not mapped to a scale, but are at a fixed value and apply to the layer as a whole. For example, colour = “red” or linewidth = 3. The geom’s documentation has an Aesthetics section that lists the available options. The ‘required’ aesthetics cannot be passed on to the params. Please note that while passing unmapped aesthetics as vectors is technically possible, the order and required length is not guaranteed to be parallel to the input data.\n\n\nWhen constructing a layer using a stat_*() function, the … argument can be used to pass on parameters to the geom part of the layer. An example of this is stat_density(geom = “area”, outline.type = “both”). The geom’s documentation lists which parameters it can accept.\n\n\nInversely, when constructing a layer using a geom_*() function, the … argument can be used to pass on parameters to the stat part of the layer. An example of this is geom_area(stat = “density”, adjust = 0.5). The stat’s documentation lists which parameters it can accept.\n\n\nThe key_glyph argument of layer() may also be passed on through …. This can be one of the functions described as key glyphs, to change the display of the layer in the legend.\n\n\n\n\n\n\nstat\n\n\nThe statistical transformation to use on the data for this layer. When using a geom_*() function to construct a layer, the stat argument can be used the override the default coupling between geoms and stats. The stat argument accepts the following:\n\n\nA Stat ggproto subclass, for example StatCount.\n\n\nA string naming the stat. To give the stat as a string, strip the function name of the stat_ prefix. For example, to use stat_count(), give the stat as “count”.\n\n\nFor more information and other ways to specify the stat, see the layer stat documentation.\n\n\n\n\n\n\nscale\n\n\nOn which scale should the PIT residuals be computed: on the probability scale (“uniform”) or on the normal scale (“normal”).\n\n\n\n\nlevel\n\n\nnumeric. The confidence level required.\n\n\n\n\ntype\n\n\ncharacter. Which type of confidence interval should be plotted: ‘\"exact\"’ or ‘\"approximation\"’. According to Agresti and Coull (1998), for interval estimation of binomial proportions an approximation can be better than exact.\n\n\n\n\nlibrary(\"topmodels\")\n\nif (require(\"ggplot2\")) {\n  ## Fit model\n  data(\"CrabSatellites\", package = \"countreg\")\n  m1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n  m2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n  ## Compute pithist\n  p1 &lt;- pithist(m1_pois, type = \"random\", plot = FALSE)\n  p2 &lt;- pithist(m2_pois, type = \"random\", plot = FALSE)\n\n  d &lt;- c(p1, p2)\n\n  ## Create factor\n  main &lt;- attr(d, \"main\")\n  main &lt;- make.names(main, unique = TRUE)\n  d$group &lt;- factor(d$group, labels = main)\n\n  ## Plot bar style PIT histogram\n  gg1 &lt;- ggplot(data = d) +\n    geom_pithist(aes(x = mid, y = observed, width = width, group = group), freq = TRUE) +\n    geom_pithist_simint(aes(x = mid, ymin = simint_lwr, ymax = simint_upr), freq = TRUE) +\n    geom_pithist_confint(aes(x = mid, y = observed, width = width), style = \"line\", freq = TRUE) +\n    geom_pithist_expected(aes(x = mid, y = observed, width = width), freq = TRUE) +\n    facet_grid(group ~ .) +\n    xlab(\"PIT\") +\n    ylab(\"Frequency\")\n  gg1\n\n  gg2 &lt;- ggplot(data = d) +\n    geom_pithist(aes(x = mid, y = observed, width = width, group = group), freq = FALSE) +\n    geom_pithist_simint(aes(\n      x = mid, ymin = simint_lwr, ymax = simint_upr, y = observed,\n      width = width\n    ), freq = FALSE) +\n    geom_pithist_confint(aes(x = mid, y = observed, width = width), style = \"line\", freq = FALSE) +\n    geom_pithist_expected(aes(x = mid, y = observed, width = width), freq = FALSE) +\n    facet_grid(group ~ .) +\n    xlab(\"PIT\") +\n    ylab(\"Density\")\n  gg2\n\n  ## Plot line style PIT histogram\n  gg3 &lt;- ggplot(data = d) +\n    geom_pithist(aes(x = mid, y = observed, width = width, group = group), style = \"line\") +\n    geom_pithist_confint(aes(x = mid, y = observed, width = width), style = \"polygon\") +\n    facet_grid(group ~ .) +\n    xlab(\"PIT\") +\n    ylab(\"Density\")\n  gg3\n}",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "geom_pithist"
    ]
  },
  {
    "objectID": "man/topmodels.html",
    "href": "man/topmodels.html",
    "title": "topmodels",
    "section": "",
    "text": "A quick overview plot with panels for all graphical evaluation methods provided for probabilistic (regression) model objects. If plot = TRUE, the resulting objects are plotted by plot or autoplot before they are returned within a single list, depending on whether the package ggplot2 is loaded.\n\ntopmodels(\n  object,\n  plot = TRUE,\n  class = NULL,\n  newdata = NULL,\n  na.action = na.pass,\n  which = NULL,\n  ask = dev.interactive(),\n  spar = TRUE,\n  single_page = NULL,\n  envir = parent.frame(),\n  ...\n)\n\n\n\n\n\nobject\n\n\nAn object supported by “procast”.\n\n\n\n\nplot\n\n\nShould the plot or autoplot method be called to draw all chosen plots? Either set plot expicitly to “base” vs. “ggplot2” to choose the type of plot, or for a logical plot argument it’s chosen conditional if the package ggplot2 is loaded.\n\n\n\n\nclass\n\n\nShould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to employ NA.\n\n\n\n\nwhich\n\n\nCharacter or integer, selects the type of plot: “rootogram” graphically compares (square roots) of empirical frequencies with fitted frequencies from a probability model, “pithist” compares empirical probabilities from fitted models with a uniform distribution, “reliagram” shows a reliability diagram for assessing the reliability of a fitted probabilistic distributional forecast, “qqrplot” shows a quantile-quantile plot of quantile residuals, and “wormplot” shows a worm plot using quantile resiudals.\n\n\n\n\nask\n\n\nFor multiple plots, the user is asked to show the next plot. Argument is ignored for ggplot2 style graphics.\n\n\n\n\nspar\n\n\nShould graphical parameters be set? Will be ignored for ggplot2 style graphics.\n\n\n\n\nsingle_page\n\n\nLogical. Should all plots be shown on a single page? Only choice for ggplot2 style graphics.\n\n\n\n\nenvir\n\n\nenvironment, default is parent.frame()\n\n\n\n\n…\n\n\nArguments to be passed to rootogram, pithist, reliagram, qqrplot, and wormplot.\n\n\n\nRender the diagnostic graphics rootogram, pithist, reliagram qqrplot, and wormplot.\n\nA list containing the objects plotted conditional on the arguemnt which.\n\nrootogram, pithist, reliagram qqrplot, wormplot\n\n\nlibrary(\"topmodels\")\n\n\ndata(\"CrabSatellites\", package = \"countreg\")\nCrabSatellites2 &lt;- CrabSatellites[CrabSatellites$satellites &lt;= 1, ]\n\nm1 &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2 &lt;- glm(satellites ~ width + color, data = CrabSatellites2, family = binomial)\n\n## ggplot2 graphics\ntopmodels(m1, single_page = TRUE, nsim = 30, plot = \"ggplot2\")\n\n\n\n\n\n\ntopmodels(m2, single_page = TRUE, nsim = 30, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "topmodels"
    ]
  },
  {
    "objectID": "man/topmodels.html#plotting-graphical-evaluation-tools-for-probabilistic-models",
    "href": "man/topmodels.html#plotting-graphical-evaluation-tools-for-probabilistic-models",
    "title": "topmodels",
    "section": "",
    "text": "A quick overview plot with panels for all graphical evaluation methods provided for probabilistic (regression) model objects. If plot = TRUE, the resulting objects are plotted by plot or autoplot before they are returned within a single list, depending on whether the package ggplot2 is loaded.\n\ntopmodels(\n  object,\n  plot = TRUE,\n  class = NULL,\n  newdata = NULL,\n  na.action = na.pass,\n  which = NULL,\n  ask = dev.interactive(),\n  spar = TRUE,\n  single_page = NULL,\n  envir = parent.frame(),\n  ...\n)\n\n\n\n\n\nobject\n\n\nAn object supported by “procast”.\n\n\n\n\nplot\n\n\nShould the plot or autoplot method be called to draw all chosen plots? Either set plot expicitly to “base” vs. “ggplot2” to choose the type of plot, or for a logical plot argument it’s chosen conditional if the package ggplot2 is loaded.\n\n\n\n\nclass\n\n\nShould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to employ NA.\n\n\n\n\nwhich\n\n\nCharacter or integer, selects the type of plot: “rootogram” graphically compares (square roots) of empirical frequencies with fitted frequencies from a probability model, “pithist” compares empirical probabilities from fitted models with a uniform distribution, “reliagram” shows a reliability diagram for assessing the reliability of a fitted probabilistic distributional forecast, “qqrplot” shows a quantile-quantile plot of quantile residuals, and “wormplot” shows a worm plot using quantile resiudals.\n\n\n\n\nask\n\n\nFor multiple plots, the user is asked to show the next plot. Argument is ignored for ggplot2 style graphics.\n\n\n\n\nspar\n\n\nShould graphical parameters be set? Will be ignored for ggplot2 style graphics.\n\n\n\n\nsingle_page\n\n\nLogical. Should all plots be shown on a single page? Only choice for ggplot2 style graphics.\n\n\n\n\nenvir\n\n\nenvironment, default is parent.frame()\n\n\n\n\n…\n\n\nArguments to be passed to rootogram, pithist, reliagram, qqrplot, and wormplot.\n\n\n\nRender the diagnostic graphics rootogram, pithist, reliagram qqrplot, and wormplot.\n\nA list containing the objects plotted conditional on the arguemnt which.\n\nrootogram, pithist, reliagram qqrplot, wormplot\n\n\nlibrary(\"topmodels\")\n\n\ndata(\"CrabSatellites\", package = \"countreg\")\nCrabSatellites2 &lt;- CrabSatellites[CrabSatellites$satellites &lt;= 1, ]\n\nm1 &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2 &lt;- glm(satellites ~ width + color, data = CrabSatellites2, family = binomial)\n\n## ggplot2 graphics\ntopmodels(m1, single_page = TRUE, nsim = 30, plot = \"ggplot2\")\n\n\n\n\n\n\ntopmodels(m2, single_page = TRUE, nsim = 30, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "topmodels"
    ]
  },
  {
    "objectID": "man/plot.pithist.html",
    "href": "man/plot.pithist.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for probability integral transform (PIT) histograms of the class “pithist” computed by link{pithist}.\n\n## S3 method for class 'pithist'\nplot(\n  x,\n  single_graph = FALSE,\n  style = NULL,\n  freq = NULL,\n  expected = TRUE,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"exact\", \"approximation\"),\n  simint = NULL,\n  xlim = c(NA, NA),\n  ylim = c(0, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  axes = TRUE,\n  box = TRUE,\n  col = \"black\",\n  border = \"black\",\n  lwd = NULL,\n  lty = 1,\n  alpha_min = 0.2,\n  expected_col = NULL,\n  expected_lty = NULL,\n  expected_lwd = 1.75,\n  confint_col = NULL,\n  confint_lty = 2,\n  confint_lwd = 1.75,\n  confint_alpha = NULL,\n  simint_col = \"black\",\n  simint_lty = 1,\n  simint_lwd = 1.75,\n  ...\n)\n\n## S3 method for class 'pithist'\nlines(\n  x,\n  freq = NULL,\n  expected = FALSE,\n  confint = FALSE,\n  confint_level = 0.95,\n  confint_type = c(\"exact\", \"approximation\"),\n  simint = FALSE,\n  col = \"black\",\n  lwd = 2,\n  lty = 1,\n  expected_col = \"black\",\n  expected_lty = 2,\n  expected_lwd = 1.75,\n  confint_col = \"black\",\n  confint_lty = 1,\n  confint_lwd = 1.75,\n  confint_alpha = 1,\n  simint_col = \"black\",\n  simint_lty = 1,\n  simint_lwd = 1.75,\n  ...\n)\n\n## S3 method for class 'pithist'\nautoplot(\n  object,\n  single_graph = FALSE,\n  style = NULL,\n  freq = NULL,\n  expected = NULL,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"exact\", \"approximation\"),\n  simint = NULL,\n  xlim = c(NA, NA),\n  ylim = c(0, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  legend = FALSE,\n  theme = NULL,\n  colour = NULL,\n  fill = NULL,\n  size = NULL,\n  linetype = NULL,\n  alpha = NULL,\n  expected_colour = NULL,\n  expected_size = 0.75,\n  expected_linetype = NULL,\n  expected_alpha = NA,\n  confint_colour = NULL,\n  confint_fill = NULL,\n  confint_size = 0.75,\n  confint_linetype = NULL,\n  confint_alpha = NULL,\n  simint_colour = \"black\",\n  simint_size = 0.5,\n  simint_linetype = 1,\n  simint_alpha = NA,\n  ...\n)\n\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph? If yes, style must be set to “line”.\n\n\n\n\nstyle\n\n\nNULL or character specifying the style of pithist. For style = “bar” a traditional PIT hisogram is drawn, for style = “line” solely the upper border line is plotted. single_graph = TRUE always results in a combined line-style PIT histogram.\n\n\n\n\nfreq\n\n\nNULL or logical. TRUE will enforce the PIT to be represented by frequencies (counts) while FALSE will enforce densities.\n\n\n\n\nexpected\n\n\nlogical. Should the expected values be plotted as reference?\n\n\n\n\nconfint\n\n\nNULL or logical. Should confident intervals be drawn? Either logical or as\n\n\n\n\nconfint_level\n\n\nnumeric in [0, 1]. The confidence level to be shown.\n\n\n\n\nconfint_type\n\n\ncharacter. Which type of confidence interval should be plotted: ‘\"exact\"’ or ‘\"approximation\"’. According to Agresti and Coull (1998), for interval estimation of binomial proportions an approximation can be better than exact.\n\n\n\n\nsimint\n\n\nNULL or logical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized? character string defining one of ‘\"polygon\"’, ‘\"line\"’ or ‘\"none\"’. If freq = NULL it is taken from the object.\n\n\n\n\nxlim, ylim, xlab, ylab, main, axes, box\n\n\ngraphical parameters.\n\n\n\n\ncol, border, lwd, lty, alpha_min\n\n\ngraphical parameters for the main part of the base plot.\n\n\n\n\nsimint_col, simint_lty, simint_lwd, confint_col, confint_lty, confint_lwd, confint_alpha, expected_col, expected_lty, expected_lwd\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon in the base plot.\n\n\n\n\n…\n\n\nfurther graphical parameters passed to the plotting function.\n\n\n\n\nobject, x\n\n\nan object of class pithist.\n\n\n\n\nlegend\n\n\nlogical. Should a legend be added in the ggplot2 style graphic?\n\n\n\n\ntheme\n\n\nWhich ‘ggplot2’ theme should be used. If not set, theme_bw is employed.\n\n\n\n\ncolour, fill, size, linetype, alpha\n\n\ngraphical parameters for the histogram style part in the autoplot.\n\n\n\n\nsimint_colour, simint_size, simint_linetype, simint_alpha, confint_colour, confint_fill, confint_size, confint_linetype, expected_colour, expected_size, expected_linetype, expected_alpha\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon using autoplot.\n\n\n\nPIT histograms graphically evaluate the probability integral transform (PIT), i.e., the value that the predictive CDF attains at the observation, with a uniform distribution. For a well calibrated model fit, the observation will be drawn from the predictive distribution and the PIT will have a standard uniform distribution.\nPIT histograms can be rendered as ggplot2 or base R graphics by using the generics autoplot or plot. For a single base R graphically panel, lines adds an additional PIT histogram.\n\nAgresti A, Coull AB (1998). “Approximate is Better than “Exact” for Interval Estimation of Binomial Proportions.” The American Statistician, 52(2), 119–126. doi:10.1080/00031305.1998.10480550\nCzado C, Gneiting T, Held L (2009). “Predictive Model Assessment for Count Data.” Biometrics, 65(4), 1254–1261. doi:10.2307/2981683\nDawid AP (1984). “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach”, Journal of the Royal Statistical Society: Series A (General), 147(2), 278–292. doi:10.2307/2981683\nDiebold FX, Gunther TA, Tay AS (1998). “Evaluating Density Forecasts with Applications to Financial Risk Management”. International Economic Review, 39(4), 863–883. doi:10.2307/2527342\nGneiting T, Balabdaoui F, Raftery AE (2007). “Probabilistic Forecasts, Calibration and Sharpness”. Journal of the Royal Statistical Society: Series B (Methodological). 69(2), 243–268. doi:10.1111/j.1467-9868.2007.00587.x\n\npithist, procast, hist\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot pithist\npithist(m1_lm)\n\n\n\n\n\n\n## customize colors and style\npithist(m1_lm, expected_col = \"blue\", lty = 2, pch = 20, style = \"line\")\n\n\n\n\n\n\n## add separate model\nif (require(\"crch\", quietly = TRUE)) {\n  m1_crch &lt;- crch(dist ~ speed | speed, data = cars)\n  #lines(pithist(m1_crch, plot = FALSE), col = 2, lty = 2, confint_col = 2) #FIXME\n}\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model\n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ## compute pithists\n  pit2_lm &lt;- pithist(m2_lm, plot = FALSE)\n  pit2_crch &lt;- pithist(m2_crch, plot = FALSE)\n\n  ## plot in single graph with style \"line\"\n  plot(c(pit2_lm, pit2_crch),\n    col = c(1, 2), confint_col = c(1, 2), expected_col = 3,\n    style = \"line\", single_graph = TRUE\n  )\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot pithist as \"ggplot2\" graphic\npithist(m3_pois, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.pithist"
    ]
  },
  {
    "objectID": "man/plot.pithist.html#s3-methods-for-plotting-pit-histograms",
    "href": "man/plot.pithist.html#s3-methods-for-plotting-pit-histograms",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for probability integral transform (PIT) histograms of the class “pithist” computed by link{pithist}.\n\n## S3 method for class 'pithist'\nplot(\n  x,\n  single_graph = FALSE,\n  style = NULL,\n  freq = NULL,\n  expected = TRUE,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"exact\", \"approximation\"),\n  simint = NULL,\n  xlim = c(NA, NA),\n  ylim = c(0, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  axes = TRUE,\n  box = TRUE,\n  col = \"black\",\n  border = \"black\",\n  lwd = NULL,\n  lty = 1,\n  alpha_min = 0.2,\n  expected_col = NULL,\n  expected_lty = NULL,\n  expected_lwd = 1.75,\n  confint_col = NULL,\n  confint_lty = 2,\n  confint_lwd = 1.75,\n  confint_alpha = NULL,\n  simint_col = \"black\",\n  simint_lty = 1,\n  simint_lwd = 1.75,\n  ...\n)\n\n## S3 method for class 'pithist'\nlines(\n  x,\n  freq = NULL,\n  expected = FALSE,\n  confint = FALSE,\n  confint_level = 0.95,\n  confint_type = c(\"exact\", \"approximation\"),\n  simint = FALSE,\n  col = \"black\",\n  lwd = 2,\n  lty = 1,\n  expected_col = \"black\",\n  expected_lty = 2,\n  expected_lwd = 1.75,\n  confint_col = \"black\",\n  confint_lty = 1,\n  confint_lwd = 1.75,\n  confint_alpha = 1,\n  simint_col = \"black\",\n  simint_lty = 1,\n  simint_lwd = 1.75,\n  ...\n)\n\n## S3 method for class 'pithist'\nautoplot(\n  object,\n  single_graph = FALSE,\n  style = NULL,\n  freq = NULL,\n  expected = NULL,\n  confint = NULL,\n  confint_level = 0.95,\n  confint_type = c(\"exact\", \"approximation\"),\n  simint = NULL,\n  xlim = c(NA, NA),\n  ylim = c(0, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  legend = FALSE,\n  theme = NULL,\n  colour = NULL,\n  fill = NULL,\n  size = NULL,\n  linetype = NULL,\n  alpha = NULL,\n  expected_colour = NULL,\n  expected_size = 0.75,\n  expected_linetype = NULL,\n  expected_alpha = NA,\n  confint_colour = NULL,\n  confint_fill = NULL,\n  confint_size = 0.75,\n  confint_linetype = NULL,\n  confint_alpha = NULL,\n  simint_colour = \"black\",\n  simint_size = 0.5,\n  simint_linetype = 1,\n  simint_alpha = NA,\n  ...\n)\n\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph? If yes, style must be set to “line”.\n\n\n\n\nstyle\n\n\nNULL or character specifying the style of pithist. For style = “bar” a traditional PIT hisogram is drawn, for style = “line” solely the upper border line is plotted. single_graph = TRUE always results in a combined line-style PIT histogram.\n\n\n\n\nfreq\n\n\nNULL or logical. TRUE will enforce the PIT to be represented by frequencies (counts) while FALSE will enforce densities.\n\n\n\n\nexpected\n\n\nlogical. Should the expected values be plotted as reference?\n\n\n\n\nconfint\n\n\nNULL or logical. Should confident intervals be drawn? Either logical or as\n\n\n\n\nconfint_level\n\n\nnumeric in [0, 1]. The confidence level to be shown.\n\n\n\n\nconfint_type\n\n\ncharacter. Which type of confidence interval should be plotted: ‘\"exact\"’ or ‘\"approximation\"’. According to Agresti and Coull (1998), for interval estimation of binomial proportions an approximation can be better than exact.\n\n\n\n\nsimint\n\n\nNULL or logical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized? character string defining one of ‘\"polygon\"’, ‘\"line\"’ or ‘\"none\"’. If freq = NULL it is taken from the object.\n\n\n\n\nxlim, ylim, xlab, ylab, main, axes, box\n\n\ngraphical parameters.\n\n\n\n\ncol, border, lwd, lty, alpha_min\n\n\ngraphical parameters for the main part of the base plot.\n\n\n\n\nsimint_col, simint_lty, simint_lwd, confint_col, confint_lty, confint_lwd, confint_alpha, expected_col, expected_lty, expected_lwd\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon in the base plot.\n\n\n\n\n…\n\n\nfurther graphical parameters passed to the plotting function.\n\n\n\n\nobject, x\n\n\nan object of class pithist.\n\n\n\n\nlegend\n\n\nlogical. Should a legend be added in the ggplot2 style graphic?\n\n\n\n\ntheme\n\n\nWhich ‘ggplot2’ theme should be used. If not set, theme_bw is employed.\n\n\n\n\ncolour, fill, size, linetype, alpha\n\n\ngraphical parameters for the histogram style part in the autoplot.\n\n\n\n\nsimint_colour, simint_size, simint_linetype, simint_alpha, confint_colour, confint_fill, confint_size, confint_linetype, expected_colour, expected_size, expected_linetype, expected_alpha\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon using autoplot.\n\n\n\nPIT histograms graphically evaluate the probability integral transform (PIT), i.e., the value that the predictive CDF attains at the observation, with a uniform distribution. For a well calibrated model fit, the observation will be drawn from the predictive distribution and the PIT will have a standard uniform distribution.\nPIT histograms can be rendered as ggplot2 or base R graphics by using the generics autoplot or plot. For a single base R graphically panel, lines adds an additional PIT histogram.\n\nAgresti A, Coull AB (1998). “Approximate is Better than “Exact” for Interval Estimation of Binomial Proportions.” The American Statistician, 52(2), 119–126. doi:10.1080/00031305.1998.10480550\nCzado C, Gneiting T, Held L (2009). “Predictive Model Assessment for Count Data.” Biometrics, 65(4), 1254–1261. doi:10.2307/2981683\nDawid AP (1984). “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach”, Journal of the Royal Statistical Society: Series A (General), 147(2), 278–292. doi:10.2307/2981683\nDiebold FX, Gunther TA, Tay AS (1998). “Evaluating Density Forecasts with Applications to Financial Risk Management”. International Economic Review, 39(4), 863–883. doi:10.2307/2527342\nGneiting T, Balabdaoui F, Raftery AE (2007). “Probabilistic Forecasts, Calibration and Sharpness”. Journal of the Royal Statistical Society: Series B (Methodological). 69(2), 243–268. doi:10.1111/j.1467-9868.2007.00587.x\n\npithist, procast, hist\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot pithist\npithist(m1_lm)\n\n\n\n\n\n\n## customize colors and style\npithist(m1_lm, expected_col = \"blue\", lty = 2, pch = 20, style = \"line\")\n\n\n\n\n\n\n## add separate model\nif (require(\"crch\", quietly = TRUE)) {\n  m1_crch &lt;- crch(dist ~ speed | speed, data = cars)\n  #lines(pithist(m1_crch, plot = FALSE), col = 2, lty = 2, confint_col = 2) #FIXME\n}\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[, grep(\"^rainfc\", names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model\n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ## compute pithists\n  pit2_lm &lt;- pithist(m2_lm, plot = FALSE)\n  pit2_crch &lt;- pithist(m2_crch, plot = FALSE)\n\n  ## plot in single graph with style \"line\"\n  plot(c(pit2_lm, pit2_crch),\n    col = c(1, 2), confint_col = c(1, 2), expected_col = 3,\n    style = \"line\", single_graph = TRUE\n  )\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot pithist as \"ggplot2\" graphic\npithist(m3_pois, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.pithist"
    ]
  },
  {
    "objectID": "man/plot.reliagram.html",
    "href": "man/plot.reliagram.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for reliability diagrams of the class “reliagram” computed by link{reliagram}.\n\n## S3 method for class 'reliagram'\nplot(\n  x,\n  single_graph = FALSE,\n  minimum = 0,\n  confint = TRUE,\n  ref = TRUE,\n  xlim = c(0, 1),\n  ylim = c(0, 1),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  col = \"black\",\n  fill = adjustcolor(\"black\", alpha.f = 0.2),\n  alpha_min = 0.2,\n  lwd = 2,\n  pch = 19,\n  lty = 1,\n  type = NULL,\n  add_hist = TRUE,\n  add_info = TRUE,\n  add_rug = TRUE,\n  add_min = TRUE,\n  axes = TRUE,\n  box = TRUE,\n  ...\n)\n\n## S3 method for class 'reliagram'\nlines(\n  x,\n  minimum = 0,\n  confint = FALSE,\n  ref = FALSE,\n  col = \"black\",\n  fill = adjustcolor(\"black\", alpha.f = 0.2),\n  alpha_min = 0.2,\n  lwd = 2,\n  pch = 19,\n  lty = 1,\n  type = \"b\",\n  ...\n)\n\n## S3 method for class 'reliagram'\nautoplot(\n  object,\n  single_graph = FALSE,\n  minimum = 0,\n  confint = TRUE,\n  ref = TRUE,\n  xlim = c(0, 1),\n  ylim = c(0, 1),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  colour = \"black\",\n  fill = adjustcolor(\"black\", alpha.f = 0.2),\n  alpha_min = 0.2,\n  size = 1,\n  shape = 19,\n  linetype = 1,\n  type = NULL,\n  add_hist = TRUE,\n  add_info = TRUE,\n  add_rug = TRUE,\n  add_min = TRUE,\n  legend = FALSE,\n  ...\n)\n\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph?\n\n\n\n\nminimum, ref, xlim, ylim, col, fill, alpha_min, lwd, pch, lty, type, add_hist, add_info, add_rug, add_min, axes, box\n\n\nadditional graphical parameters for base plots, whereby x is a object of class reliagram.\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be calculated and drawn?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters.\n\n\n\n\n…\n\n\nfurther graphical parameters.\n\n\n\n\nobject, x\n\n\nan object of class reliagram.\n\n\n\n\ncolour, size, shape, linetype, legend\n\n\ngraphical parameters passed for ggplot2 style plots, whereby object is a object of class reliagram.\n\n\n\nReliagrams evaluate if a probability model is calibrated (reliable) by first partitioning the forecast probability for a binary event into a certain number of bins and then plotting (within each bin) the averaged forecast probability against the observered/empirical relative frequency.\nFor continous probability forecasts, reliability diagrams can be plotted either for a pre-specified threshold or for a specific quantile probability of the response values.\nReliagrams can be rendered as ggplot2 or base R graphics by using the generics autoplot or plot. For a single base R graphically panel, points adds an additional reliagram.\n\nWilks DS (2011) Statistical Methods in the Atmospheric Sciences, 3rd ed., Academic Press, 704 pp.\n\nlink{reliagram}, procast\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot reliagram\nreliagram(m1_lm)\n\n\n\n\n\n\n## customize colors\nreliagram(m1_lm, ref = \"blue\", lty = 2, pch = 20)\n\n## add separate model\nif (require(\"crch\", quietly = TRUE)) {\n  m1_crch &lt;- crch(dist ~ speed | speed, data = cars)\n  lines(reliagram(m1_crch, plot = FALSE), col = 2, lty = 2, confint = 2)\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model \n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ## compute reliagrams\n  rel2_lm &lt;- reliagram(m2_lm, plot = FALSE)\n  rel2_crch &lt;- reliagram(m2_crch, plot = FALSE)\n\n  ## plot in single graph\n  plot(c(rel2_lm, rel2_crch), col = c(1, 2), confint = c(1, 2), ref = 3, single_graph = TRUE)\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois  &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot reliagram as \"ggplot2\" graphic\nreliagram(m3_pois, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.reliagram"
    ]
  },
  {
    "objectID": "man/plot.reliagram.html#s3-methods-for-a-reliagram-extended-reliability-diagram",
    "href": "man/plot.reliagram.html#s3-methods-for-a-reliagram-extended-reliability-diagram",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for reliability diagrams of the class “reliagram” computed by link{reliagram}.\n\n## S3 method for class 'reliagram'\nplot(\n  x,\n  single_graph = FALSE,\n  minimum = 0,\n  confint = TRUE,\n  ref = TRUE,\n  xlim = c(0, 1),\n  ylim = c(0, 1),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  col = \"black\",\n  fill = adjustcolor(\"black\", alpha.f = 0.2),\n  alpha_min = 0.2,\n  lwd = 2,\n  pch = 19,\n  lty = 1,\n  type = NULL,\n  add_hist = TRUE,\n  add_info = TRUE,\n  add_rug = TRUE,\n  add_min = TRUE,\n  axes = TRUE,\n  box = TRUE,\n  ...\n)\n\n## S3 method for class 'reliagram'\nlines(\n  x,\n  minimum = 0,\n  confint = FALSE,\n  ref = FALSE,\n  col = \"black\",\n  fill = adjustcolor(\"black\", alpha.f = 0.2),\n  alpha_min = 0.2,\n  lwd = 2,\n  pch = 19,\n  lty = 1,\n  type = \"b\",\n  ...\n)\n\n## S3 method for class 'reliagram'\nautoplot(\n  object,\n  single_graph = FALSE,\n  minimum = 0,\n  confint = TRUE,\n  ref = TRUE,\n  xlim = c(0, 1),\n  ylim = c(0, 1),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  colour = \"black\",\n  fill = adjustcolor(\"black\", alpha.f = 0.2),\n  alpha_min = 0.2,\n  size = 1,\n  shape = 19,\n  linetype = 1,\n  type = NULL,\n  add_hist = TRUE,\n  add_info = TRUE,\n  add_rug = TRUE,\n  add_min = TRUE,\n  legend = FALSE,\n  ...\n)\n\n\n\n\n\nsingle_graph\n\n\nlogical. Should all computed extended reliability diagrams be plotted in a single graph?\n\n\n\n\nminimum, ref, xlim, ylim, col, fill, alpha_min, lwd, pch, lty, type, add_hist, add_info, add_rug, add_min, axes, box\n\n\nadditional graphical parameters for base plots, whereby x is a object of class reliagram.\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be calculated and drawn?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters.\n\n\n\n\n…\n\n\nfurther graphical parameters.\n\n\n\n\nobject, x\n\n\nan object of class reliagram.\n\n\n\n\ncolour, size, shape, linetype, legend\n\n\ngraphical parameters passed for ggplot2 style plots, whereby object is a object of class reliagram.\n\n\n\nReliagrams evaluate if a probability model is calibrated (reliable) by first partitioning the forecast probability for a binary event into a certain number of bins and then plotting (within each bin) the averaged forecast probability against the observered/empirical relative frequency.\nFor continous probability forecasts, reliability diagrams can be plotted either for a pre-specified threshold or for a specific quantile probability of the response values.\nReliagrams can be rendered as ggplot2 or base R graphics by using the generics autoplot or plot. For a single base R graphically panel, points adds an additional reliagram.\n\nWilks DS (2011) Statistical Methods in the Atmospheric Sciences, 3rd ed., Academic Press, 704 pp.\n\nlink{reliagram}, procast\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot reliagram\nreliagram(m1_lm)\n\n\n\n\n\n\n## customize colors\nreliagram(m1_lm, ref = \"blue\", lty = 2, pch = 20)\n\n## add separate model\nif (require(\"crch\", quietly = TRUE)) {\n  m1_crch &lt;- crch(dist ~ speed | speed, data = cars)\n  lines(reliagram(m1_crch, plot = FALSE), col = 2, lty = 2, confint = 2)\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model \n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ## compute reliagrams\n  rel2_lm &lt;- reliagram(m2_lm, plot = FALSE)\n  rel2_crch &lt;- reliagram(m2_crch, plot = FALSE)\n\n  ## plot in single graph\n  plot(c(rel2_lm, rel2_crch), col = c(1, 2), confint = c(1, 2), ref = 3, single_graph = TRUE)\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois  &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot reliagram as \"ggplot2\" graphic\nreliagram(m3_pois, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.reliagram"
    ]
  },
  {
    "objectID": "man/VolcanoHeights.html",
    "href": "man/VolcanoHeights.html",
    "title": "topmodels",
    "section": "",
    "text": "Heights of 218 volcanos taken from Tukey (1972).\n\ndata(\"VolcanoHeights\", package = \"topmodels\")\n\n\nA numeric vector of 218 volcano heights (in 1000 feet).\n\nThe data are taken from Tukey (1972) who obtained them from The World Almanac, 1966 (New York: The New York World-Telegram and The Sun, 1966), pp. 282–283.\n\nFigure 1 in Tukey (1972).\n\nTukey JW (1972). “Some Graphic and Semigraphic Displays.” In Bancroft TA (ed.), Statistical Papers in Honor of George W. Snedecor, pp. 293–316. Iowa State University Press, Ames, IA. Reprinted in Cleveland WS (ed.): The Collected Works of John W. Tukey, Volume V. Graphics: 1965–1985, Wadsworth & Brooks/Cole, Pacific Grove, CA, 1988.\n\n\nlibrary(\"topmodels\")\n\n## Rootograms from Tukey (1972)\n## (some 'breaks' don't match exactly)\nlibrary(\"topmodels\")\ndata(\"VolcanoHeights\", package = \"topmodels\")\n\n## Figure 16\nrootogram(lm(VolcanoHeights ~ 1), style = \"standing\",\n  breaks = 0:20 - 0.01, expected = FALSE, confint = FALSE)\n\n\n\n\n\n\n## Figure 17\nrootogram(lm(sqrt(1000 * VolcanoHeights) ~ 1), style = \"standing\",\n  breaks = 0:17 * 10 - 1.1, expected = FALSE, confint = FALSE)\n\n\n\n\n\n\n## Figure 18\nrootogram(lm(sqrt(1000 * VolcanoHeights) ~ 1), style = \"hanging\",\n  breaks = -2:18 * 10 - 1.1, confint = FALSE)\n\n\n\n\n\n\n## Figure 19\nrootogram(lm(sqrt(1000 * VolcanoHeights) ~ 1), style = \"suspended\",\n  breaks = -2:18 * 10 - 1.1, ylim = c(6, -2), confint = FALSE)\nabline(h = c(-1.5, -1, 1, 1.5), lty = c(2, 3, 3, 2))",
    "crumbs": [
      "Data sets",
      "VolcanoHeights"
    ]
  },
  {
    "objectID": "man/VolcanoHeights.html#tukeys-volcano-heights",
    "href": "man/VolcanoHeights.html#tukeys-volcano-heights",
    "title": "topmodels",
    "section": "",
    "text": "Heights of 218 volcanos taken from Tukey (1972).\n\ndata(\"VolcanoHeights\", package = \"topmodels\")\n\n\nA numeric vector of 218 volcano heights (in 1000 feet).\n\nThe data are taken from Tukey (1972) who obtained them from The World Almanac, 1966 (New York: The New York World-Telegram and The Sun, 1966), pp. 282–283.\n\nFigure 1 in Tukey (1972).\n\nTukey JW (1972). “Some Graphic and Semigraphic Displays.” In Bancroft TA (ed.), Statistical Papers in Honor of George W. Snedecor, pp. 293–316. Iowa State University Press, Ames, IA. Reprinted in Cleveland WS (ed.): The Collected Works of John W. Tukey, Volume V. Graphics: 1965–1985, Wadsworth & Brooks/Cole, Pacific Grove, CA, 1988.\n\n\nlibrary(\"topmodels\")\n\n## Rootograms from Tukey (1972)\n## (some 'breaks' don't match exactly)\nlibrary(\"topmodels\")\ndata(\"VolcanoHeights\", package = \"topmodels\")\n\n## Figure 16\nrootogram(lm(VolcanoHeights ~ 1), style = \"standing\",\n  breaks = 0:20 - 0.01, expected = FALSE, confint = FALSE)\n\n\n\n\n\n\n## Figure 17\nrootogram(lm(sqrt(1000 * VolcanoHeights) ~ 1), style = \"standing\",\n  breaks = 0:17 * 10 - 1.1, expected = FALSE, confint = FALSE)\n\n\n\n\n\n\n## Figure 18\nrootogram(lm(sqrt(1000 * VolcanoHeights) ~ 1), style = \"hanging\",\n  breaks = -2:18 * 10 - 1.1, confint = FALSE)\n\n\n\n\n\n\n## Figure 19\nrootogram(lm(sqrt(1000 * VolcanoHeights) ~ 1), style = \"suspended\",\n  breaks = -2:18 * 10 - 1.1, ylim = c(6, -2), confint = FALSE)\nabline(h = c(-1.5, -1, 1, 1.5), lty = c(2, 3, 3, 2))",
    "crumbs": [
      "Data sets",
      "VolcanoHeights"
    ]
  },
  {
    "objectID": "man/pithist.html",
    "href": "man/pithist.html",
    "title": "topmodels",
    "section": "",
    "text": "Probability integral transform (PIT) histograms graphically compare empirical probabilities from fitted models with a uniform distribution. If plot = TRUE, the resulting object of class “pithist” is plotted by plot.pithist or autoplot.pithist depending on whether the package ggplot2 is loaded, before the “pithist” object is returned.\n\npithist(object, ...)\n\n## Default S3 method:\npithist(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  scale = c(\"uniform\", \"normal\"),\n  breaks = NULL,\n  type = c(\"expected\", \"random\"),\n  nsim = 1L,\n  delta = NULL,\n  simint = NULL,\n  simint_level = 0.95,\n  simint_nrep = 250,\n  style = c(\"bar\", \"line\"),\n  freq = FALSE,\n  expected = TRUE,\n  confint = TRUE,\n  xlab = \"PIT\",\n  ylab = if (freq) \"Frequency\" else \"Density\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which probability integral transforms can be extracted using the generic function procast.\n\n\n\n\n…\n\n\nfurther graphical parameters forwarded to the plotting functions.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nlogical or character. Should the plot or autoplot method be called to draw the computed extended reliability diagram? Logical FALSE will suppress plotting, TRUE (default) will choose the type of plot conditional if the package ggplot2 is loaded. Alternatively “base” or “ggplot2” can be specified to explicitly choose the type of plot.\n\n\n\n\nclass\n\n\nshould the invisible return value be either a data.frame or a tbl_df. Can be set to “data.frame” or “tibble” to explicitly specify the return class, or to NULL (default) in which case the return class is conditional on whether the package “tibble” is loaded.\n\n\n\n\nscale\n\n\ncontrols the scale on which the PIT residuals are computed: on the probability scale (“uniform”; default) or on the normal scale (“normal”).\n\n\n\n\nbreaks\n\n\nNULL (default) or numeric to manually specify the breaks for the rootogram intervals. A single numeric (larger 0) specifies the number of breaks to be automatically chosen, multiple numeric values are interpreted as manually specified breaks.\n\n\n\n\ntype\n\n\ncharacter. In case of discrete distributions, should an expected (non-normal) PIT histogram be computed according to Czado et al. (2009) (“expected”; default) or should the PIT be drawn randomly from the corresponding interval (“random”)?\n\n\n\n\nnsim\n\n\npositive integer, defaults to 1L. Only used when type = “random”; how many simulated PITs should be drawn?\n\n\n\n\ndelta\n\n\nNULL or numeric. The minimal difference to compute the range of probabilities corresponding to each observation to get (randomized) quantile residuals. For NULL (default), the minimal observed difference in the response divided by 5e-6 is used.\n\n\n\n\nsimint\n\n\nNULL (default) or logical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized?\n\n\n\n\nsimint_level\n\n\nnumeric, defaults to 0.95. The confidence level required for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsimint_nrep\n\n\nnumeric, defaults to 250. The repetition number of simulated quantiles for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nstyle\n\n\ncharacter specifying plotting style. For style = “bar” (default) a traditional PIT histogram is drawn, style = “line” solely plots the upper border of the bars. If single_graph = TRUE is used (see plot.pithist), line-style PIT histograms will be enforced.\n\n\n\n\nfreq\n\n\nlogical. If TRUE, the PIT histogram is represented by frequencies, the counts component of the result; if FALSE, probability densities, component density, are plotted (so that the histogram has a total area of one).\n\n\n\n\nexpected\n\n\nlogical. Should the expected values be plotted as reference?\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be drawn?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters passed to plot.pithist or autoplot.pithist.\n\n\n\nPIT histograms graphically evaluate the probability integral transform (PIT), i.e., the value that the predictive CDF attains at the observation, with a uniform distribution. For a well calibrated model fit, the PIT will have a standard uniform distribution. For computation, pithist leverages the function proresiduals employing the procast generic and then essentially draws a hist.\nIn addition to the plot and autoplot method for pithist objects, it is also possible to combine two (or more) PIT histograms by c/rbind, which creates a set of PIT histograms that can then be plotted in one go.\n\nAn object of class “pithist” inheriting from data.frame or tbl_df conditional on the argument class including the following variables:\n\n\n\nx\n\n\nhistogram interval midpoints on the x-axis,\n\n\n\n\ny\n\n\nbottom coordinate of the histogram bars,\n\n\n\n\nwidth\n\n\nwidths of the histogram bars,\n\n\n\n\nconfint_lwr\n\n\nlower bound of the confidence interval,\n\n\n\n\nconfint_upr\n\n\nupper bound of the confidence interval,\n\n\n\n\nexpected\n\n\ny-coordinate of the expected curve.\n\n\n\nAdditionally, freq, xlab, ylab, main, and confint_level are stored as attributes.\n\nAgresti A, Coull AB (1998). “Approximate is Better than “Exact” for Interval Estimation of Binomial Proportions.” The American Statistician, 52(2), 119–126. doi:10.1080/00031305.1998.10480550\nCzado C, Gneiting T, Held L (2009). “Predictive Model Assessment for Count Data.” Biometrics, 65(4), 1254–1261. doi:10.1111/j.1541-0420.2009.01191.x\nDawid AP (1984). “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach”, Journal of the Royal Statistical Society: Series A (General), 147(2), 278–292. doi:10.2307/2981683\nDiebold FX, Gunther TA, Tay AS (1998). “Evaluating Density Forecasts with Applications to Financial Risk Management”. International Economic Review, 39(4), 863–883. doi:10.2307/2527342\nGneiting T, Balabdaoui F, Raftery AE (2007). “Probabilistic Forecasts, Calibration and Sharpness”. Journal of the Royal Statistical Society: Series B (Statistical Methodology). 69(2), 243–268. doi:10.1111/j.1467-9868.2007.00587.x\n\nplot.pithist, proresiduals, procast\n\n\nlibrary(\"topmodels\")\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot pithist\npithist(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot pithist as base graphic\np1 &lt;- pithist(m1_pois, plot = FALSE)\np2 &lt;- pithist(m2_pois, plot = FALSE)\n\n## plot combined pithist as \"ggplot2\" graphic\nggplot2::autoplot(c(p1, p2), single_graph = TRUE, style = \"line\", col = c(1, 2))",
    "crumbs": [
      "Probabilistic model diagnostics",
      "pithist"
    ]
  },
  {
    "objectID": "man/pithist.html#pit-histograms-for-assessing-goodness-of-fit-of-probability-models",
    "href": "man/pithist.html#pit-histograms-for-assessing-goodness-of-fit-of-probability-models",
    "title": "topmodels",
    "section": "",
    "text": "Probability integral transform (PIT) histograms graphically compare empirical probabilities from fitted models with a uniform distribution. If plot = TRUE, the resulting object of class “pithist” is plotted by plot.pithist or autoplot.pithist depending on whether the package ggplot2 is loaded, before the “pithist” object is returned.\n\npithist(object, ...)\n\n## Default S3 method:\npithist(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  scale = c(\"uniform\", \"normal\"),\n  breaks = NULL,\n  type = c(\"expected\", \"random\"),\n  nsim = 1L,\n  delta = NULL,\n  simint = NULL,\n  simint_level = 0.95,\n  simint_nrep = 250,\n  style = c(\"bar\", \"line\"),\n  freq = FALSE,\n  expected = TRUE,\n  confint = TRUE,\n  xlab = \"PIT\",\n  ylab = if (freq) \"Frequency\" else \"Density\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which probability integral transforms can be extracted using the generic function procast.\n\n\n\n\n…\n\n\nfurther graphical parameters forwarded to the plotting functions.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nlogical or character. Should the plot or autoplot method be called to draw the computed extended reliability diagram? Logical FALSE will suppress plotting, TRUE (default) will choose the type of plot conditional if the package ggplot2 is loaded. Alternatively “base” or “ggplot2” can be specified to explicitly choose the type of plot.\n\n\n\n\nclass\n\n\nshould the invisible return value be either a data.frame or a tbl_df. Can be set to “data.frame” or “tibble” to explicitly specify the return class, or to NULL (default) in which case the return class is conditional on whether the package “tibble” is loaded.\n\n\n\n\nscale\n\n\ncontrols the scale on which the PIT residuals are computed: on the probability scale (“uniform”; default) or on the normal scale (“normal”).\n\n\n\n\nbreaks\n\n\nNULL (default) or numeric to manually specify the breaks for the rootogram intervals. A single numeric (larger 0) specifies the number of breaks to be automatically chosen, multiple numeric values are interpreted as manually specified breaks.\n\n\n\n\ntype\n\n\ncharacter. In case of discrete distributions, should an expected (non-normal) PIT histogram be computed according to Czado et al. (2009) (“expected”; default) or should the PIT be drawn randomly from the corresponding interval (“random”)?\n\n\n\n\nnsim\n\n\npositive integer, defaults to 1L. Only used when type = “random”; how many simulated PITs should be drawn?\n\n\n\n\ndelta\n\n\nNULL or numeric. The minimal difference to compute the range of probabilities corresponding to each observation to get (randomized) quantile residuals. For NULL (default), the minimal observed difference in the response divided by 5e-6 is used.\n\n\n\n\nsimint\n\n\nNULL (default) or logical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized?\n\n\n\n\nsimint_level\n\n\nnumeric, defaults to 0.95. The confidence level required for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsimint_nrep\n\n\nnumeric, defaults to 250. The repetition number of simulated quantiles for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nstyle\n\n\ncharacter specifying plotting style. For style = “bar” (default) a traditional PIT histogram is drawn, style = “line” solely plots the upper border of the bars. If single_graph = TRUE is used (see plot.pithist), line-style PIT histograms will be enforced.\n\n\n\n\nfreq\n\n\nlogical. If TRUE, the PIT histogram is represented by frequencies, the counts component of the result; if FALSE, probability densities, component density, are plotted (so that the histogram has a total area of one).\n\n\n\n\nexpected\n\n\nlogical. Should the expected values be plotted as reference?\n\n\n\n\nconfint\n\n\nlogical. Should confident intervals be drawn?\n\n\n\n\nxlab, ylab, main\n\n\ngraphical parameters passed to plot.pithist or autoplot.pithist.\n\n\n\nPIT histograms graphically evaluate the probability integral transform (PIT), i.e., the value that the predictive CDF attains at the observation, with a uniform distribution. For a well calibrated model fit, the PIT will have a standard uniform distribution. For computation, pithist leverages the function proresiduals employing the procast generic and then essentially draws a hist.\nIn addition to the plot and autoplot method for pithist objects, it is also possible to combine two (or more) PIT histograms by c/rbind, which creates a set of PIT histograms that can then be plotted in one go.\n\nAn object of class “pithist” inheriting from data.frame or tbl_df conditional on the argument class including the following variables:\n\n\n\nx\n\n\nhistogram interval midpoints on the x-axis,\n\n\n\n\ny\n\n\nbottom coordinate of the histogram bars,\n\n\n\n\nwidth\n\n\nwidths of the histogram bars,\n\n\n\n\nconfint_lwr\n\n\nlower bound of the confidence interval,\n\n\n\n\nconfint_upr\n\n\nupper bound of the confidence interval,\n\n\n\n\nexpected\n\n\ny-coordinate of the expected curve.\n\n\n\nAdditionally, freq, xlab, ylab, main, and confint_level are stored as attributes.\n\nAgresti A, Coull AB (1998). “Approximate is Better than “Exact” for Interval Estimation of Binomial Proportions.” The American Statistician, 52(2), 119–126. doi:10.1080/00031305.1998.10480550\nCzado C, Gneiting T, Held L (2009). “Predictive Model Assessment for Count Data.” Biometrics, 65(4), 1254–1261. doi:10.1111/j.1541-0420.2009.01191.x\nDawid AP (1984). “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach”, Journal of the Royal Statistical Society: Series A (General), 147(2), 278–292. doi:10.2307/2981683\nDiebold FX, Gunther TA, Tay AS (1998). “Evaluating Density Forecasts with Applications to Financial Risk Management”. International Economic Review, 39(4), 863–883. doi:10.2307/2527342\nGneiting T, Balabdaoui F, Raftery AE (2007). “Probabilistic Forecasts, Calibration and Sharpness”. Journal of the Royal Statistical Society: Series B (Statistical Methodology). 69(2), 243–268. doi:10.1111/j.1467-9868.2007.00587.x\n\nplot.pithist, proresiduals, procast\n\n\nlibrary(\"topmodels\")\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot pithist\npithist(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot pithist as base graphic\np1 &lt;- pithist(m1_pois, plot = FALSE)\np2 &lt;- pithist(m2_pois, plot = FALSE)\n\n## plot combined pithist as \"ggplot2\" graphic\nggplot2::autoplot(c(p1, p2), single_graph = TRUE, style = \"line\", col = c(1, 2))",
    "crumbs": [
      "Probabilistic model diagnostics",
      "pithist"
    ]
  },
  {
    "objectID": "man/proresiduals.html",
    "href": "man/proresiduals.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and default method for (randomized) quantile residuals, PIT, Pearson, and raw response residuals based on distributions3 support.\n\nproresiduals(object, ...)\n\n## Default S3 method:\nproresiduals(\n  object,\n  newdata = NULL,\n  type = c(\"quantile\", \"pit\", \"pearson\", \"response\"),\n  nsim = NULL,\n  prob = NULL,\n  delta = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object for which a newresponse and a prodist method is available.\n\n\n\n\n…\n\n\nfurther parameters passed to methods.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\ntype\n\n\ncharacter indicating whether quantile (default), PIT, Pearson, or raw response residuals should be computed.\n\n\n\n\nnsim\n\n\ninteger. The number of randomly simulated residuals of type = “quantile” or “pit”. By default one simulation is returned.\n\n\n\n\nprob\n\n\nnumeric. Instead of simulating the probabilities (between 0 and 1) for type = “quantile” or “pit”, a vector of probabilities can be specified, e.g., prob = 0.5 corresponding to mid-quantile residuals.\n\n\n\n\ndelta\n\n\nnumeric. The minimal difference to compute the range of proabilities corresponding to each observation according to get (randomized) “quantile” or “pit” residuals. For NULL, the minimal observed difference in the resonse divided by 5e-6 is used. Ignored for continuous distributions.\n\n\n\nThe new generic function proresiduals comes with a powerful default method that is based on the following idea: newresponse and prodist can be used to extract the observed response and expected distribution for it, respectively. For all model classes that have methods for these two generic functions, proresiduals can compute a range of different types of residuals.\nThe simplest definition of residuals are the so-called “response” residuals which simply compute the difference between the observations and the expected means. The “pearson” residuals additionally standardize these residuals by the square root of the expected variance. Thus, these residuals are based only on the first and on the first two moments, respectively.\nTo assess the entire distribution and not just the first moments, there are also residuals based on the probability integral transform (PIT). For regression models with a continuous response distribution, “pit” residuals (see Warton 2007) are simply the expected cumulative distribution (CDF) evaluated at the observations (Dawid, 1984). For discrete distributions, a uniform random value is drawn from the range of probabilities between the CDF at the observation and the supremum of the CDF to the left of it. If the model fits well the PIT residuals should be uniformly distributed.\nIn order to obtain normally distributed residuals for well-fitting models (like often desired in linear regression models), “quantile” residuals, proposed by Dunn and Smyth (1996), additionally transform the PIT residuals by the standard normal quantile function.\nAs quantile residuals and PIT residuals are subject to randomness for discrete distributions (and also for mixed discrete-continuous distributions), it is sometimes useful to explore the extent of the random variation. This can be done either by obtaining multiple replications (via nsim) or by computing fixed quantiles of each probability interval such as prob = 0.5 (corresponding to mid-quantile residuals, see Feng et al. 2020). Another common setting is prob = c(0, 1) yielding the range of possible residuals.\n\nA vector or matrix of residuals. A matrix of residuals is returned if more than one replication of quantile or PIT residuals is computed, i.e., if either random &gt; 1 or random = FALSE and length(prob) &gt; 1.\n\nDawid AP (1984). “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach.” Journal of the Royal Statistical Society A, 147(2), 278–292. doi:10.2307/2981683.\nDunn KP, Smyth GK (1996). “Randomized Quantile Residuals.” Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\nFeng C, Li L, Sadeghpour A (2020). “A Comparison of Residual Diagnosis Tools for Diagnosing Regression Models for Count Data” BMC Medical Research Methodology, 20(175), 1–21. doi:10.1186/s12874-020-01055-2\nWarton DI, Thibaut L, Wang YA (2017) “The PIT-Trap – A ‘Model-Free’ Bootstrap Procedure for Inference about Regression Models with Discrete, Multivariate Responses”. PLOS ONE, 12(7), 1–18. doi:10.1371/journal.pone.0181790.\n\nqnorm, qqrplot\n\n\nlibrary(\"topmodels\")\n\n## Poisson GLM for FIFA 2018 data\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## random quantile residuals (on original data)\nproresiduals(m)\n\n           1            2            3            4            5            6 \n 1.915644338 -1.105078153 -0.807958596 -0.179311742  1.266353539  0.470575512 \n           7            8            9           10           11           12 \n-0.752494263 -1.045225233  1.282869075 -1.124877627  1.090942428 -0.539823528 \n          13           14           15           16           17           18 \n-0.643705716  0.289872127  1.664027076  1.075729933 -0.264916471 -0.771184981 \n          19           20           21           22           23           24 \n-2.437170350 -1.045453555  0.011902281 -0.068450565  1.088857023 -0.298712135 \n          25           26           27           28           29           30 \n-0.092781656  0.040978929 -0.854314048  0.153547831 -0.274131009 -0.247002209 \n          31           32           33           34           35           36 \n-0.817571789 -0.522624791 -0.612034420 -1.036527316 -0.775181710  0.624317835 \n          37           38           39           40           41           42 \n-0.780984001  0.637865299  0.341489250 -0.851326997 -1.155778583  1.409362082 \n          43           44           45           46           47           48 \n 0.885634944 -0.966831001  0.625367246 -0.032738602  0.451783240  0.424961257 \n          49           50           51           52           53           54 \n-1.871463209 -0.079238236 -0.444718221  0.265211278 -0.161201871 -1.901862143 \n          55           56           57           58           59           60 \n 0.352212934  0.955084300 -1.403623094 -0.173022861  0.558675802  1.224009110 \n          61           62           63           64           65           66 \n-1.442910607  0.287048754 -0.248590445 -1.075140445 -0.102006275  0.735432718 \n          67           68           69           70           71           72 \n-0.148785401  0.428322470  1.497000447 -1.584051642 -1.040486363  1.439931999 \n          73           74           75           76           77           78 \n 0.478389817 -2.074754753 -0.040001057 -0.076802385  1.852219154  1.726367467 \n          79           80           81           82           83           84 \n 2.273379199 -0.094434871 -0.728706706 -0.074710978  0.006688404  1.008577520 \n          85           86           87           88           89           90 \n-0.601928161  0.760779782  0.173040854  1.064166915  0.736167373  0.600592817 \n          91           92           93           94           95           96 \n-0.596536809  1.252235278 -0.795438505 -0.067279907 -1.703060032 -0.414581548 \n          97           98           99          100          101          102 \n 1.713871282  1.235274189  1.019891801  0.015391816 -0.169494635  0.649544807 \n         103          104          105          106          107          108 \n-0.079701603  0.545956271  0.409284332 -0.650807985  1.100409421  0.967389502 \n         109          110          111          112          113          114 \n 0.246228476 -1.204117946 -0.239730292  0.181577362 -0.377170649  0.063799316 \n         115          116          117          118          119          120 \n-0.293110417  1.011912968 -0.343094697  0.176102847  0.230919606 -0.177637379 \n         121          122          123          124          125          126 \n-0.318423938 -0.924017495 -0.071730364 -0.104286530  0.492498400 -1.929644217 \n         127          128 \n 1.515017065  0.697940283 \n\n## various flavors of residuals on small new data\nnd &lt;- data.frame(goals = c(1, 1, 1), difference = c(-1, 0, 1))\n\n## quantile residuals: random (1 sample), random (5 samples), mid-quantile (non-random)\nproresiduals(m, newdata = nd, type = \"quantile\")\n\n          1           2           3 \n 0.25103847 -0.02596762 -0.51383725 \n\nproresiduals(m, newdata = nd, type = \"quantile\", nsim = 5)\n\n            r_1        r_2         r_3        r_4          r_5\n[1,] -0.1459758  0.2499621  0.31995611  0.1707342  0.006673901\n[2,] -0.2282231 -0.2831749 -0.07696133 -0.2840809  0.171462757\n[3,] -0.5027931 -0.4081734 -0.39487938 -0.3886358 -0.542828894\n\nproresiduals(m, newdata = nd, type = \"quantile\", prob = 0.5)\n\n          1           2           3 \n 0.31008612 -0.07586646 -0.52976162 \n\n## PIT residuals (without transformation to normal): random vs. minimum/maximum quantile\nproresiduals(m, newdata = nd, type = \"pit\", nsim = 5)\n\n           r_1       r_2       r_3       r_4       r_5\n[1,] 0.5650710 0.7654889 0.6667167 0.5448863 0.6624393\n[2,] 0.3700829 0.6131877 0.4344202 0.3212836 0.3359922\n[3,] 0.2552849 0.3120397 0.2365261 0.1657959 0.4127608\n\nproresiduals(m, newdata = nd, type = \"pit\", prob = c(0, 1))\n\n           r_0       r_1\n[1,] 0.4412492 0.8022553\n[2,] 0.2902421 0.6492832\n[3,] 0.1540605 0.4422167\n\n## raw response residuals (observation - expected mean)\nproresiduals(m, newdata = nd, type = \"response\")\n\n         1          2          3 \n 0.1818546 -0.2370397 -0.8704100 \n\n## standardized Pearson residuals (response residuals divided by standard deviation)\nproresiduals(m, newdata = nd, type = \"pearson\")\n\n         1          2          3 \n 0.2010523 -0.2131225 -0.6364371 \n\n## compute residuals by manually obtaining distribution and response\n## proresiduals(procast(m, newdata = nd, drop = TRUE), nd$goals)",
    "crumbs": [
      "Procast infrastructure",
      "proresiduals"
    ]
  },
  {
    "objectID": "man/proresiduals.html#residuals-for-probabilistic-regression-models",
    "href": "man/proresiduals.html#residuals-for-probabilistic-regression-models",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and default method for (randomized) quantile residuals, PIT, Pearson, and raw response residuals based on distributions3 support.\n\nproresiduals(object, ...)\n\n## Default S3 method:\nproresiduals(\n  object,\n  newdata = NULL,\n  type = c(\"quantile\", \"pit\", \"pearson\", \"response\"),\n  nsim = NULL,\n  prob = NULL,\n  delta = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object for which a newresponse and a prodist method is available.\n\n\n\n\n…\n\n\nfurther parameters passed to methods.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\ntype\n\n\ncharacter indicating whether quantile (default), PIT, Pearson, or raw response residuals should be computed.\n\n\n\n\nnsim\n\n\ninteger. The number of randomly simulated residuals of type = “quantile” or “pit”. By default one simulation is returned.\n\n\n\n\nprob\n\n\nnumeric. Instead of simulating the probabilities (between 0 and 1) for type = “quantile” or “pit”, a vector of probabilities can be specified, e.g., prob = 0.5 corresponding to mid-quantile residuals.\n\n\n\n\ndelta\n\n\nnumeric. The minimal difference to compute the range of proabilities corresponding to each observation according to get (randomized) “quantile” or “pit” residuals. For NULL, the minimal observed difference in the resonse divided by 5e-6 is used. Ignored for continuous distributions.\n\n\n\nThe new generic function proresiduals comes with a powerful default method that is based on the following idea: newresponse and prodist can be used to extract the observed response and expected distribution for it, respectively. For all model classes that have methods for these two generic functions, proresiduals can compute a range of different types of residuals.\nThe simplest definition of residuals are the so-called “response” residuals which simply compute the difference between the observations and the expected means. The “pearson” residuals additionally standardize these residuals by the square root of the expected variance. Thus, these residuals are based only on the first and on the first two moments, respectively.\nTo assess the entire distribution and not just the first moments, there are also residuals based on the probability integral transform (PIT). For regression models with a continuous response distribution, “pit” residuals (see Warton 2007) are simply the expected cumulative distribution (CDF) evaluated at the observations (Dawid, 1984). For discrete distributions, a uniform random value is drawn from the range of probabilities between the CDF at the observation and the supremum of the CDF to the left of it. If the model fits well the PIT residuals should be uniformly distributed.\nIn order to obtain normally distributed residuals for well-fitting models (like often desired in linear regression models), “quantile” residuals, proposed by Dunn and Smyth (1996), additionally transform the PIT residuals by the standard normal quantile function.\nAs quantile residuals and PIT residuals are subject to randomness for discrete distributions (and also for mixed discrete-continuous distributions), it is sometimes useful to explore the extent of the random variation. This can be done either by obtaining multiple replications (via nsim) or by computing fixed quantiles of each probability interval such as prob = 0.5 (corresponding to mid-quantile residuals, see Feng et al. 2020). Another common setting is prob = c(0, 1) yielding the range of possible residuals.\n\nA vector or matrix of residuals. A matrix of residuals is returned if more than one replication of quantile or PIT residuals is computed, i.e., if either random &gt; 1 or random = FALSE and length(prob) &gt; 1.\n\nDawid AP (1984). “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach.” Journal of the Royal Statistical Society A, 147(2), 278–292. doi:10.2307/2981683.\nDunn KP, Smyth GK (1996). “Randomized Quantile Residuals.” Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\nFeng C, Li L, Sadeghpour A (2020). “A Comparison of Residual Diagnosis Tools for Diagnosing Regression Models for Count Data” BMC Medical Research Methodology, 20(175), 1–21. doi:10.1186/s12874-020-01055-2\nWarton DI, Thibaut L, Wang YA (2017) “The PIT-Trap – A ‘Model-Free’ Bootstrap Procedure for Inference about Regression Models with Discrete, Multivariate Responses”. PLOS ONE, 12(7), 1–18. doi:10.1371/journal.pone.0181790.\n\nqnorm, qqrplot\n\n\nlibrary(\"topmodels\")\n\n## Poisson GLM for FIFA 2018 data\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## random quantile residuals (on original data)\nproresiduals(m)\n\n           1            2            3            4            5            6 \n 1.915644338 -1.105078153 -0.807958596 -0.179311742  1.266353539  0.470575512 \n           7            8            9           10           11           12 \n-0.752494263 -1.045225233  1.282869075 -1.124877627  1.090942428 -0.539823528 \n          13           14           15           16           17           18 \n-0.643705716  0.289872127  1.664027076  1.075729933 -0.264916471 -0.771184981 \n          19           20           21           22           23           24 \n-2.437170350 -1.045453555  0.011902281 -0.068450565  1.088857023 -0.298712135 \n          25           26           27           28           29           30 \n-0.092781656  0.040978929 -0.854314048  0.153547831 -0.274131009 -0.247002209 \n          31           32           33           34           35           36 \n-0.817571789 -0.522624791 -0.612034420 -1.036527316 -0.775181710  0.624317835 \n          37           38           39           40           41           42 \n-0.780984001  0.637865299  0.341489250 -0.851326997 -1.155778583  1.409362082 \n          43           44           45           46           47           48 \n 0.885634944 -0.966831001  0.625367246 -0.032738602  0.451783240  0.424961257 \n          49           50           51           52           53           54 \n-1.871463209 -0.079238236 -0.444718221  0.265211278 -0.161201871 -1.901862143 \n          55           56           57           58           59           60 \n 0.352212934  0.955084300 -1.403623094 -0.173022861  0.558675802  1.224009110 \n          61           62           63           64           65           66 \n-1.442910607  0.287048754 -0.248590445 -1.075140445 -0.102006275  0.735432718 \n          67           68           69           70           71           72 \n-0.148785401  0.428322470  1.497000447 -1.584051642 -1.040486363  1.439931999 \n          73           74           75           76           77           78 \n 0.478389817 -2.074754753 -0.040001057 -0.076802385  1.852219154  1.726367467 \n          79           80           81           82           83           84 \n 2.273379199 -0.094434871 -0.728706706 -0.074710978  0.006688404  1.008577520 \n          85           86           87           88           89           90 \n-0.601928161  0.760779782  0.173040854  1.064166915  0.736167373  0.600592817 \n          91           92           93           94           95           96 \n-0.596536809  1.252235278 -0.795438505 -0.067279907 -1.703060032 -0.414581548 \n          97           98           99          100          101          102 \n 1.713871282  1.235274189  1.019891801  0.015391816 -0.169494635  0.649544807 \n         103          104          105          106          107          108 \n-0.079701603  0.545956271  0.409284332 -0.650807985  1.100409421  0.967389502 \n         109          110          111          112          113          114 \n 0.246228476 -1.204117946 -0.239730292  0.181577362 -0.377170649  0.063799316 \n         115          116          117          118          119          120 \n-0.293110417  1.011912968 -0.343094697  0.176102847  0.230919606 -0.177637379 \n         121          122          123          124          125          126 \n-0.318423938 -0.924017495 -0.071730364 -0.104286530  0.492498400 -1.929644217 \n         127          128 \n 1.515017065  0.697940283 \n\n## various flavors of residuals on small new data\nnd &lt;- data.frame(goals = c(1, 1, 1), difference = c(-1, 0, 1))\n\n## quantile residuals: random (1 sample), random (5 samples), mid-quantile (non-random)\nproresiduals(m, newdata = nd, type = \"quantile\")\n\n          1           2           3 \n 0.25103847 -0.02596762 -0.51383725 \n\nproresiduals(m, newdata = nd, type = \"quantile\", nsim = 5)\n\n            r_1        r_2         r_3        r_4          r_5\n[1,] -0.1459758  0.2499621  0.31995611  0.1707342  0.006673901\n[2,] -0.2282231 -0.2831749 -0.07696133 -0.2840809  0.171462757\n[3,] -0.5027931 -0.4081734 -0.39487938 -0.3886358 -0.542828894\n\nproresiduals(m, newdata = nd, type = \"quantile\", prob = 0.5)\n\n          1           2           3 \n 0.31008612 -0.07586646 -0.52976162 \n\n## PIT residuals (without transformation to normal): random vs. minimum/maximum quantile\nproresiduals(m, newdata = nd, type = \"pit\", nsim = 5)\n\n           r_1       r_2       r_3       r_4       r_5\n[1,] 0.5650710 0.7654889 0.6667167 0.5448863 0.6624393\n[2,] 0.3700829 0.6131877 0.4344202 0.3212836 0.3359922\n[3,] 0.2552849 0.3120397 0.2365261 0.1657959 0.4127608\n\nproresiduals(m, newdata = nd, type = \"pit\", prob = c(0, 1))\n\n           r_0       r_1\n[1,] 0.4412492 0.8022553\n[2,] 0.2902421 0.6492832\n[3,] 0.1540605 0.4422167\n\n## raw response residuals (observation - expected mean)\nproresiduals(m, newdata = nd, type = \"response\")\n\n         1          2          3 \n 0.1818546 -0.2370397 -0.8704100 \n\n## standardized Pearson residuals (response residuals divided by standard deviation)\nproresiduals(m, newdata = nd, type = \"pearson\")\n\n         1          2          3 \n 0.2010523 -0.2131225 -0.6364371 \n\n## compute residuals by manually obtaining distribution and response\n## proresiduals(procast(m, newdata = nd, drop = TRUE), nd$goals)",
    "crumbs": [
      "Procast infrastructure",
      "proresiduals"
    ]
  },
  {
    "objectID": "man/promodel.html",
    "href": "man/promodel.html",
    "title": "topmodels",
    "section": "",
    "text": "The function promodel is a wrapper for dispatching the base predict and residuals methods to the procast and proresiduals functions for probabilistic forecasts and probabilistic residuals, respectively.\n\npromodel(object)\n\n## S3 method for class 'promodel'\nresiduals(object, ...)\n\n## S3 method for class 'promodel'\npredict(object, ...)\n\n\n\n\n\nobject\n\n\na fitted model object for which procast and/or proresiduals work.\n\n\n\n\n…\n\n\nfurther arguments passed on to procast or proresiduals, respectively.\n\n\n\nThe default methods for procast and proresiduals in this package make a wide range of different probabilistic forecasts and probabilistic residuals available for many fitted model object classes. However, it may sometimes be useful to call these flexible methods via the base predict and residuals methods. For example, this may be useful in combination with other packages that rely on the base functions such as marginaleffects.\nTherefore, the promodel wrapper function simply adds an additional class “promodel” (probabilistic model) to the original class of an object. Then the methods for predict and residuals then strip off this class again before calling procast and proresiduals, respectively.\n\n\nlibrary(\"topmodels\")\n\n## Poisson regression model for FIFA 2018 data:\n## number of goals scored by each team in each game, explained by\n## predicted ability difference of the competing teams\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## prediction using a new data set (final of the tournament)\nfinal &lt;- tail(FIFA2018, 2)\n\n## base predict method computes linear predictor on link scale (here in logs)\npredict(m, newdata = final)\n\n        127         128 \n 0.47275699 -0.04731455 \n\n## procast-based method computes distribution object by default\npm &lt;- promodel(m)\npredict(pm, newdata = final)\n\n                   distribution\n127 Poisson(lambda = 1.6044114)\n128 Poisson(lambda = 0.9537873)\n\n## all other procast types are available as well\npredict(pm, newdata = final, type = \"density\", at = 0:4)\n\n          d_0       d_1       d_2        d_3        d_4\n127 0.2010078 0.3224993 0.2587107 0.13835949 0.05549639\n128 0.3852791 0.3674743 0.1752462 0.05571586 0.01328527\n\npredict(pm, newdata = final, type = \"cdf\", at = 0:4)\n\n          p_0       p_1       p_2       p_3       p_4\n127 0.2010078 0.5235071 0.7822178 0.9205773 0.9760737\n128 0.3852791 0.7527534 0.9279995 0.9837154 0.9970007\n\n## the base residuals method defaults to deviance residuals\n## but the proresiduals-based method defaults to quantile residuals\nhead(residuals(m))\n\n          1           2           3           4           5           6 \n 1.98287409 -1.31569179 -1.43503752 -0.42419390  1.13746339 -0.06469232 \n\nhead(residuals(pm))\n\n         1          2          3          4          5          6 \n 2.3083371 -1.1740308 -1.7560423  0.1203678  0.9763199  0.3113093",
    "crumbs": [
      "Procast infrastructure",
      "promodel"
    ]
  },
  {
    "objectID": "man/promodel.html#predictions-and-residuals-dispatch-for-probabilistic-models",
    "href": "man/promodel.html#predictions-and-residuals-dispatch-for-probabilistic-models",
    "title": "topmodels",
    "section": "",
    "text": "The function promodel is a wrapper for dispatching the base predict and residuals methods to the procast and proresiduals functions for probabilistic forecasts and probabilistic residuals, respectively.\n\npromodel(object)\n\n## S3 method for class 'promodel'\nresiduals(object, ...)\n\n## S3 method for class 'promodel'\npredict(object, ...)\n\n\n\n\n\nobject\n\n\na fitted model object for which procast and/or proresiduals work.\n\n\n\n\n…\n\n\nfurther arguments passed on to procast or proresiduals, respectively.\n\n\n\nThe default methods for procast and proresiduals in this package make a wide range of different probabilistic forecasts and probabilistic residuals available for many fitted model object classes. However, it may sometimes be useful to call these flexible methods via the base predict and residuals methods. For example, this may be useful in combination with other packages that rely on the base functions such as marginaleffects.\nTherefore, the promodel wrapper function simply adds an additional class “promodel” (probabilistic model) to the original class of an object. Then the methods for predict and residuals then strip off this class again before calling procast and proresiduals, respectively.\n\n\nlibrary(\"topmodels\")\n\n## Poisson regression model for FIFA 2018 data:\n## number of goals scored by each team in each game, explained by\n## predicted ability difference of the competing teams\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## prediction using a new data set (final of the tournament)\nfinal &lt;- tail(FIFA2018, 2)\n\n## base predict method computes linear predictor on link scale (here in logs)\npredict(m, newdata = final)\n\n        127         128 \n 0.47275699 -0.04731455 \n\n## procast-based method computes distribution object by default\npm &lt;- promodel(m)\npredict(pm, newdata = final)\n\n                   distribution\n127 Poisson(lambda = 1.6044114)\n128 Poisson(lambda = 0.9537873)\n\n## all other procast types are available as well\npredict(pm, newdata = final, type = \"density\", at = 0:4)\n\n          d_0       d_1       d_2        d_3        d_4\n127 0.2010078 0.3224993 0.2587107 0.13835949 0.05549639\n128 0.3852791 0.3674743 0.1752462 0.05571586 0.01328527\n\npredict(pm, newdata = final, type = \"cdf\", at = 0:4)\n\n          p_0       p_1       p_2       p_3       p_4\n127 0.2010078 0.5235071 0.7822178 0.9205773 0.9760737\n128 0.3852791 0.7527534 0.9279995 0.9837154 0.9970007\n\n## the base residuals method defaults to deviance residuals\n## but the proresiduals-based method defaults to quantile residuals\nhead(residuals(m))\n\n          1           2           3           4           5           6 \n 1.98287409 -1.31569179 -1.43503752 -0.42419390  1.13746339 -0.06469232 \n\nhead(residuals(pm))\n\n         1          2          3          4          5          6 \n 2.3083371 -1.1740308 -1.7560423  0.1203678  0.9763199  0.3113093",
    "crumbs": [
      "Procast infrastructure",
      "promodel"
    ]
  },
  {
    "objectID": "man/plot.qqrplot.html",
    "href": "man/plot.qqrplot.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for Q-Q residual plots for objects of class “qqrplot” returned by link{qqrplot}.\n\n## S3 method for class 'qqrplot'\nplot(\n  x,\n  single_graph = FALSE,\n  detrend = NULL,\n  simint = NULL,\n  confint = NULL,\n  confint_type = c(\"pointwise\", \"simultaneous\", \"beta\", \"normal\", \"ks\", \"ell\"),\n  confint_level = 0.95,\n  ref = NULL,\n  ref_type = NULL,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  axes = TRUE,\n  box = TRUE,\n  col = \"black\",\n  pch = 19,\n  simint_col = \"black\",\n  simint_alpha = 0.2,\n  confint_col = \"black\",\n  confint_lty = 2,\n  confint_lwd = 1.25,\n  confint_alpha = NULL,\n  ref_col = \"black\",\n  ref_lty = 2,\n  ref_lwd = 1.25,\n  ...\n)\n\n## S3 method for class 'qqrplot'\npoints(\n  x,\n  detrend = NULL,\n  simint = FALSE,\n  col = \"black\",\n  pch = 19,\n  simint_col = \"black\",\n  simint_alpha = 0.2,\n  ...\n)\n\n## S3 method for class 'qqrplot'\nautoplot(\n  object,\n  single_graph = FALSE,\n  detrend = NULL,\n  simint = NULL,\n  confint = NULL,\n  confint_type = c(\"pointwise\", \"simultaneous\", \"beta\", \"normal\", \"ks\", \"ell\"),\n  confint_level = 0.95,\n  ref = NULL,\n  ref_type = NULL,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  legend = FALSE,\n  theme = NULL,\n  alpha = NA,\n  colour = \"black\",\n  fill = NA,\n  shape = 19,\n  size = 2,\n  stroke = 0.5,\n  simint_fill = \"black\",\n  simint_alpha = 0.2,\n  confint_colour = NULL,\n  confint_fill = NULL,\n  confint_size = NULL,\n  confint_linetype = NULL,\n  confint_alpha = NULL,\n  ref_colour = \"black\",\n  ref_size = 0.5,\n  ref_linetype = 2,\n  ...\n)\n\n\n\n\n\nx, object\n\n\nan object of class qqrplot as returned by qqrplot.\n\n\n\n\nsingle_graph\n\n\nlogical, defaults to FALSE. In case of multiple Q-Q residual plots: should all be drawn in a single graph?\n\n\n\n\ndetrend\n\n\nlogical. Should the qqrplot be detrended, i.e, plotted as a ‘wormplot()’? If NULL (default) this is extracted from x/object.\n\n\n\n\nsimint\n\n\nlogical or quantile specification. Should the simint of quantiles of the randomized quantile residuals be visualized?\n\n\n\n\nconfint\n\n\nlogical or character string describing the style for plotting ‘c(\"polygon\", \"line\")’.\n\n\n\n\nconfint_type\n\n\ncharacter. Method for creating the confidence intervals. There are two methods for pointwise confidence intervals: Based on the ‘\"beta\"’ or ‘\"normal\"’ distribution, yielding very similar results. And there are two methods for simultaneous confidence intervals: Based on the Kolmogorov-Smirnov test (‘\"ks\"’) or equal local levels (‘\"ell\"’), where the latter has much better properties but requires the qqconf package to be installed ([qqconf::get_qq_band()]). Finally, the methods ‘\"pointwise\"’ and ‘\"simultaneous\"’ are simply aliases for the preferred corresponding methods ‘\"beta\"’ and ‘\"ell\"’, respectively.\n\n\n\n\nconfint_level\n\n\nnumeric. The confidence level required, defaults to 0.95.\n\n\n\n\nref\n\n\nlogical. Should a reference line be plotted?\n\n\n\n\nref_type\n\n\ncharacter specifying that the ‘\"identity\"’ line should be used as a reference or, alternatively, a line through the ‘\"quartiles\"’ of the quantile residuals. Moreover, also a numeric vector of length two can be used to define the probabilities of the quantiles to be used for defining the reference line. Note, that the reference is also used for detrending the quantile residuals. For uniform scales, the identity line must be used for reference (‘ref_type = \"identity\"’).\n\n\n\n\nxlim, ylim, axes, box\n\n\nadditional graphical parameters for base plots, whereby x is a object of class qqrplot.\n\n\n\n\nxlab, ylab, main, …\n\n\ngraphical plotting parameters passed to plot or points, respectively.\n\n\n\n\ncol, pch\n\n\ngraphical parameters for the main part of the base plot.\n\n\n\n\nsimint_col, simint_alpha, confint_col, confint_lty, confint_lwd, ref_col, ref_lty, ref_lwd\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon in the base plot.\n\n\n\n\nlegend\n\n\nlogical. Should a legend be added in the ggplot2 style graphic?\n\n\n\n\ntheme\n\n\nname of the ‘ggplot2’ theme to be used. If theme = NULL, the theme_bw is employed.\n\n\n\n\ncolour, fill, alpha, shape, size, stroke\n\n\ngraphical parameters passed to ggplot2 style plots.\n\n\n\n\nsimint_fill, confint_colour, confint_fill, confint_size, confint_linetype, confint_alpha, ref_colour, ref_size, ref_linetype\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon using autoplot.\n\n\n\nQ-Q residuals plots draw quantile residuals (by default on the standard normal scale) against theoretical quantiles from the same distribution. Alternatively, quantile residuals can also be compared on the uniform scale (scale = “uniform”) using no transformation.\nQ-Q residuals plots can be rendered as ggplot2 or base R graphics by using the generics autoplot or plot. points (points.qqrplot) can be used to add Q-Q residuals to an existing base R graphics panel.\n\nDunn KP, Smyth GK (1996). “Randomized Quantile Residuals.” Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\n\nqqrplot, wormplot, proresiduals, qqnorm\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot qqrplot\nqqrplot(m1_lm)\n\n\n\n\n\n\n## customize colors\nqqrplot(m1_lm, plot = \"base\", ref_col = \"blue\", lty = 2, pch = 20)\n\n## add separate model\nif (require(\"crch\", quietly = TRUE)) {\n  m1_crch &lt;- crch(dist ~ speed | speed, data = cars)\n  points(qqrplot(m1_crch, plot = FALSE), col = 2, lty = 2, simint = 2)\n}\n\n\n\n\n\n\n\n[1] \"expected\"\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model \n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ## compute qqrplots\n  qq2_lm &lt;- qqrplot(m2_lm, plot = FALSE)\n  qq2_crch &lt;- qqrplot(m2_crch, plot = FALSE)\n\n  ## plot in single graph\n  plot(c(qq2_lm, qq2_crch), col = c(1, 2), simint_col = c(1, 2), single_graph = TRUE)\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois  &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot qqrplot as \"ggplot2\" graphic\nqqrplot(m3_pois, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.qqrplot"
    ]
  },
  {
    "objectID": "man/plot.qqrplot.html#s3-methods-for-plotting-q-q-residuals-plots",
    "href": "man/plot.qqrplot.html#s3-methods-for-plotting-q-q-residuals-plots",
    "title": "topmodels",
    "section": "",
    "text": "Generic plotting functions for Q-Q residual plots for objects of class “qqrplot” returned by link{qqrplot}.\n\n## S3 method for class 'qqrplot'\nplot(\n  x,\n  single_graph = FALSE,\n  detrend = NULL,\n  simint = NULL,\n  confint = NULL,\n  confint_type = c(\"pointwise\", \"simultaneous\", \"beta\", \"normal\", \"ks\", \"ell\"),\n  confint_level = 0.95,\n  ref = NULL,\n  ref_type = NULL,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  axes = TRUE,\n  box = TRUE,\n  col = \"black\",\n  pch = 19,\n  simint_col = \"black\",\n  simint_alpha = 0.2,\n  confint_col = \"black\",\n  confint_lty = 2,\n  confint_lwd = 1.25,\n  confint_alpha = NULL,\n  ref_col = \"black\",\n  ref_lty = 2,\n  ref_lwd = 1.25,\n  ...\n)\n\n## S3 method for class 'qqrplot'\npoints(\n  x,\n  detrend = NULL,\n  simint = FALSE,\n  col = \"black\",\n  pch = 19,\n  simint_col = \"black\",\n  simint_alpha = 0.2,\n  ...\n)\n\n## S3 method for class 'qqrplot'\nautoplot(\n  object,\n  single_graph = FALSE,\n  detrend = NULL,\n  simint = NULL,\n  confint = NULL,\n  confint_type = c(\"pointwise\", \"simultaneous\", \"beta\", \"normal\", \"ks\", \"ell\"),\n  confint_level = 0.95,\n  ref = NULL,\n  ref_type = NULL,\n  xlim = c(NA, NA),\n  ylim = c(NA, NA),\n  xlab = NULL,\n  ylab = NULL,\n  main = NULL,\n  legend = FALSE,\n  theme = NULL,\n  alpha = NA,\n  colour = \"black\",\n  fill = NA,\n  shape = 19,\n  size = 2,\n  stroke = 0.5,\n  simint_fill = \"black\",\n  simint_alpha = 0.2,\n  confint_colour = NULL,\n  confint_fill = NULL,\n  confint_size = NULL,\n  confint_linetype = NULL,\n  confint_alpha = NULL,\n  ref_colour = \"black\",\n  ref_size = 0.5,\n  ref_linetype = 2,\n  ...\n)\n\n\n\n\n\nx, object\n\n\nan object of class qqrplot as returned by qqrplot.\n\n\n\n\nsingle_graph\n\n\nlogical, defaults to FALSE. In case of multiple Q-Q residual plots: should all be drawn in a single graph?\n\n\n\n\ndetrend\n\n\nlogical. Should the qqrplot be detrended, i.e, plotted as a ‘wormplot()’? If NULL (default) this is extracted from x/object.\n\n\n\n\nsimint\n\n\nlogical or quantile specification. Should the simint of quantiles of the randomized quantile residuals be visualized?\n\n\n\n\nconfint\n\n\nlogical or character string describing the style for plotting ‘c(\"polygon\", \"line\")’.\n\n\n\n\nconfint_type\n\n\ncharacter. Method for creating the confidence intervals. There are two methods for pointwise confidence intervals: Based on the ‘\"beta\"’ or ‘\"normal\"’ distribution, yielding very similar results. And there are two methods for simultaneous confidence intervals: Based on the Kolmogorov-Smirnov test (‘\"ks\"’) or equal local levels (‘\"ell\"’), where the latter has much better properties but requires the qqconf package to be installed ([qqconf::get_qq_band()]). Finally, the methods ‘\"pointwise\"’ and ‘\"simultaneous\"’ are simply aliases for the preferred corresponding methods ‘\"beta\"’ and ‘\"ell\"’, respectively.\n\n\n\n\nconfint_level\n\n\nnumeric. The confidence level required, defaults to 0.95.\n\n\n\n\nref\n\n\nlogical. Should a reference line be plotted?\n\n\n\n\nref_type\n\n\ncharacter specifying that the ‘\"identity\"’ line should be used as a reference or, alternatively, a line through the ‘\"quartiles\"’ of the quantile residuals. Moreover, also a numeric vector of length two can be used to define the probabilities of the quantiles to be used for defining the reference line. Note, that the reference is also used for detrending the quantile residuals. For uniform scales, the identity line must be used for reference (‘ref_type = \"identity\"’).\n\n\n\n\nxlim, ylim, axes, box\n\n\nadditional graphical parameters for base plots, whereby x is a object of class qqrplot.\n\n\n\n\nxlab, ylab, main, …\n\n\ngraphical plotting parameters passed to plot or points, respectively.\n\n\n\n\ncol, pch\n\n\ngraphical parameters for the main part of the base plot.\n\n\n\n\nsimint_col, simint_alpha, confint_col, confint_lty, confint_lwd, ref_col, ref_lty, ref_lwd\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon in the base plot.\n\n\n\n\nlegend\n\n\nlogical. Should a legend be added in the ggplot2 style graphic?\n\n\n\n\ntheme\n\n\nname of the ‘ggplot2’ theme to be used. If theme = NULL, the theme_bw is employed.\n\n\n\n\ncolour, fill, alpha, shape, size, stroke\n\n\ngraphical parameters passed to ggplot2 style plots.\n\n\n\n\nsimint_fill, confint_colour, confint_fill, confint_size, confint_linetype, confint_alpha, ref_colour, ref_size, ref_linetype\n\n\nFurther graphical parameters for the ‘confint’ and ‘simint’ line/polygon using autoplot.\n\n\n\nQ-Q residuals plots draw quantile residuals (by default on the standard normal scale) against theoretical quantiles from the same distribution. Alternatively, quantile residuals can also be compared on the uniform scale (scale = “uniform”) using no transformation.\nQ-Q residuals plots can be rendered as ggplot2 or base R graphics by using the generics autoplot or plot. points (points.qqrplot) can be used to add Q-Q residuals to an existing base R graphics panel.\n\nDunn KP, Smyth GK (1996). “Randomized Quantile Residuals.” Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\n\nqqrplot, wormplot, proresiduals, qqnorm\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot qqrplot\nqqrplot(m1_lm)\n\n\n\n\n\n\n## customize colors\nqqrplot(m1_lm, plot = \"base\", ref_col = \"blue\", lty = 2, pch = 20)\n\n## add separate model\nif (require(\"crch\", quietly = TRUE)) {\n  m1_crch &lt;- crch(dist ~ speed | speed, data = cars)\n  points(qqrplot(m1_crch, plot = FALSE), col = 2, lty = 2, simint = 2)\n}\n\n\n\n\n\n\n\n[1] \"expected\"\n\n#-------------------------------------------------------------------------------\nif (require(\"crch\")) {\n\n  ## precipitation observations and forecasts for Innsbruck\n  data(\"RainIbk\", package = \"crch\")\n  RainIbk &lt;- sqrt(RainIbk)\n  RainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, mean)\n  RainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, sd)\n  RainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\n  ## linear model w/ constant variance estimation\n  m2_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\n\n  ## logistic censored model \n  m2_crch &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, dist = \"logistic\")\n\n  ## compute qqrplots\n  qq2_lm &lt;- qqrplot(m2_lm, plot = FALSE)\n  qq2_crch &lt;- qqrplot(m2_crch, plot = FALSE)\n\n  ## plot in single graph\n  plot(c(qq2_lm, qq2_crch), col = c(1, 2), simint_col = c(1, 2), single_graph = TRUE)\n}\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm3_pois  &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\n\n## compute and plot qqrplot as \"ggplot2\" graphic\nqqrplot(m3_pois, plot = \"ggplot2\")",
    "crumbs": [
      "Plotting probabilistic model diagnostics",
      "plot.qqrplot"
    ]
  },
  {
    "objectID": "man/qqrplot.html",
    "href": "man/qqrplot.html",
    "title": "topmodels",
    "section": "",
    "text": "Visualize goodness of fit of regression models by Quantile-Quantile (Q-Q) plots using quantile residuals. If plot = TRUE, the resulting object of class “qqrplot” is plotted by plot.qqrplot or autoplot.qqrplot before it is returned, depending on whether the package ggplot2 is loaded.\n\nqqrplot(object, ...)\n\n## Default S3 method:\nqqrplot(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  detrend = FALSE,\n  ref_type = \"identity\",\n  scale = c(\"normal\", \"uniform\"),\n  nsim = 1L,\n  delta = NULL,\n  simint = TRUE,\n  simint_level = 0.95,\n  simint_nrep = 250,\n  confint = TRUE,\n  ref = TRUE,\n  xlab = \"Theoretical quantiles\",\n  ylab = if (!detrend) \"Quantile residuals\" else \"Deviation\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which probability integral transforms can be extracted using the generic function procast.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nlogical or character. Should the plot or autoplot method be called to draw the computed Q-Q plot? Logical FALSE will suppress plotting, TRUE (default) will choose the type of plot conditional if the package ggplot2 is loaded. Alternatively “base” or “ggplot2” can be specified to explicitly choose the type of plot.\n\n\n\n\nclass\n\n\nshould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\ndetrend\n\n\nlogical, defaults to FALSE. Should the qqrplot be detrended, i.e, plotted as a wormplot?\n\n\n\n\nref_type\n\n\ncharacter specifying that the \"identity\" line should be used as as a reference or the \"quartiles\" of the quantile residuals should be used for defining the reference line. Alternatively, also a numeric vector of length two can be used to define the probabilities to be used for defining the reference line. Note, that the reference is also used for detrending the quantile residuals.\n\n\n\n\nscale\n\n\ncharacter. On which scale should the quantile residuals be shown: on the probability scale (“uniform”) or on the normal scale (“normal”).\n\n\n\n\nnsim, delta\n\n\narguments passed to proresiduals.\n\n\n\n\nsimint\n\n\nlogical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized?\n\n\n\n\nsimint_level\n\n\nnumeric. The confidence level required for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsimint_nrep\n\n\nnumeric (positive; default 250). The number of repetitions of simulated quantiles for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nconfint\n\n\nlogical or character describing the style for plotting confidence intervals. TRUE (default) and “line” will add point-wise confidence intervals of the (randomized) quantile residuals as lines, “polygon” will draw a polygon instead, and FALSE suppresses the drawing.\n\n\n\n\nref\n\n\nlogical, defaults to TRUE. Should a reference line be plotted?\n\n\n\n\nxlab, ylab, main, …\n\n\ngraphical parameters passed to plot.qqrplot or autoplot.qqrplot.\n\n\n\nQ-Q residuals plots draw quantile residuals (by default on the standard normal scale) against theoretical quantiles from the same distribution. Alternatively, quantile residuals can also be compared on the uniform scale (scale = “uniform”) using no transformation. For computation, qqrplot leverages the function proresiduals employing the procast generic.\nAdditional options are offered for models with discrete responses where randomization of quantiles is needed.\nIn addition to the plot and autoplot method for qqrplot objects, it is also possible to combine two (or more) Q-Q residuals plots by c/rbind, which creates a set of Q-Q residuals plots that can then be plotted in one go.\n\nAn object of class “qqrplot” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nobserved\n\n\ndeviations between theoretical and empirical quantiles,\n\n\n\n\nexpected\n\n\ntheoretical quantiles,\n\n\n\n\nsimint_observed_lwr\n\n\nlower bound of the simulated confidence interval,\n\n\n\n\nsimint_observed_upr\n\n\nupper bound of the simulated confidence interval,\n\n\n\n\nsimint_expected\n\n\nTODO: (ML) Description missing.\n\n\n\nIn case of nsim &gt; 1, a set of nsim pairs of observed and expected quantiles are returned (observed_1, expected_1, … observed_nsim, observed_nsim) is returned.\nThe “qqrplot” also contains additional attributes xlab, ylab, main, simint_level, scale, and detrended used to create the plot.\n\nDunn KP, Smyth GK (1996). “Randomized Quantile Residuals.” Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\n\nplot.qqrplot, wormplot, proresiduals, qqnorm\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot qqrplot\nqqrplot(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot qqrplot as base graphic\nq1 &lt;- qqrplot(m1_pois, plot = FALSE)\nq2 &lt;- qqrplot(m2_pois, plot = FALSE)\n\n## plot combined qqrplot as \"ggplot2\" graphic\nggplot2::autoplot(c(q1, q2), single_graph = TRUE, col = c(1, 2), fill = c(1, 2))\n\n\n\n\n\n\n## Use different `scale`s with confidence intervals\nqqrplot(m1_pois, scale = \"uniform\")\n\n\n\n\n\n\nqqrplot(m1_pois, scale = \"normal\")\n\n\n\n\n\n\nqqrplot(m1_pois, detrend = TRUE, scale = \"uniform\", confint = \"line\")\n\n\n\n\n\n\nqqrplot(m1_pois, detrend = TRUE, scale = \"normal\", confint = \"line\")",
    "crumbs": [
      "Probabilistic model diagnostics",
      "qqrplot"
    ]
  },
  {
    "objectID": "man/qqrplot.html#q-q-plots-for-quantile-residuals",
    "href": "man/qqrplot.html#q-q-plots-for-quantile-residuals",
    "title": "topmodels",
    "section": "",
    "text": "Visualize goodness of fit of regression models by Quantile-Quantile (Q-Q) plots using quantile residuals. If plot = TRUE, the resulting object of class “qqrplot” is plotted by plot.qqrplot or autoplot.qqrplot before it is returned, depending on whether the package ggplot2 is loaded.\n\nqqrplot(object, ...)\n\n## Default S3 method:\nqqrplot(\n  object,\n  newdata = NULL,\n  plot = TRUE,\n  class = NULL,\n  detrend = FALSE,\n  ref_type = \"identity\",\n  scale = c(\"normal\", \"uniform\"),\n  nsim = 1L,\n  delta = NULL,\n  simint = TRUE,\n  simint_level = 0.95,\n  simint_nrep = 250,\n  confint = TRUE,\n  ref = TRUE,\n  xlab = \"Theoretical quantiles\",\n  ylab = if (!detrend) \"Quantile residuals\" else \"Deviation\",\n  main = NULL,\n  ...\n)\n\n\n\n\n\nobject\n\n\nan object from which probability integral transforms can be extracted using the generic function procast.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\nplot\n\n\nlogical or character. Should the plot or autoplot method be called to draw the computed Q-Q plot? Logical FALSE will suppress plotting, TRUE (default) will choose the type of plot conditional if the package ggplot2 is loaded. Alternatively “base” or “ggplot2” can be specified to explicitly choose the type of plot.\n\n\n\n\nclass\n\n\nshould the invisible return value be either a data.frame or a tibble. Either set class expicitly to “data.frame” vs. “tibble”, or for NULL it’s chosen automatically conditional if the package tibble is loaded.\n\n\n\n\ndetrend\n\n\nlogical, defaults to FALSE. Should the qqrplot be detrended, i.e, plotted as a wormplot?\n\n\n\n\nref_type\n\n\ncharacter specifying that the \"identity\" line should be used as as a reference or the \"quartiles\" of the quantile residuals should be used for defining the reference line. Alternatively, also a numeric vector of length two can be used to define the probabilities to be used for defining the reference line. Note, that the reference is also used for detrending the quantile residuals.\n\n\n\n\nscale\n\n\ncharacter. On which scale should the quantile residuals be shown: on the probability scale (“uniform”) or on the normal scale (“normal”).\n\n\n\n\nnsim, delta\n\n\narguments passed to proresiduals.\n\n\n\n\nsimint\n\n\nlogical. In case of discrete distributions, should the simulation (confidence) interval due to the randomization be visualized?\n\n\n\n\nsimint_level\n\n\nnumeric. The confidence level required for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nsimint_nrep\n\n\nnumeric (positive; default 250). The number of repetitions of simulated quantiles for calculating the simulation (confidence) interval due to the randomization.\n\n\n\n\nconfint\n\n\nlogical or character describing the style for plotting confidence intervals. TRUE (default) and “line” will add point-wise confidence intervals of the (randomized) quantile residuals as lines, “polygon” will draw a polygon instead, and FALSE suppresses the drawing.\n\n\n\n\nref\n\n\nlogical, defaults to TRUE. Should a reference line be plotted?\n\n\n\n\nxlab, ylab, main, …\n\n\ngraphical parameters passed to plot.qqrplot or autoplot.qqrplot.\n\n\n\nQ-Q residuals plots draw quantile residuals (by default on the standard normal scale) against theoretical quantiles from the same distribution. Alternatively, quantile residuals can also be compared on the uniform scale (scale = “uniform”) using no transformation. For computation, qqrplot leverages the function proresiduals employing the procast generic.\nAdditional options are offered for models with discrete responses where randomization of quantiles is needed.\nIn addition to the plot and autoplot method for qqrplot objects, it is also possible to combine two (or more) Q-Q residuals plots by c/rbind, which creates a set of Q-Q residuals plots that can then be plotted in one go.\n\nAn object of class “qqrplot” inheriting from “data.frame” or “tibble” conditional on the argument class with the following variables:\n\n\n\nobserved\n\n\ndeviations between theoretical and empirical quantiles,\n\n\n\n\nexpected\n\n\ntheoretical quantiles,\n\n\n\n\nsimint_observed_lwr\n\n\nlower bound of the simulated confidence interval,\n\n\n\n\nsimint_observed_upr\n\n\nupper bound of the simulated confidence interval,\n\n\n\n\nsimint_expected\n\n\nTODO: (ML) Description missing.\n\n\n\nIn case of nsim &gt; 1, a set of nsim pairs of observed and expected quantiles are returned (observed_1, expected_1, … observed_nsim, observed_nsim) is returned.\nThe “qqrplot” also contains additional attributes xlab, ylab, main, simint_level, scale, and detrended used to create the plot.\n\nDunn KP, Smyth GK (1996). “Randomized Quantile Residuals.” Journal of Computational and Graphical Statistics, 5(3), 236–244. doi:10.2307/1390802\n\nplot.qqrplot, wormplot, proresiduals, qqnorm\n\n\nlibrary(\"topmodels\")\n\n\n## speed and stopping distances of cars\nm1_lm &lt;- lm(dist ~ speed, data = cars)\n\n## compute and plot qqrplot\nqqrplot(m1_lm)\n\n\n\n\n\n\n#-------------------------------------------------------------------------------\n## determinants for male satellites to nesting horseshoe crabs\ndata(\"CrabSatellites\", package = \"countreg\")\n\n## linear poisson model\nm1_pois &lt;- glm(satellites ~ width + color, data = CrabSatellites, family = poisson)\nm2_pois &lt;- glm(satellites ~ color, data = CrabSatellites, family = poisson)\n\n## compute and plot qqrplot as base graphic\nq1 &lt;- qqrplot(m1_pois, plot = FALSE)\nq2 &lt;- qqrplot(m2_pois, plot = FALSE)\n\n## plot combined qqrplot as \"ggplot2\" graphic\nggplot2::autoplot(c(q1, q2), single_graph = TRUE, col = c(1, 2), fill = c(1, 2))\n\n\n\n\n\n\n## Use different `scale`s with confidence intervals\nqqrplot(m1_pois, scale = \"uniform\")\n\n\n\n\n\n\nqqrplot(m1_pois, scale = \"normal\")\n\n\n\n\n\n\nqqrplot(m1_pois, detrend = TRUE, scale = \"uniform\", confint = \"line\")\n\n\n\n\n\n\nqqrplot(m1_pois, detrend = TRUE, scale = \"normal\", confint = \"line\")",
    "crumbs": [
      "Probabilistic model diagnostics",
      "qqrplot"
    ]
  },
  {
    "objectID": "man/proscore.html",
    "href": "man/proscore.html",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and default method for computing various kinds of scores for fitted or predicted probability distributions from (regression) models.\n\nproscore(object, newdata = NULL, ...)\n\n## Default S3 method:\nproscore(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = c(\"logs\", \"crps\"),\n  aggregate = TRUE,\n  drop = FALSE,\n  ...\n)\n\n\n\n\n\nobject\n\n\na fitted model object. For the default method this needs to have a prodist and a newresponse method.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict and from which to obtain the response variable. If omitted, the original observations are used.\n\n\n\n\n…\n\n\nfurther parameters passed to the aggregate function (if any).\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to employ NA.\n\n\n\n\ntype\n\n\ncharacter specifying the type of score to compute. Avaible types: “logs” (or equivalently “log-score”), “loglikelihood” (or equivalently “log_pdf”), “CRPS” (or equivalently “RPS”), “MAE”, “MSE”, “DSS” (or equivalently “Dawid-Sebastiani”). Upper or lower case spellings can be used interchangably, hyphens or underscores can be included or omitted. Setting type = NULL yields all available scores.\n\n\n\n\naggregate\n\n\nlogical or function to be used for aggregating scores across observations. Setting aggregate = TRUE (the default) corresponds to using mean.\n\n\n\n\ndrop\n\n\nlogical. Should scores be returned in a data frame (default) or (if possible) dropped to a vector?\n\n\n\nThe function proscore provides a unified framework for scoring probabilistic forecasts (in-sample or out-of-sample). The following scores are currently available, using the following notation: \\(Y\\) is the predicted random variable with cumulative distribution function \\(F(\\cdot)\\) and probability density function \\(f(\\cdot)\\). The corresponding expectation and variance are denoted by \\(E(Y)\\) and \\(V(Y)\\). The actual observation is \\(y\\).\nLog-score: Also known as logarithmic score. This is the negative log-likelihood where the negative sign has the effect that smaller values indicate a better fit.\n\n\n -f(y) \nLog-likelihood: Also known as log-density. Clearly, this is equivalent to the log-score above but using the conventional sign where bigger values indicate a better fit.\n\n\n f(y) \nContinuous ranked probability score (CRPS):\n\n\n _{-}^{} ( F(x) - 1(x y) )^2 x \nwhere \\(1(\\cdot)\\) denotes the indicator function.\nIn case of a discrete rather than a continuous distribution, the ranked probability score (RPS) is defined analogously using the sum rather than the integral. In other words it is then the sum of the squared deviations between the predicted cumulative probabilities \\(F(x)\\) and the ideal step function for the actual observation \\(y\\).\nMean absolute error (MAE):\n\n\n | y - E(Y) | \nMean squared error (MSE):\n\n\n ( y - E(Y) )^2 \nDawid-Sebastiani score (DSS):\n\n\n + (V(Y)) \nInternally, the default proscore method first computes the fitted/predicted probability distribution object using prodist (corresponding to \\(Y\\) above) and then obtains the corresponding observation \\(y\\) using newresponse. Subsequently, the scores are evaluated using either the log_pdf method, crps method, or simply the mean. Finally, the resulting individual scores per observation can be returned as a full data frame, or aggregated (e.g., by using mean, sum, or summary, etc.).\n\nEither a data.frame of scores (if drop = FALSE, default) or a named numeric vector (if drop = TRUE and the scores are not a matrix). The names are the type specified by the user (i.e., are not canonicalized by partial matching etc.).\n\n\nlibrary(\"topmodels\")\n\n## Poisson regression model for FIFA 2018 data:\n## number of goals scored by each team in each game, explained by\n## predicted ability difference of the competing teams\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## default: in-sample mean log-score and CRPS\nproscore(m)\n\n      logs      crps\n1 1.388258 0.5619936\n\n## element-wise score using a new data set (final of the tournament)\nfinal &lt;- tail(FIFA2018, 2)\nproscore(m, newdata = final, aggregate = FALSE)\n\n        logs      crps\n127 2.891437 1.7744030\n128 1.741564 0.7205361\n\n## replicate in-sample log-likelihood\nproscore(m, type = \"loglik\", aggregate = sum)\n\n     loglik\n1 -177.6971\n\nlogLik(m)\n\n'log Lik.' -177.6971 (df=2)\n\n## compute mean of all available scores\nproscore(m, type = NULL)\n\n      logs loglikelihood      crps       mae      mse      dss\n1 1.388258     -1.388258 0.5619936 0.8320441 1.162032 1.085419\n\n## upper vs. lower case spelling is matched internally but preserved in output\nproscore(m, type = c(\"logs\", \"crps\"))\n\n      logs      crps\n1 1.388258 0.5619936\n\nproscore(m, type = c(\"Log-score\", \"CRPS\"))\n\n  Log-score      CRPS\n1  1.388258 0.5619936\n\n## least-squares regression for speed and breaking distance of cars\ndata(\"cars\", package = \"datasets\")\nm &lt;- lm(dist ~ speed, data = cars)\n\n## replicate in-sample log-likelihood and residual sum of squares\n## (aka deviance) by taking the sum (rather than the mean) of the\n## log-density and squared errors, respectively\nproscore(m, type = c(\"loglik\", \"MSE\"), aggregate = sum)\n\n     loglik      MSE\n1 -206.5784 11353.52\n\nlogLik(m)\n\n'log Lik.' -206.5784 (df=3)\n\ndeviance(m)\n\n[1] 11353.52",
    "crumbs": [
      "Procast infrastructure",
      "proscore"
    ]
  },
  {
    "objectID": "man/proscore.html#scoring-probabilistic-forecasts",
    "href": "man/proscore.html#scoring-probabilistic-forecasts",
    "title": "topmodels",
    "section": "",
    "text": "Generic function and default method for computing various kinds of scores for fitted or predicted probability distributions from (regression) models.\n\nproscore(object, newdata = NULL, ...)\n\n## Default S3 method:\nproscore(\n  object,\n  newdata = NULL,\n  na.action = na.pass,\n  type = c(\"logs\", \"crps\"),\n  aggregate = TRUE,\n  drop = FALSE,\n  ...\n)\n\n\n\n\n\nobject\n\n\na fitted model object. For the default method this needs to have a prodist and a newresponse method.\n\n\n\n\nnewdata\n\n\noptionally, a data frame in which to look for variables with which to predict and from which to obtain the response variable. If omitted, the original observations are used.\n\n\n\n\n…\n\n\nfurther parameters passed to the aggregate function (if any).\n\n\n\n\nna.action\n\n\nfunction determining what should be done with missing values in newdata. The default is to employ NA.\n\n\n\n\ntype\n\n\ncharacter specifying the type of score to compute. Avaible types: “logs” (or equivalently “log-score”), “loglikelihood” (or equivalently “log_pdf”), “CRPS” (or equivalently “RPS”), “MAE”, “MSE”, “DSS” (or equivalently “Dawid-Sebastiani”). Upper or lower case spellings can be used interchangably, hyphens or underscores can be included or omitted. Setting type = NULL yields all available scores.\n\n\n\n\naggregate\n\n\nlogical or function to be used for aggregating scores across observations. Setting aggregate = TRUE (the default) corresponds to using mean.\n\n\n\n\ndrop\n\n\nlogical. Should scores be returned in a data frame (default) or (if possible) dropped to a vector?\n\n\n\nThe function proscore provides a unified framework for scoring probabilistic forecasts (in-sample or out-of-sample). The following scores are currently available, using the following notation: \\(Y\\) is the predicted random variable with cumulative distribution function \\(F(\\cdot)\\) and probability density function \\(f(\\cdot)\\). The corresponding expectation and variance are denoted by \\(E(Y)\\) and \\(V(Y)\\). The actual observation is \\(y\\).\nLog-score: Also known as logarithmic score. This is the negative log-likelihood where the negative sign has the effect that smaller values indicate a better fit.\n\n\n -f(y) \nLog-likelihood: Also known as log-density. Clearly, this is equivalent to the log-score above but using the conventional sign where bigger values indicate a better fit.\n\n\n f(y) \nContinuous ranked probability score (CRPS):\n\n\n _{-}^{} ( F(x) - 1(x y) )^2 x \nwhere \\(1(\\cdot)\\) denotes the indicator function.\nIn case of a discrete rather than a continuous distribution, the ranked probability score (RPS) is defined analogously using the sum rather than the integral. In other words it is then the sum of the squared deviations between the predicted cumulative probabilities \\(F(x)\\) and the ideal step function for the actual observation \\(y\\).\nMean absolute error (MAE):\n\n\n | y - E(Y) | \nMean squared error (MSE):\n\n\n ( y - E(Y) )^2 \nDawid-Sebastiani score (DSS):\n\n\n + (V(Y)) \nInternally, the default proscore method first computes the fitted/predicted probability distribution object using prodist (corresponding to \\(Y\\) above) and then obtains the corresponding observation \\(y\\) using newresponse. Subsequently, the scores are evaluated using either the log_pdf method, crps method, or simply the mean. Finally, the resulting individual scores per observation can be returned as a full data frame, or aggregated (e.g., by using mean, sum, or summary, etc.).\n\nEither a data.frame of scores (if drop = FALSE, default) or a named numeric vector (if drop = TRUE and the scores are not a matrix). The names are the type specified by the user (i.e., are not canonicalized by partial matching etc.).\n\n\nlibrary(\"topmodels\")\n\n## Poisson regression model for FIFA 2018 data:\n## number of goals scored by each team in each game, explained by\n## predicted ability difference of the competing teams\ndata(\"FIFA2018\", package = \"distributions3\")\nm &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson)\n\n## default: in-sample mean log-score and CRPS\nproscore(m)\n\n      logs      crps\n1 1.388258 0.5619936\n\n## element-wise score using a new data set (final of the tournament)\nfinal &lt;- tail(FIFA2018, 2)\nproscore(m, newdata = final, aggregate = FALSE)\n\n        logs      crps\n127 2.891437 1.7744030\n128 1.741564 0.7205361\n\n## replicate in-sample log-likelihood\nproscore(m, type = \"loglik\", aggregate = sum)\n\n     loglik\n1 -177.6971\n\nlogLik(m)\n\n'log Lik.' -177.6971 (df=2)\n\n## compute mean of all available scores\nproscore(m, type = NULL)\n\n      logs loglikelihood      crps       mae      mse      dss\n1 1.388258     -1.388258 0.5619936 0.8320441 1.162032 1.085419\n\n## upper vs. lower case spelling is matched internally but preserved in output\nproscore(m, type = c(\"logs\", \"crps\"))\n\n      logs      crps\n1 1.388258 0.5619936\n\nproscore(m, type = c(\"Log-score\", \"CRPS\"))\n\n  Log-score      CRPS\n1  1.388258 0.5619936\n\n## least-squares regression for speed and breaking distance of cars\ndata(\"cars\", package = \"datasets\")\nm &lt;- lm(dist ~ speed, data = cars)\n\n## replicate in-sample log-likelihood and residual sum of squares\n## (aka deviance) by taking the sum (rather than the mean) of the\n## log-density and squared errors, respectively\nproscore(m, type = c(\"loglik\", \"MSE\"), aggregate = sum)\n\n     loglik      MSE\n1 -206.5784 11353.52\n\nlogLik(m)\n\n'log Lik.' -206.5784 (df=3)\n\ndeviance(m)\n\n[1] 11353.52",
    "crumbs": [
      "Procast infrastructure",
      "proscore"
    ]
  }
]