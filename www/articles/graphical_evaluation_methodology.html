<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Graphical Evaluation: Methodology • topmodels</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Graphical Evaluation: Methodology">
<meta property="og:description" content="topmodels">
<meta property="og:image" content="https://topmodels.R-Forge.R-project.org/logo.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@MoritzNLang">
<meta name="twitter:site" content="@MoritzNLang">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">topmodels</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1-0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/topmodels.html">Get started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/graphical_evaluation_methodology.html">Graphical Evaluation: Methodology</a>
    </li>
    <li>
      <a href="../articles/graphical_evaluation_simulations.html">Graphical Evaluation: Simulations</a>
    </li>
    <li>
      <a href="../articles/graphical_evaluation_realcases.html">Graphical Evaluation: Real Cases</a>
    </li>
    <li>
      <a href="../articles/implementation_functions_graphical_evaluation.html">Implementation: Functions for Graphical Evaluation</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
<li>
  <a href="../contact.html">Contact</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Graphical Evaluation: Methodology</h1>
                        <h4 class="author">Moritz Lang, Achim Zeileis</h4>
            
      
      
      <div class="hidden name"><code>graphical_evaluation_methodology.Rmd</code></div>

    </div>

    
    
<style type="text/css">
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
</style>
<script type="text/javascript">
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
</script><div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>Before discussing the various graphical evaluation methods in more detail, we want to outline the underlying motivation and identify similarities and differences in the methodologies. According to the seminal work of <span class="citation">Gneiting, Balabdaoui, and Raftery (2007)</span>, probabilistic forecasts aim to <em>maximize the sharpness of the predictive distributions subject to calibration</em>. Calibration here refers to the statistical concordance between the forecast and the observation, and is thus a joint property of the forecast and observation. Sharpness, on the other hand, is a property of the forecast only and indicates how concentrated a predictive distribution is. In general, the more concentrated the sharper the forecast.</p>
<p>In this article, we focus on several graphical diagnostic tools to assess the calibration of a probabilistic forecast <span class="math inline">\(F( \cdot | \boldsymbol{\theta}_{i})\)</span>, issued in form of a predictive distribution <span class="math inline">\(f( \cdot | \boldsymbol{\theta}_{i})\)</span>. Given observations <span class="math inline">\(y_i (i = 1, \ldots, n)\)</span>, we assume a set of observation-specific fitted parameters <span class="math inline">\(\hat{\boldsymbol{\theta}}_{i} = (\hat{\theta}_{i1}, \ldots, \hat{\theta}_{iK})^\top\)</span>, where the estimation may have been performed on the same observations <span class="math inline">\(i = 1, \ldots, n\)</span> (i.e., corresponding to an in-sample assessment) or on a different data set (i.e., corresponding to an out-of-sample evaluation). The estimation procedure itself can be either fully parametric or semi-parametric, as long as fitted parameters <span class="math inline">\(\hat{\boldsymbol{\theta}}_{i}\)</span> exist for all observations of interest. However, since the uncertainty in the estimation of the parameters is not accounted for, small deviations from asymptotic theoretical properties will be apparent in all graphical displays due to some sampling variation.</p>
<div id="probabilistic-calibration-pit-residuals" class="section level3">
<h3 class="hasAnchor">
<a href="#probabilistic-calibration-pit-residuals" class="anchor"></a>Probabilistic calibration: PIT residuals</h3>
<p>According to <span class="citation">Gneiting, Balabdaoui, and Raftery (2007)</span>, model calibration can be further distinguished between probabilistic calibration and marginal calibration. Probabilistic calibration is usually assessed using probability integral transform (PIT) values <span class="citation">(Dawid 1984; Diebold, Gunther, and Tay 1998; Gneiting, Balabdaoui, and Raftery 2007)</span> or so-called PIT residuals <span class="citation">(Warton 2017)</span>. These are simply the predictive cumulative distribution function (CDF) evaluated at the observations</p>
<p><span class="math display">\[u_i = F(y_i | \, \hat{\boldsymbol{\theta}}_i),\]</span></p>
<p>where <span class="math inline">\(F( \cdot )\)</span> denotes the CDF of the modeled distribution <span class="math inline">\(f( \cdot )\)</span> with estimated parameters <span class="math inline">\(\hat{\boldsymbol{\theta}}_{i}\)</span>. PIT residuals have the desirable property, that if the model is a good approximation to the true data-generating process, i.e., the observation is drawn from the predictive distribution, the PIT residuals <span class="math inline">\(u_i\)</span> are approximately uniformly distributed on <span class="math inline">\([0, 1]\)</span> for continous predictive distributions <span class="math inline">\(F( \cdot )\)</span>. PIT residuals or variants have therefore been used extensively for model diagnosis and depending on their implementation are known under various names, among them forecast distribution transformed residuals <span class="citation">(Smith 1985)</span>, randomized quantile residuals <span class="citation">(Dunn and Smyth 1996)</span>, and universal residuals <span class="citation">(Brockwell 2007)</span>.</p>
<p>In case of a discrete predictive distribution or a distribution with a discrete component, e.g., in case of censoring, <span class="math inline">\(u_i\)</span> can be generated as a random draw <span class="math inline">\(\text{U}\)</span> from the interval:</p>
<p><span class="math display">\[u_i = \text{U}[F(y_i - 1 | \, \hat{\boldsymbol{\theta}}_i), F(y_i | \,
\hat{\boldsymbol{\theta}}_i)].\]</span></p>
<p>Here, we follow the definition by <span class="citation">Dunn and Smyth (1996)</span>, but similar approaches have also been proposed in, e.g., <span class="citation">Brockwell (2007)</span> and <span class="citation">Smith (1985)</span>. Again <span class="math inline">\(u_i\)</span> is uniformally distributed, apart from sampling variability.</p>
<p>Since the PIT residuals are an iid sample from the standard uniform distribution, the PIT residuals can also be mapped to other distribution scales, e.g. to the standard normal scale, and should follow a standard normal distribution here. In the simplest case, the PIT residuals <span class="math inline">\(u_i\)</span> can be plotted against the probabilities of a uniform distribution in so-called P-P plots <span class="citation">(Wilk and Gnanadesikan 1968; Handcock and Morris 1999)</span>. However, it is far more common to transform the PIT residuals to the normal scale and compare them to the standard normal quantiles in a normal Q-Q plot <span class="citation">(Hoaglin 2006)</span>. Alternatively, in a PIT histogram, the uniformally distributed PIT residuals are divided into intervals by a certain number of breakpoints and plotted in a histogram-style plot. Regardless of the graphical display, the PIT residuals are always on the probability scale, which might be transformed to the normal scale or another scale if preferred.</p>
</div>
<div id="marginal-calibration-observed-vs--expected-frequencies" class="section level3">
<h3 class="hasAnchor">
<a href="#marginal-calibration-observed-vs--expected-frequencies" class="anchor"></a>Marginal calibration: Observed vs. expected frequencies</h3>
<p>Marginal calibration is generally concerned with whether the oberseved frequencies match the frequencies expected by the model. For discrete observations, frequencies for the observations themselves can be considered; for continuous observations or more generally, frequencies for intevals of observations are being used. Here, the expected frequencies are computed by differences between the predictive CDFs <span class="math inline">\(F( \cdot )\)</span>, evaluated at the interval breaks. Hence, mariginal calibration is always obtained on the observation scale compared to the probabilistic calibration performed on the probability scale. Although there are some previous studies that display observation points rather than intervals <span class="citation">(e.g., Gneiting, Balabdaoui, and Raftery 2007)</span>, here we stick to the former and discuss only the so-called rootograms which are histogram-style plots <span class="citation">(Kleiber and Zeileis 2016)</span>.</p>
<p>For the special case of a binary event, the observed event frequency is typically plotted against the predictive probability in a so-called reliability diagram <span class="citation">(Wilks 2011; Bröcker and Smith 2007)</span>. Here, the predicted probability for a binary event is partitioned into a certain number of bins and the averaged forecast probability within each bin is plotted against the observerd relative frequency. Typically, equidistant binning is employed, but here the rather arbitrary number of bins can be quite sensible. A simple and common enhancement is therefore to use evenly populated bins, though even here instabilities can be a major issue <span class="citation">(Dimitriadis, Gneiting, and Jordan 2021)</span>.</p>
</div>
<div id="similarities-and-differences" class="section level3">
<h3 class="hasAnchor">
<a href="#similarities-and-differences" class="anchor"></a>Similarities and differences</h3>
<p>In the graphical displays for assessing the goodness of fit, several recurring elements can be seen:</p>
<ul>
<li><p>PIT residuals are asymptotically uniformly distributed or transformed to another probability scale: The PIT histogram is on the uniform probability scale versus the normal Q-Q plot on the normal scale. Whereas, the transformation to the normal scale spreads the values in the tails further apart and thus better highlights possible discrepancies in the distribuional tails.</p></li>
<li><p>The marginal calibration is usually evaluated on the observation scale by checking whether observed and expected frequencies match. The rootogram, on the observation scale, is therefore especially useful for count data with values close to zero.</p></li>
<li><p>Discretization: Instead of plotting the raw values, e.g. PIT residuals, often some discretization improves readability of the graphical displays. The disadvantage here is that the breakpoint are often kind of arbitrary and certain misspecification might therefore be masked by plotting the values as intervals. For example, misscpecifications in the outer tails of the distribution are often not visible in PIT histograms, as the intervals are averaving over many data points; here, Q-Q plots are clearly superior. Another example is the reliabitiliy diagram, which can be quite instable when using equidistant binning.</p></li>
<li><p>The uncertainty due to the estimation of the parameters is not taken into account. Therefore, some sampling variation is seen in all graphical displays.</p></li>
</ul>
</div>
</div>
<div id="methodology" class="section level2">
<h2 class="hasAnchor">
<a href="#methodology" class="anchor"></a>Methodology</h2>
<div id="rootogram" class="section level3">
<h3 class="hasAnchor">
<a href="#rootogram" class="anchor"></a>Rootogram</h3>
<p>The rootogram is a graphical tool for assessing the goodness of fit in terms of mariginal calibration of a parametric univariate distributional model, with estimated parameters <span class="math inline">\(\hat{\boldsymbol{\theta}}_{i} = (\hat{\theta}_{i1}, \ldots, \hat{\theta}_{iK})^\top\)</span> and <span class="math inline">\(f( \cdot )\)</span> desribing the density or probability mass function. Rootograms evaluate graphically whether observed frequencies <span class="math inline">\(\text{obs}_j\)</span> match the expected frequencies <span class="math inline">\(\text{exp}_j\)</span> by plotting histogram-like rectangles or bars for the observed frequencies and a curve for the fitted frequencies, both on a square-root scale. In the form presented here, it was implemented by <span class="citation">Kleiber and Zeileis (2016)</span> building on work of <span class="citation">Tukey (1977)</span>.</p>
<p>In the most general form, given an observational vector of a random variable <span class="math inline">\(y_i (i = 1, \ldots, n)\)</span> which is divided into subsets by a set of breakpoints <span class="math inline">\(b_0, b_1, b_2, \dots~\)</span>, the observed and expected frequencies are given by</p>
<p><span class="math display">\[\text{obs}_j = \sum_{i=1}^{n}w_{i} I(y_i \in (b_j, b_{j+1}]),\]</span> <span class="math display">\[\text{exp}_j = \sum_{i=1}^{n}w\{F(b_{j+1} |
  \hat{\boldsymbol{\theta}}_{i}) - F(b_{j} | \hat{\boldsymbol{\theta}}_{i})\},\]</span></p>
<p>with <span class="math inline">\(F( \cdot )\)</span> being the CDF of the modeled distributional model <span class="math inline">\(f( \cdot )\)</span> and <span class="math inline">\(w_i\)</span> being optional observation-specific weights. Whereby, the weights are typically needed either for survey data or for situations with model-based weights <span class="citation">(Kleiber and Zeileis 2016)</span>.</p>
<p>For a discrete variable <span class="math inline">\(y_i\)</span>, the observed and expected frequencies can be simplified and are given for each integer <span class="math inline">\(j\)</span> by</p>
<p><span class="math display">\[\text{obs}_j = \sum_{i=1}^{n}I(y_i - j),\]</span> <span class="math display">\[\text{exp}_j = \sum_{i=1}^{n}f(j | \hat{\boldsymbol{\theta}}_{i}),\]</span></p>
<p>with the indicator variable <span class="math inline">\(I( \cdot )\)</span> <span class="citation">(Kleiber and Zeileis 2016)</span>. As rootograms are best known for count data, the latter form is quite common.</p>
<p>Different styles of rootograms have been proposed and are extensively discussed in <span class="citation">Kleiber and Zeileis (2016)</span>. As default, they propose a so called “hanging” rootogram, which aligns all deviations along the horizontal axis, as the rectangles are drawn from <span class="math inline">\(\sqrt{exp_j}\)</span> to <span class="math inline">\(\sqrt{exp_j} - \sqrt{obs_j}\)</span>, so that they “hang” from the curve with the expected frequencies <span class="math inline">\(\sqrt{exp_j}\)</span>.</p>
<p>The concept of comparing observed and expected frequencies graphically was also introduced in the seminal work on assessing calibration and sharpness for a predictive probalilty model by <span class="citation">Gneiting, Balabdaoui, and Raftery (2007)</span> and, building on this, applied to count data by <span class="citation">Czado, Gneiting, and Held (2009)</span>. However, since in both cases either the deviations or the expected and observed frequencies are presented only as lines connecting the respective frequencies, deviations are more difficult to detect compared to the rootograms introduced by <span class="citation">Tukey (1977)</span> and further enhanced by <span class="citation">Kleiber and Zeileis (2016)</span>.</p>
</div>
<div id="pit-histogram" class="section level3">
<h3 class="hasAnchor">
<a href="#pit-histogram" class="anchor"></a>PIT Histogram</h3>
<p>As described in the introduction, to check for probabilistic calibration of a regression model, <span class="citation">Dawid (1984)</span> proposed the use of the probability integral transform (PIT) which is simply the predictive cumulative distribution function (CDF) evaluated at the observations. PIT values have been used under various names <span class="citation">(e.g., Smith 1985; Dunn and Smyth 1996; Brockwell 2007)</span> , to emphasize their similar properties to residuals we follow <span class="citation">Warton (2017)</span> and refer to them as PIT residuals from now on.</p>
<p>For a continuous random variable <span class="math inline">\(y_i (i = 1, \ldots, n)\)</span>, PIT residuals are defined as</p>
<p><span class="math display">\[u_i = F(y_i | \, \hat{\boldsymbol{\theta}}_i)\]</span></p>
<p>where <span class="math inline">\(F( \cdot )\)</span> denotes the CDF of the modeled distribution <span class="math inline">\(f( \cdot )\)</span> with estimated parameters <span class="math inline">\(\hat{\boldsymbol{\theta}}_{i} = (\hat{\theta}_{i1}, \ldots, \hat{\theta}_{iK})^\top\)</span>. If the estimated model is a good approximation to the true data generating process, the observation will be drawn from the predictive distribution and the PIT residuals <span class="math inline">\(u_i\)</span> are approximately uniformly distributed on <span class="math inline">\([0, 1]\)</span>. Plotting the histogram of the PIT residuals and checking for uniformity is therefore a common empirical way of checking for calibration <span class="citation">(Diebold, Gunther, and Tay 1998; Gneiting, Balabdaoui, and Raftery 2007)</span>. Whereas, deviations from uniformity point to underlying forecast errors and model deficiencies: U-shaped histograms refer to underdispersed predictive distributions, inverted U-shaped histograms to overdispersion, and skewed histograms suggest that central tendencies must be biased <span class="citation">(Gneiting, Balabdaoui, and Raftery 2007; Czado, Gneiting, and Held 2009)</span>.</p>
<p>When considering discrete response distributions or distributions with a discrete component, e.g., in case of censoring, for a random discrete variable <span class="math inline">\(y_i\)</span> the PIT <span class="math inline">\(u_i\)</span> can be generated as a random draw from the interval <span class="math inline">\([F(y_i - 1 | \, \hat{\boldsymbol{\theta}}_i), F(y_i | \,  \hat{\boldsymbol{\theta}}_i)]\)</span>. Even if this leads to some randomness in the graphical representation of PIT residuals, for cases with a high number of observations the impact on the graphical evaluation when repeating the calculations (i.e. drawing new values <span class="math inline">\(u_i\)</span>) is typically rather small. For small data sets, we recommend to increase the number of random draws which significantly reduces the randomness in the graphical display.</p>
<p>Alternatively, a nonrandom PIT histogram was introduced by <span class="citation">Czado, Gneiting, and Held (2009)</span>, where rather than building on randomized pointwise PIT resdiuals <span class="math inline">\(u_i\)</span> the expected fraction of the CDF along the interval <span class="math inline">\([F(y_i - 1 | \, \hat{\boldsymbol{\theta}}_i), F(y_i | \,  \hat{\boldsymbol{\theta}}_i)]\)</span> is used. This is asympotically equivalent to drawing an infinite number of random PIT residuals.</p>
</div>
<div id="q-q-residuals-plot" class="section level3">
<h3 class="hasAnchor">
<a href="#q-q-residuals-plot" class="anchor"></a>Q-Q Residuals Plot</h3>
<p>Quantile residuals are simply the inverse cumulative distribution function of a standard normal distribution <span class="math inline">\(\Phi^{-1}\)</span> evaluated at the PIT residuals <span class="math inline">\(u_i (i = 1, \ldots, n)\)</span>, hence, they can be defined as</p>
<p><span class="math display">\[\hat{r}_i = \Phi^{-1}(F(y_i | \, \hat{\boldsymbol{\theta}}_{i})) = 
  \Phi^{-1}(u_i),\]</span></p>
<p>where <span class="math inline">\(F( \cdot )\)</span> again denotes the cumulative distribution function (CDF) of the modeled distribution <span class="math inline">\(f( \cdot )\)</span> with estimated parameters <span class="math inline">\(\hat{\boldsymbol{\theta}}_{i} = (\hat{\theta}_{i1}, \ldots, \hat{\theta}_{iK})^\top\)</span> <span class="citation">(Dunn and Smyth 1996)</span>. As before, for discrete or partly discrete responses, the approach includes some randomization to achieve continuous <span class="math inline">\(u_i\)</span> values; quantile residuals are therefore often referred to as randomized quantile residuals in the literature <span class="citation">(Dunn and Smyth 1996)</span>.</p>
<p>In case of a correct model fit, the values <span class="math inline">\(u_i\)</span> are uniformly distributed on the unit interval and the Q-Q residuals should at least approximately be standard normally distributed. Hence, to check for normality, quantile residuals can be graphically compared to theoretical quantiles of the standard normal distribution, where strong deviations from the bisecting line indicate a misspecified model fit.</p>
<p>Mathematically, Q-Q plot consists of the tuples</p>
<p><span class="math display">\[(z_{(1)},  \hat{r}_{(1)}), \ldots,  (z_{(n)},  \hat{r}_{(n)}),\]</span></p>
<p>where <span class="math inline">\(\hat{r}_{(i)}\)</span> denotes the <span class="math inline">\(i\)</span>th order statistic of the quantile residuals, so that <span class="math inline">\(\hat{r}_{(1)} \leq \hat{r}_{(2)} \cdot \leq \hat{r}_{(n)}\)</span>, and <span class="math inline">\(z_{(i)}\)</span> is the ordered statistics from the respective standard normal quantiles <span class="math inline">\(\Phi^{-1}( p_i)\)</span>, evaluated at the cumulative proportion <span class="math inline">\(p_i = (i - 0.5) / n\)</span> for <span class="math inline">\(n\)</span> greater <span class="math inline">\(10\)</span>. This graphical evaluation is well known as normal probability plot or normal Q-Q plot <span class="citation">(Hoaglin 2006)</span>. Due to the transformation of the PIT residuals <span class="math inline">\(u_i\)</span> to the normal scale, their extreme values are more widely spread, so that normal Q-Q diagrams are better suited than, for example, PIT histograms to detect violations of the distribution assumption within its tails. An additional possible advantage of Q-Q plots is that they avoid the necessity of defining breakpoints as typically needed for histogram style evaluations <span class="citation">(Klein et al. 2015)</span>.</p>
<p>But Q-Q plots can also be applied to check if residuals follow any other known distribution, by employing any other inverse cumulative distribution function of interest instead of <span class="math inline">\(\Phi^{-1}\)</span> in the computation and comparing the quantile residuals <span class="math inline">\(\hat{r}_i\)</span> to the respective theoretical quantiles. This is called than a theoretical quantile-quantile plot or Q-Q plot for short <span class="citation">(Friendly 1991)</span>.</p>
</div>
<div id="worm-plot" class="section level3">
<h3 class="hasAnchor">
<a href="#worm-plot" class="anchor"></a>Worm plot</h3>
<p>As in Q-Q plots, small too medium deviations can be quite hard to detect, untilting the plot by subtracting the theoretical quantiles, makes detecting pattern of departure from a now horizontal line much easier. Mathematically, therefore, the tuples in the plot are</p>
<p><span class="math display">\[(z_{(1)},  \hat{r}_{(1)} - z_{(1)}), \ldots,  (z_{(n)},  \hat{r}_{(n)} - z_{(n)}),\]</span></p>
<p>where as before, where <span class="math inline">\(\hat{r}_{(i)}\)</span> denotes the order statistic of the empirical quantile residuals and <span class="math inline">\(z_{(i)}\)</span> the ordered statistics of the respective standard normal quantiles. This so-called de-trended Q-Q plot <span class="citation">(Friendly 1991)</span> is best known by the application of <span class="citation">Buuren and Fredriks (2001)</span>, and is therefore usually referred to as worm plot according to their naming.</p>
</div>
</div>
<div id="summary-plot" class="section level2">
<h2 class="hasAnchor">
<a href="#summary-plot" class="anchor"></a>Summary plot</h2>
<p><img src="graphical_evaluation_methodology_files/figure-html/plot-summary-1.png" width="100%" style="display: block; margin: auto;"></p>
<table class="table">
<colgroup>
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
</colgroup>
<thead><tr class="header">
<th>Predictive distribution</th>
<th>well calibrated</th>
<th>too skew to the left</th>
<th>too skew to the right</th>
<th>tails too light</th>
<th>tails too heavy</th>
<th>underdispersed (underestimated variance)</th>
<th>overdispersed (overestimated variance)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Resdiuals</strong></td>
<td>normal</td>
<td>right skewed</td>
<td>left skewed</td>
<td>heavy tailed</td>
<td>light tailed</td>
<td>overdispersed</td>
<td>underdispersed</td>
</tr>
<tr class="even">
<td><strong>Q-Q plot</strong></td>
<td>bisecting line</td>
<td>positive curvature (bends up the line at both ends)</td>
<td>negative curvature (bends down at both ends)</td>
<td>reverse S-shape (dips below the line at the low end and rises above it at the high end)</td>
<td>S-shape</td>
<td>crossing qqline from below (?)</td>
<td>crossing qqline from above ?</td>
</tr>
<tr class="odd">
<td><strong>Worm plot</strong></td>
<td>horizontal line</td>
<td>U-shape</td>
<td>inverse U-shape</td>
<td>S-shape on the left bent down</td>
<td>S-shape on the left bent up</td>
<td>positive slope</td>
<td>negative slope</td>
</tr>
<tr class="even">
<td><strong>PIT histogram</strong></td>
<td>uniform</td>
<td>skewed</td>
<td>skewed</td>
<td>superimposed U-shape</td>
<td>superimposed inverse U-shape"</td>
<td>U-shape</td>
<td>inverse U-shape</td>
</tr>
<tr class="odd">
<td><strong>Rootogram</strong></td>
<td>no deviations</td>
<td>?</td>
<td>?</td>
<td>wave-like (underfitting in the tails and the center)</td>
<td>?</td>
<td>?</td>
<td>?</td>
</tr>
<tr class="even">
<td><strong>Interpretation</strong></td>
<td>no misspecifications</td>
<td>?</td>
<td>?</td>
<td>values more extrem as expected</td>
<td>values less extrem as expected</td>
<td>?</td>
<td>?</td>
</tr>
</tbody>
</table>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-Broecker+Smith:2007">
<p>Bröcker, Jochen, and Leonard A. Smith. 2007. “Increasing the Reliability of Reliability Diagrams.” <em>Weather and Forecasting</em> 22 (3): 651–61. <a href="https://doi.org/10.1175/WAF993.1">https://doi.org/10.1175/WAF993.1</a>.</p>
</div>
<div id="ref-Brockwell:2007">
<p>Brockwell, A.E. 2007. “Universal Residuals: A Multivariate Transformation.” <em>Statistics &amp; Probability Letters</em> 77 (14): 1473–8. <a href="https://doi.org/https://doi.org/10.1016/j.spl.2007.02.008">https://doi.org/https://doi.org/10.1016/j.spl.2007.02.008</a>.</p>
</div>
<div id="ref-Buuren+Fredriks:2001">
<p>Buuren, Stef van, and Miranda Fredriks. 2001. “Worm Plot: A Simple Diagnostic Device for Modelling Growth Reference Curves.” <em>Statistics in Medicine</em> 20 (8): 1259–77. <a href="https://doi.org/10.1002/sim.746">https://doi.org/10.1002/sim.746</a>.</p>
</div>
<div id="ref-Czado+Gneiting+Held:2009">
<p>Czado, Claudia, Tilmann Gneiting, and Leonhard Held. 2009. “Predictive Model Assessment for Count Data.” <em>Biometrics</em> 65 (4): 1254–61. <a href="https://doi.org/10.1111/j.1541-0420.2009.01191.x">https://doi.org/10.1111/j.1541-0420.2009.01191.x</a>.</p>
</div>
<div id="ref-Dawid:1984">
<p>Dawid, A. P. 1984. “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach.” <em>Journal of the Royal Statistical Society: Series A (General)</em> 147 (2): 278–92. <a href="https://doi.org/10.2307/2981683">https://doi.org/10.2307/2981683</a>.</p>
</div>
<div id="ref-Diebold+Gunther+Tay:1998">
<p>Diebold, Francis X., Todd A. Gunther, and Anthony S. Tay. 1998. “Evaluating Density Forecasts with Applications to Financial Risk Management.” <em>International Economic Review</em> 39 (4): 863–83. <a href="https://doi.org/10.2307/2527342">https://doi.org/10.2307/2527342</a>.</p>
</div>
<div id="ref-Dimitriadis+Gneiting+Jordan:2021">
<p>Dimitriadis, Timo, Tilmann Gneiting, and Alexander I. Jordan. 2021. “Stable Reliability Diagrams for Probabilistic Classifiers.” <em>Proceedings of the National Academy of Sciences</em> 118 (8). <a href="https://doi.org/10.1073/pnas.2016191118">https://doi.org/10.1073/pnas.2016191118</a>.</p>
</div>
<div id="ref-Dunn+Smyth:1996">
<p>Dunn, Peter K., and Gordon K. Smyth. 1996. “Randomized Quantile Residuals.” <em>Journal of Computational and Graphical Statistics</em> 5 (3): 236–44. <a href="https://doi.org/10.2307/1390802">https://doi.org/10.2307/1390802</a>.</p>
</div>
<div id="ref-Friendly:1991">
<p>Friendly, Michael. 1991. <em>SAS System for Statistical Graphics</em>. 1st ed. Cary, NC: SAS Institute Inc.</p>
</div>
<div id="ref-Gneiting+Balabdaoui+Raftery:2007">
<p>Gneiting, Tilmann, Fadoua Balabdaoui, and Adrian E. Raftery. 2007. “Probabilistic Forecasts, Calibration and Sharpness.” <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 69 (2): 243–68. <a href="https://doi.org/10.1111/j.1467-9868.2007.00587.x">https://doi.org/10.1111/j.1467-9868.2007.00587.x</a>.</p>
</div>
<div id="ref-Handcock+Morris:1999">
<p>Handcock, Mark S., and Martina Morris. 1999. <em>Relative Distribution Methods in the Social Sciences</em>. New York: Springer. <a href="http://www.stat.ucla.edu/~handcock/RelDist">http://www.stat.ucla.edu/~handcock/RelDist</a>.</p>
</div>
<div id="ref-Hoaglin:2006">
<p>Hoaglin, David C. 2006. “Using Quantiles to Study Shape.” In <em>Exploring Data Tables, Trends, and Shapes</em>, 417–60. John Wiley &amp; Sons, Ltd. <a href="https://doi.org/https://doi.org/10.1002/9781118150702.ch10">https://doi.org/https://doi.org/10.1002/9781118150702.ch10</a>.</p>
</div>
<div id="ref-Kleiber+Zeileis:2016">
<p>Kleiber, Christian, and Achim Zeileis. 2016. “Visualizing Count Data Regressions Using Rootograms.” <em>The American Statistician</em> 70 (3): 296–303. <a href="https://doi.org/10.1080/00031305.2016.1173590">https://doi.org/10.1080/00031305.2016.1173590</a>.</p>
</div>
<div id="ref-Klein+Kneib+Lang+Sohn:2015">
<p>Klein, Nadja, Thomas Kneib, Stefan Lang, and Alexander Sohn. 2015. “Bayesian Structured Additive Distributional Regression with an Application to Regional Income Inequality in Germany.” <em>Annals of Applied Statistics</em> 9: 1024–52. <a href="https://doi.org/10.1214/15-aoas823">https://doi.org/10.1214/15-aoas823</a>.</p>
</div>
<div id="ref-Smith:1985">
<p>Smith, J. Q. 1985. “Diagnostic Checks of Non-Standard Time Series Models.” <em>Journal of Forecasting</em> 4 (3): 283–91. <a href="https://doi.org/https://doi.org/10.1002/for.3980040305">https://doi.org/https://doi.org/10.1002/for.3980040305</a>.</p>
</div>
<div id="ref-Tukey:1977">
<p>Tukey, John W. 1977. <em>Exploratory Data Analysis</em>. Addison-Wesley.</p>
</div>
<div id="ref-Warton:2017">
<p>Warton, Loïc AND Wang, David I. AND Thibaut. 2017. “The Pit-Trap—a ‘Model-Free’ Bootstrap Procedure for Inference About Regression Models with Discrete, Multivariate Responses.” <em>PLOS ONE</em> 12 (7): 1–18. <a href="https://doi.org/10.1371/journal.pone.0181790">https://doi.org/10.1371/journal.pone.0181790</a>.</p>
</div>
<div id="ref-Wilk:1968">
<p>Wilk, M. B., and R. Gnanadesikan. 1968. “Probability Plotting Methods for the Analysis of Data.” <em>Biometrika</em> 55 (1): 1–17.</p>
</div>
<div id="ref-Wilks:2011">
<p>Wilks, Daniel. 2011. <em>Statistical Methods in the Atmospheric Sciences</em>. 3rd ed. Academic Press.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Achim Zeileis, Moritz N. Lang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
