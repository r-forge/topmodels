[
  {
    "objectID": "man/CensoredNormal.html",
    "href": "man/CensoredNormal.html",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-censored normal distributions using the workflow from the distributions3 package.\n\nCensoredNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\n\n\n\n\n\nmu\n\n\nnumeric. The location parameter of the underlying uncensored normal distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nsigma\n\n\nnumeric. The scale parameter (standard deviation) of the underlying uncensored normal distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left censoring point. Can be any real number, defaults to -Inf (uncensored). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the uncensored normal distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right censoring point. Can be any real number, defaults to Inf (uncensored). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the uncensored normal distribution at this point.\n\n\n\nThe constructor function CensoredNormal sets up a distribution object, representing the censored normal probability distribution by the corresponding parameters: the latent mean mu = \\(\\mu\\) and latent standard deviation sigma = \\(\\sigma\\) (i.e., the parameters of the underlying uncensored normal variable), the left censoring point (with -Inf corresponding to uncensored), and the right censoring point (with Inf corresponding to uncensored).\nThe censored normal distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\n\\(\\Phi((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Phi((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\phi((x - \\mu)/\\sigma)/\\sigma\\)\n\n\notherwise\n\n\n\nwhere \\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of censored normal distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the CensoredNormal distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the censored normal distributions in the crch package, see dcnorm, and the crps_cnorm function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (only TRUE if there is no censoring, i.e., if both left and right are infinite).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA CensoredNormal distribution object.\n\ndcnorm, Normal, TruncatedNormal, CensoredLogistic, CensoredStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three censored normal distributions:\n## - uncensored standard normal\n## - left-censored at zero (Tobit) with latent mu = 1 and sigma = 1\n## - interval-censored in [0, 5] with latent mu = 1 and sigma = 2\nX &lt;- CensoredNormal(\n  mu    = c(   0,   1, 1),\n  sigma = c(   1,   1, 2),\n  left  = c(-Inf,   0, 0),\n  right = c( Inf, Inf, 5)\n)\nX\n\n[1] \"CensoredNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\"\n[2] \"CensoredNormal(mu = 1, sigma = 1, left =    0, right = Inf)\"\n[3] \"CensoredNormal(mu = 1, sigma = 2, left =    0, right =   5)\"\n\n## compute mean and variance of the censored distribution\nmean(X)\n\n[1] 0.000000 1.083315 1.378612\n\nvariance(X)\n\n[1] 1.0000000 0.7510878 2.0679838\n\n## higher moments (skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1        r_2        r_3       r_4       r_5\n[1,] -0.3421647 -0.6121245 -1.7461032 0.3600695 0.9275691\n[2,]  1.4528670  0.0000000  0.1263061 2.5174300 1.0124322\n[3,]  2.2338249  0.1466394  3.1254139 0.0000000 0.0000000\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"uncensored\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-censored at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-censored in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3989423 0.1586553 0.1994711\n\npdf(X, x, log = TRUE)\n\n[1] -0.9189385 -1.8410216 -1.6120857\n\nlog_pdf(X, x)\n\n[1] -0.9189385 -1.8410216 -1.6120857\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.1586553 0.5000000\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0 1 1\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n        q_0.05 q_0.5   q_0.95\n[1,] -1.644854     0 1.644854\n[2,]  0.000000     1 2.644854\n[3,]  0.000000     1 4.289707\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -1.644854  1.000000  4.289707\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -1.644854\n[2,]  1.000000\n[3,]  4.289707\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 0.01580424\n[2,]    1.083315 1.12030540\n[3,]    1.378612 1.38062119\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.2336950 0.5952063 0.3984091",
    "crumbs": [
      "distributions3 objects",
      "CensoredNormal"
    ]
  },
  {
    "objectID": "man/CensoredNormal.html#create-a-censored-normal-distribution",
    "href": "man/CensoredNormal.html#create-a-censored-normal-distribution",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-censored normal distributions using the workflow from the distributions3 package.\n\nCensoredNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\n\n\n\n\n\nmu\n\n\nnumeric. The location parameter of the underlying uncensored normal distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nsigma\n\n\nnumeric. The scale parameter (standard deviation) of the underlying uncensored normal distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left censoring point. Can be any real number, defaults to -Inf (uncensored). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the uncensored normal distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right censoring point. Can be any real number, defaults to Inf (uncensored). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the uncensored normal distribution at this point.\n\n\n\nThe constructor function CensoredNormal sets up a distribution object, representing the censored normal probability distribution by the corresponding parameters: the latent mean mu = \\(\\mu\\) and latent standard deviation sigma = \\(\\sigma\\) (i.e., the parameters of the underlying uncensored normal variable), the left censoring point (with -Inf corresponding to uncensored), and the right censoring point (with Inf corresponding to uncensored).\nThe censored normal distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\n\\(\\Phi((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Phi((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\phi((x - \\mu)/\\sigma)/\\sigma\\)\n\n\notherwise\n\n\n\nwhere \\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of censored normal distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the CensoredNormal distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the censored normal distributions in the crch package, see dcnorm, and the crps_cnorm function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (only TRUE if there is no censoring, i.e., if both left and right are infinite).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA CensoredNormal distribution object.\n\ndcnorm, Normal, TruncatedNormal, CensoredLogistic, CensoredStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three censored normal distributions:\n## - uncensored standard normal\n## - left-censored at zero (Tobit) with latent mu = 1 and sigma = 1\n## - interval-censored in [0, 5] with latent mu = 1 and sigma = 2\nX &lt;- CensoredNormal(\n  mu    = c(   0,   1, 1),\n  sigma = c(   1,   1, 2),\n  left  = c(-Inf,   0, 0),\n  right = c( Inf, Inf, 5)\n)\nX\n\n[1] \"CensoredNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\"\n[2] \"CensoredNormal(mu = 1, sigma = 1, left =    0, right = Inf)\"\n[3] \"CensoredNormal(mu = 1, sigma = 2, left =    0, right =   5)\"\n\n## compute mean and variance of the censored distribution\nmean(X)\n\n[1] 0.000000 1.083315 1.378612\n\nvariance(X)\n\n[1] 1.0000000 0.7510878 2.0679838\n\n## higher moments (skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1        r_2        r_3       r_4       r_5\n[1,] -0.3421647 -0.6121245 -1.7461032 0.3600695 0.9275691\n[2,]  1.4528670  0.0000000  0.1263061 2.5174300 1.0124322\n[3,]  2.2338249  0.1466394  3.1254139 0.0000000 0.0000000\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"uncensored\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-censored at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-censored in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3989423 0.1586553 0.1994711\n\npdf(X, x, log = TRUE)\n\n[1] -0.9189385 -1.8410216 -1.6120857\n\nlog_pdf(X, x)\n\n[1] -0.9189385 -1.8410216 -1.6120857\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.1586553 0.5000000\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0 1 1\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n        q_0.05 q_0.5   q_0.95\n[1,] -1.644854     0 1.644854\n[2,]  0.000000     1 2.644854\n[3,]  0.000000     1 4.289707\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -1.644854  1.000000  4.289707\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -1.644854\n[2,]  1.000000\n[3,]  4.289707\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 0.01580424\n[2,]    1.083315 1.12030540\n[3,]    1.378612 1.38062119\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.2336950 0.5952063 0.3984091",
    "crumbs": [
      "distributions3 objects",
      "CensoredNormal"
    ]
  },
  {
    "objectID": "man/TruncatedLogistic.html",
    "href": "man/TruncatedLogistic.html",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-truncated logistic distributions using the workflow from the distributions3 package.\n\nTruncatedLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying untruncated logistic distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying untruncated logistic distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left truncation point. Can be any real number, defaults to -Inf (untruncated). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the untruncated logistic distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right truncation point. Can be any real number, defaults to Inf (untruncated). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the untruncated logistic distribution at this point.\n\n\n\nThe constructor function TruncatedLogistic sets up a distribution object, representing the truncated logistic probability distribution by the corresponding parameters: the latent mean location = \\(\\mu\\) and latent standard deviation scale = \\(\\sigma\\) (i.e., the parameters of the underlying untruncated logistic variable), the left truncation point (with -Inf corresponding to untruncated), and the right truncation point (with Inf corresponding to untruncated).\nThe truncated logistic distribution has probability density function (PDF):\n\n\n\\(f(x) = 1/\\sigma \\lambda((x - \\mu)/\\sigma) / (\\Lambda((right - \\mu)/\\sigma) - \\Lambda((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise, where \\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of truncated logistic distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the TruncatedLogistic distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the truncated logistic distributions in the crch package, see dtlogis, and the crps_tlogis function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (always TRUE).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA TruncatedLogistic distribution object.\n\ndtlogis, Logistic, CensoredLogistic, TruncatedNormal, TruncatedStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three truncated logistic distributions:\n## - untruncated standard logistic\n## - left-truncated at zero with latent location = 1 and scale = 1\n## - interval-truncated in [0, 5] with latent location = 2 and scale = 1\nX &lt;- TruncatedLogistic(\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 1),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"TruncatedLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"TruncatedLogistic(location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"TruncatedLogistic(location = 2, scale = 1, left =    0, right =   5)\"\n\n## compute mean of the truncated distribution\nmean(X)\n\n[1] 0.000000 1.796384 2.209353\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1       r_2        r_3         r_4         r_5\n[1,] -0.5489266 0.7114939 -0.9934677 -0.09368233 -3.16777672\n[2,]  1.1006458 2.4089727  2.4675811  1.05483091  0.02403454\n[3,]  2.7604891 0.7532299  0.6488695  1.49733364  1.04806366\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"untruncated\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-truncated at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-truncated in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.2500000 0.2689414 0.2359236\n\npdf(X, x, log = TRUE)\n\n[1] -1.386294 -1.313262 -1.444247\n\nlog_pdf(X, x)\n\n[1] -1.386294 -1.313262 -1.444247\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.500000 0.000000 0.179678\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.000000 1.551445 2.143801\n\n## cdf() and quantile() are inverses (except at truncation points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05    q_0.5   q_0.95\n[1,] -2.9444390 0.000000 2.944439\n[2,]  0.1787310 1.551445 4.271756\n[3,]  0.3482419 2.143801 4.324742\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.944439  1.551445  4.324742\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.944439\n[2,]  1.551445\n[3,]  4.324742\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 -0.0299458\n[2,]    1.796384  1.7546601\n[3,]    2.209353  2.2205845\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.3862944 1.0893568 0.6860449",
    "crumbs": [
      "distributions3 objects",
      "TruncatedLogistic"
    ]
  },
  {
    "objectID": "man/TruncatedLogistic.html#create-a-truncated-logistic-distribution",
    "href": "man/TruncatedLogistic.html#create-a-truncated-logistic-distribution",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-truncated logistic distributions using the workflow from the distributions3 package.\n\nTruncatedLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying untruncated logistic distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying untruncated logistic distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left truncation point. Can be any real number, defaults to -Inf (untruncated). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the untruncated logistic distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right truncation point. Can be any real number, defaults to Inf (untruncated). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the untruncated logistic distribution at this point.\n\n\n\nThe constructor function TruncatedLogistic sets up a distribution object, representing the truncated logistic probability distribution by the corresponding parameters: the latent mean location = \\(\\mu\\) and latent standard deviation scale = \\(\\sigma\\) (i.e., the parameters of the underlying untruncated logistic variable), the left truncation point (with -Inf corresponding to untruncated), and the right truncation point (with Inf corresponding to untruncated).\nThe truncated logistic distribution has probability density function (PDF):\n\n\n\\(f(x) = 1/\\sigma \\lambda((x - \\mu)/\\sigma) / (\\Lambda((right - \\mu)/\\sigma) - \\Lambda((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise, where \\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of truncated logistic distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the TruncatedLogistic distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the truncated logistic distributions in the crch package, see dtlogis, and the crps_tlogis function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (always TRUE).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA TruncatedLogistic distribution object.\n\ndtlogis, Logistic, CensoredLogistic, TruncatedNormal, TruncatedStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three truncated logistic distributions:\n## - untruncated standard logistic\n## - left-truncated at zero with latent location = 1 and scale = 1\n## - interval-truncated in [0, 5] with latent location = 2 and scale = 1\nX &lt;- TruncatedLogistic(\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 1),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"TruncatedLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"TruncatedLogistic(location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"TruncatedLogistic(location = 2, scale = 1, left =    0, right =   5)\"\n\n## compute mean of the truncated distribution\nmean(X)\n\n[1] 0.000000 1.796384 2.209353\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1       r_2        r_3         r_4         r_5\n[1,] -0.5489266 0.7114939 -0.9934677 -0.09368233 -3.16777672\n[2,]  1.1006458 2.4089727  2.4675811  1.05483091  0.02403454\n[3,]  2.7604891 0.7532299  0.6488695  1.49733364  1.04806366\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"untruncated\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-truncated at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-truncated in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.2500000 0.2689414 0.2359236\n\npdf(X, x, log = TRUE)\n\n[1] -1.386294 -1.313262 -1.444247\n\nlog_pdf(X, x)\n\n[1] -1.386294 -1.313262 -1.444247\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.500000 0.000000 0.179678\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.000000 1.551445 2.143801\n\n## cdf() and quantile() are inverses (except at truncation points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05    q_0.5   q_0.95\n[1,] -2.9444390 0.000000 2.944439\n[2,]  0.1787310 1.551445 4.271756\n[3,]  0.3482419 2.143801 4.324742\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.944439  1.551445  4.324742\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.944439\n[2,]  1.551445\n[3,]  4.324742\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 -0.0299458\n[2,]    1.796384  1.7546601\n[3,]    2.209353  2.2205845\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.3862944 1.0893568 0.6860449",
    "crumbs": [
      "distributions3 objects",
      "TruncatedLogistic"
    ]
  },
  {
    "objectID": "man/crch.stabsel.html",
    "href": "man/crch.stabsel.html",
    "title": "crch",
    "section": "",
    "text": "Auxilirary function which allows to do stability selection on heteroscedastic crch models based on crch.boost.\n\ncrch.stabsel(formula, data, ..., nu = 0.1, q, B = 100, thr = 0.9, \n  maxit = 2000, data_percentage = 0.5)\n\n\n\n\n\nformula\n\n\na formula expression of the form y ~ x | z where y is the response and x and z are regressor variables for the location and the scale of the fitted distribution respectively.\n\n\n\n\ndata\n\n\nan optional data frame containing the variables occurring in the formulas.\n\n\n\n\n…\n\n\nAdditional attributes to control the crch model. Note that control is not allowed; crch.stabsel uses crch.boost by default.\n\n\n\n\nnu\n\n\nBoosting step size (see crch.boost) default is 0.1 as for crch.boost while lower values might yield better results frequently and should be considered.\n\n\n\n\nq\n\n\nPositive numeric. Maximum number of parameters to be selected during each iteration (not including intercepts).\n\n\n\n\nB\n\n\nnumeric, total number of iterations.\n\n\n\n\nthr\n\n\nnumeric threshold ((0.5-1.0)). Used to generate the new formula and the computation of the per-family error rate.\n\n\n\n\nmaxit\n\n\nPositive numeric value. Maximum number for the boosting algorithm. If q is not reached before maxit the algorithm will stop.\n\n\n\n\ndata_percentage\n\n\nPercentage of data which should be sampled in each of the iterations. Default (and suggested) is 0.5.\n\n\n\ncrch.boost allows to perform gradient boosting on heteroscedastic additive models. crch.stabsel is a wrapper around the core crch.boost algorithm to perform stability selection (see references).\nHalf of the data set (data) is sampled B times to perform boosting (based on crch.boost). Rather than perform the boosting iterations until a certain stopping criterion is reached (e.g., maximum number of iterations maxit) the algorithm stops as soon as q parameters have been selected. The number of parameters is computed across both parameters location and scale. Intercepts are not counted.\n\nReturns an object of class “stabsel.crch” containing the stability selection summary and the new formula based on the stability selection.\n\n\n\ntable\n\n\nA table object containing the parameters which have been selected and the corresponding frequency of selection.\n\n\n\n\nformula.org\n\n\nOriginal formula used to perform the stability selection.\n\n\n\n\nformula.new\n\n\nNew formula based including the coefficients selected during stability selection.\n\n\n\n\nfamily\n\n\nA list object which contains the distribution-specification from the crch.stabsel call including: dist, cens, and truncated.\n\n\n\n\nparameter\n\n\nList with the parameters used to perform the stability selection including q, B, thr, p, and PFER (per-family error rate).\n\n\n\nMeinhausen N, Buehlmann P (2010). Stability selection. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 72(4), 417–473. doi:10.1111/j.1467-9868.2010.00740.x.\n\ncrch, crch.boost\n\n\nlibrary(\"crch\")\n\n# generate data\nsuppressWarnings(RNGversion(\"3.5.0\"))\nset.seed(5)\nx &lt;- matrix(rnorm(1000*20),1000,20)\ny &lt;- rnorm(1000, 1 + x[,1] - 1.5 * x[,2], exp(-1 + 0.3*x[,3]))\ny &lt;- pmax(0, y)\ndata &lt;- data.frame(cbind(y, x))\n\n# fit model with maximum likelihood\nCRCH1 &lt;- crch(y ~ .|., data = data, dist = \"gaussian\", left = 0)\n\n# Perform stability selection\nstabsel &lt;- crch.stabsel(y ~ .|.,  data = data, dist = \"gaussian\", left = 0,\n           q = 8, B = 5)\n\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 1/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 3/42\nIteration 53/2000 parameters added 3/42\nIteration 54/2000 parameters added 3/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 4/42\nIteration 60/2000 parameters added 4/42\nIteration 61/2000 parameters added 4/42\nIteration 62/2000 parameters added 4/42\nIteration 63/2000 parameters added 4/42\nIteration 64/2000 parameters added 4/42\nIteration 65/2000 parameters added 4/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 4/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 5/42\nIteration 75/2000 parameters added 5/42\nIteration 76/2000 parameters added 5/42\nIteration 77/2000 parameters added 6/42\nIteration 78/2000 parameters added 6/42\nIteration 79/2000 parameters added 6/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 7/42\nIteration 82/2000 parameters added 7/42\nIteration 83/2000 parameters added 7/42\nIteration 84/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 2/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 2/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 3/42\nIteration 64/2000 parameters added 3/42\nIteration 65/2000 parameters added 3/42\nIteration 66/2000 parameters added 3/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 5/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 5/42\nIteration 75/2000 parameters added 5/42\nIteration 76/2000 parameters added 5/42\nIteration 77/2000 parameters added 5/42\nIteration 78/2000 parameters added 5/42\nIteration 79/2000 parameters added 6/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 6/42\nIteration 82/2000 parameters added 7/42\nIteration 83/2000 parameters added 7/42\nIteration 84/2000 parameters added 7/42\nIteration 85/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 1/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 3/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 4/42\nIteration 64/2000 parameters added 4/42\nIteration 65/2000 parameters added 4/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 4/42\nIteration 71/2000 parameters added 4/42\nIteration 72/2000 parameters added 4/42\nIteration 73/2000 parameters added 4/42\nIteration 74/2000 parameters added 4/42\nIteration 75/2000 parameters added 4/42\nIteration 76/2000 parameters added 4/42\nIteration 77/2000 parameters added 4/42\nIteration 78/2000 parameters added 4/42\nIteration 79/2000 parameters added 5/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 6/42\nIteration 82/2000 parameters added 6/42\nIteration 83/2000 parameters added 6/42\nIteration 84/2000 parameters added 6/42\nIteration 85/2000 parameters added 6/42\nIteration 86/2000 parameters added 7/42\nIteration 87/2000 parameters added 7/42\nIteration 88/2000 parameters added 7/42\nIteration 89/2000 parameters added 7/42\nIteration 90/2000 parameters added 7/42\nIteration 91/2000 parameters added 7/42\nIteration 92/2000 parameters added 7/42\nIteration 93/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 1/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 2/42\nIteration 55/2000 parameters added 2/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 3/42\nIteration 64/2000 parameters added 4/42\nIteration 65/2000 parameters added 4/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 4/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 5/42\nIteration 75/2000 parameters added 5/42\nIteration 76/2000 parameters added 6/42\nIteration 77/2000 parameters added 7/42\nIteration 78/2000 parameters added 7/42\nIteration 79/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 2/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 2/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 3/42\nIteration 64/2000 parameters added 3/42\nIteration 65/2000 parameters added 3/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 5/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 6/42\nIteration 75/2000 parameters added 6/42\nIteration 76/2000 parameters added 6/42\nIteration 77/2000 parameters added 6/42\nIteration 78/2000 parameters added 6/42\nIteration 79/2000 parameters added 6/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 6/42\nIteration 82/2000 parameters added 6/42\nIteration 83/2000 parameters added 6/42\nIteration 84/2000 parameters added 6/42\nIteration 85/2000 parameters added 6/42\nIteration 86/2000 parameters added 6/42\nIteration 87/2000 parameters added 6/42\nIteration 88/2000 parameters added 6/42\nIteration 89/2000 parameters added 7/42\nIteration 90/2000 parameters added 7/42\nIteration 91/2000 parameters added 7/42\nIteration 92/2000 parameters added 8/42\n\n# Show stability selection summary\nprint(stabsel); plot(stabsel)\n\n\n  crch Stability Selection Info\n\n  Family information\n   Distribution:       gaussian\n   Truncated:          FALSE\n   Left-censoring:     0\n   Right-censoring:    Inf\n\n  Selection parameters\n   Number of parameters (q):         8\n   Number of iterations (B):         5\n   Selection threshold (thr):     0.90\n   Total number of parameter (p):   40\n\n  Per family error rate\n   Given p/q/thr the expected value of falsely\n   chosen parameters is:          2.00\n\n  Selected formula:\n   y ~ V2 + V3 | V4\n&lt;environment: 0x55df0a09e058&gt;\n\n\n\n\n\n\n\nCRCH2 &lt;- crch(stabsel$formula.new, data = data, dist = \"gaussian\", left = 0 )\nBOOST &lt;- crch(stabsel$formula.new, data = data, dist = \"gaussian\", left = 0,\n              control = crch.boost() )\n\n### AIC comparison\nsapply( list(CRCH1,CRCH2,BOOST), logLik )\n\n[1] -367.6337 -384.2485 -385.0090",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch.stabsel"
    ]
  },
  {
    "objectID": "man/crch.stabsel.html#auxiliary-functions-for-stability-selection-using-boosting",
    "href": "man/crch.stabsel.html#auxiliary-functions-for-stability-selection-using-boosting",
    "title": "crch",
    "section": "",
    "text": "Auxilirary function which allows to do stability selection on heteroscedastic crch models based on crch.boost.\n\ncrch.stabsel(formula, data, ..., nu = 0.1, q, B = 100, thr = 0.9, \n  maxit = 2000, data_percentage = 0.5)\n\n\n\n\n\nformula\n\n\na formula expression of the form y ~ x | z where y is the response and x and z are regressor variables for the location and the scale of the fitted distribution respectively.\n\n\n\n\ndata\n\n\nan optional data frame containing the variables occurring in the formulas.\n\n\n\n\n…\n\n\nAdditional attributes to control the crch model. Note that control is not allowed; crch.stabsel uses crch.boost by default.\n\n\n\n\nnu\n\n\nBoosting step size (see crch.boost) default is 0.1 as for crch.boost while lower values might yield better results frequently and should be considered.\n\n\n\n\nq\n\n\nPositive numeric. Maximum number of parameters to be selected during each iteration (not including intercepts).\n\n\n\n\nB\n\n\nnumeric, total number of iterations.\n\n\n\n\nthr\n\n\nnumeric threshold ((0.5-1.0)). Used to generate the new formula and the computation of the per-family error rate.\n\n\n\n\nmaxit\n\n\nPositive numeric value. Maximum number for the boosting algorithm. If q is not reached before maxit the algorithm will stop.\n\n\n\n\ndata_percentage\n\n\nPercentage of data which should be sampled in each of the iterations. Default (and suggested) is 0.5.\n\n\n\ncrch.boost allows to perform gradient boosting on heteroscedastic additive models. crch.stabsel is a wrapper around the core crch.boost algorithm to perform stability selection (see references).\nHalf of the data set (data) is sampled B times to perform boosting (based on crch.boost). Rather than perform the boosting iterations until a certain stopping criterion is reached (e.g., maximum number of iterations maxit) the algorithm stops as soon as q parameters have been selected. The number of parameters is computed across both parameters location and scale. Intercepts are not counted.\n\nReturns an object of class “stabsel.crch” containing the stability selection summary and the new formula based on the stability selection.\n\n\n\ntable\n\n\nA table object containing the parameters which have been selected and the corresponding frequency of selection.\n\n\n\n\nformula.org\n\n\nOriginal formula used to perform the stability selection.\n\n\n\n\nformula.new\n\n\nNew formula based including the coefficients selected during stability selection.\n\n\n\n\nfamily\n\n\nA list object which contains the distribution-specification from the crch.stabsel call including: dist, cens, and truncated.\n\n\n\n\nparameter\n\n\nList with the parameters used to perform the stability selection including q, B, thr, p, and PFER (per-family error rate).\n\n\n\nMeinhausen N, Buehlmann P (2010). Stability selection. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 72(4), 417–473. doi:10.1111/j.1467-9868.2010.00740.x.\n\ncrch, crch.boost\n\n\nlibrary(\"crch\")\n\n# generate data\nsuppressWarnings(RNGversion(\"3.5.0\"))\nset.seed(5)\nx &lt;- matrix(rnorm(1000*20),1000,20)\ny &lt;- rnorm(1000, 1 + x[,1] - 1.5 * x[,2], exp(-1 + 0.3*x[,3]))\ny &lt;- pmax(0, y)\ndata &lt;- data.frame(cbind(y, x))\n\n# fit model with maximum likelihood\nCRCH1 &lt;- crch(y ~ .|., data = data, dist = \"gaussian\", left = 0)\n\n# Perform stability selection\nstabsel &lt;- crch.stabsel(y ~ .|.,  data = data, dist = \"gaussian\", left = 0,\n           q = 8, B = 5)\n\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 1/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 3/42\nIteration 53/2000 parameters added 3/42\nIteration 54/2000 parameters added 3/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 4/42\nIteration 60/2000 parameters added 4/42\nIteration 61/2000 parameters added 4/42\nIteration 62/2000 parameters added 4/42\nIteration 63/2000 parameters added 4/42\nIteration 64/2000 parameters added 4/42\nIteration 65/2000 parameters added 4/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 4/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 5/42\nIteration 75/2000 parameters added 5/42\nIteration 76/2000 parameters added 5/42\nIteration 77/2000 parameters added 6/42\nIteration 78/2000 parameters added 6/42\nIteration 79/2000 parameters added 6/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 7/42\nIteration 82/2000 parameters added 7/42\nIteration 83/2000 parameters added 7/42\nIteration 84/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 2/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 2/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 3/42\nIteration 64/2000 parameters added 3/42\nIteration 65/2000 parameters added 3/42\nIteration 66/2000 parameters added 3/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 5/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 5/42\nIteration 75/2000 parameters added 5/42\nIteration 76/2000 parameters added 5/42\nIteration 77/2000 parameters added 5/42\nIteration 78/2000 parameters added 5/42\nIteration 79/2000 parameters added 6/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 6/42\nIteration 82/2000 parameters added 7/42\nIteration 83/2000 parameters added 7/42\nIteration 84/2000 parameters added 7/42\nIteration 85/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 1/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 3/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 4/42\nIteration 64/2000 parameters added 4/42\nIteration 65/2000 parameters added 4/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 4/42\nIteration 71/2000 parameters added 4/42\nIteration 72/2000 parameters added 4/42\nIteration 73/2000 parameters added 4/42\nIteration 74/2000 parameters added 4/42\nIteration 75/2000 parameters added 4/42\nIteration 76/2000 parameters added 4/42\nIteration 77/2000 parameters added 4/42\nIteration 78/2000 parameters added 4/42\nIteration 79/2000 parameters added 5/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 6/42\nIteration 82/2000 parameters added 6/42\nIteration 83/2000 parameters added 6/42\nIteration 84/2000 parameters added 6/42\nIteration 85/2000 parameters added 6/42\nIteration 86/2000 parameters added 7/42\nIteration 87/2000 parameters added 7/42\nIteration 88/2000 parameters added 7/42\nIteration 89/2000 parameters added 7/42\nIteration 90/2000 parameters added 7/42\nIteration 91/2000 parameters added 7/42\nIteration 92/2000 parameters added 7/42\nIteration 93/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 1/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 2/42\nIteration 55/2000 parameters added 2/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 3/42\nIteration 64/2000 parameters added 4/42\nIteration 65/2000 parameters added 4/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 4/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 5/42\nIteration 75/2000 parameters added 5/42\nIteration 76/2000 parameters added 6/42\nIteration 77/2000 parameters added 7/42\nIteration 78/2000 parameters added 7/42\nIteration 79/2000 parameters added 8/42\nIteration 1/2000 parameters added 1/42\nIteration 2/2000 parameters added 1/42\nIteration 3/2000 parameters added 1/42\nIteration 4/2000 parameters added 1/42\nIteration 5/2000 parameters added 2/42\nIteration 6/2000 parameters added 2/42\nIteration 7/2000 parameters added 2/42\nIteration 8/2000 parameters added 2/42\nIteration 9/2000 parameters added 2/42\nIteration 10/2000 parameters added 2/42\nIteration 11/2000 parameters added 2/42\nIteration 12/2000 parameters added 2/42\nIteration 13/2000 parameters added 2/42\nIteration 14/2000 parameters added 2/42\nIteration 15/2000 parameters added 2/42\nIteration 16/2000 parameters added 2/42\nIteration 17/2000 parameters added 2/42\nIteration 18/2000 parameters added 2/42\nIteration 19/2000 parameters added 2/42\nIteration 20/2000 parameters added 2/42\nIteration 21/2000 parameters added 2/42\nIteration 22/2000 parameters added 2/42\nIteration 23/2000 parameters added 2/42\nIteration 24/2000 parameters added 2/42\nIteration 25/2000 parameters added 2/42\nIteration 26/2000 parameters added 2/42\nIteration 27/2000 parameters added 2/42\nIteration 28/2000 parameters added 2/42\nIteration 29/2000 parameters added 2/42\nIteration 30/2000 parameters added 2/42\nIteration 31/2000 parameters added 2/42\nIteration 32/2000 parameters added 2/42\nIteration 33/2000 parameters added 2/42\nIteration 34/2000 parameters added 2/42\nIteration 35/2000 parameters added 2/42\nIteration 36/2000 parameters added 2/42\nIteration 37/2000 parameters added 2/42\nIteration 38/2000 parameters added 2/42\nIteration 39/2000 parameters added 2/42\nIteration 40/2000 parameters added 2/42\nIteration 41/2000 parameters added 2/42\nIteration 42/2000 parameters added 2/42\nIteration 43/2000 parameters added 2/42\nIteration 44/2000 parameters added 2/42\nIteration 45/2000 parameters added 2/42\nIteration 46/2000 parameters added 2/42\nIteration 47/2000 parameters added 2/42\nIteration 48/2000 parameters added 2/42\nIteration 49/2000 parameters added 2/42\nIteration 50/2000 parameters added 2/42\nIteration 51/2000 parameters added 2/42\nIteration 52/2000 parameters added 2/42\nIteration 53/2000 parameters added 2/42\nIteration 54/2000 parameters added 2/42\nIteration 55/2000 parameters added 3/42\nIteration 56/2000 parameters added 3/42\nIteration 57/2000 parameters added 3/42\nIteration 58/2000 parameters added 3/42\nIteration 59/2000 parameters added 3/42\nIteration 60/2000 parameters added 3/42\nIteration 61/2000 parameters added 3/42\nIteration 62/2000 parameters added 3/42\nIteration 63/2000 parameters added 3/42\nIteration 64/2000 parameters added 3/42\nIteration 65/2000 parameters added 3/42\nIteration 66/2000 parameters added 4/42\nIteration 67/2000 parameters added 4/42\nIteration 68/2000 parameters added 4/42\nIteration 69/2000 parameters added 4/42\nIteration 70/2000 parameters added 5/42\nIteration 71/2000 parameters added 5/42\nIteration 72/2000 parameters added 5/42\nIteration 73/2000 parameters added 5/42\nIteration 74/2000 parameters added 6/42\nIteration 75/2000 parameters added 6/42\nIteration 76/2000 parameters added 6/42\nIteration 77/2000 parameters added 6/42\nIteration 78/2000 parameters added 6/42\nIteration 79/2000 parameters added 6/42\nIteration 80/2000 parameters added 6/42\nIteration 81/2000 parameters added 6/42\nIteration 82/2000 parameters added 6/42\nIteration 83/2000 parameters added 6/42\nIteration 84/2000 parameters added 6/42\nIteration 85/2000 parameters added 6/42\nIteration 86/2000 parameters added 6/42\nIteration 87/2000 parameters added 6/42\nIteration 88/2000 parameters added 6/42\nIteration 89/2000 parameters added 7/42\nIteration 90/2000 parameters added 7/42\nIteration 91/2000 parameters added 7/42\nIteration 92/2000 parameters added 8/42\n\n# Show stability selection summary\nprint(stabsel); plot(stabsel)\n\n\n  crch Stability Selection Info\n\n  Family information\n   Distribution:       gaussian\n   Truncated:          FALSE\n   Left-censoring:     0\n   Right-censoring:    Inf\n\n  Selection parameters\n   Number of parameters (q):         8\n   Number of iterations (B):         5\n   Selection threshold (thr):     0.90\n   Total number of parameter (p):   40\n\n  Per family error rate\n   Given p/q/thr the expected value of falsely\n   chosen parameters is:          2.00\n\n  Selected formula:\n   y ~ V2 + V3 | V4\n&lt;environment: 0x55df0a09e058&gt;\n\n\n\n\n\n\n\nCRCH2 &lt;- crch(stabsel$formula.new, data = data, dist = \"gaussian\", left = 0 )\nBOOST &lt;- crch(stabsel$formula.new, data = data, dist = \"gaussian\", left = 0,\n              control = crch.boost() )\n\n### AIC comparison\nsapply( list(CRCH1,CRCH2,BOOST), logLik )\n\n[1] -367.6337 -384.2485 -385.0090",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch.stabsel"
    ]
  },
  {
    "objectID": "man/crch.boost.html",
    "href": "man/crch.boost.html",
    "title": "crch",
    "section": "",
    "text": "Auxiliary functions to fit crch models via boosting\n\ncrch.boost(maxit = 100, nu = 0.1, start = NULL, dot = \"separate\", \n  mstop = c(\"max\", \"aic\", \"bic\", \"cv\"),  nfolds = 10, foldid = NULL, \n  maxvar = NULL)\n\ncrch.boost.fit(x, z, y, left, right, truncated = FALSE, dist = \"gaussian\",\n  df = NULL, link.scale = \"log\", type = \"ml\", weights = NULL, offset = NULL, \n  control = crch.boost())\n\n\n\n\n\nmaxit\n\n\nthe maximum number of boosting iterations.\n\n\n\n\nnu\n\n\nboosting step size. Default is 0.1.\n\n\n\n\nstart\n\n\na previously boosted but not converged “crch.boost” object to continue.\n\n\n\n\ndot\n\n\ncharacter specifying how to process formula parts with a dot (.) on the right-hand side. This can either be “separate” so that each formula part is expanded separately or “sequential” so that the parts are expanded sequentially conditional on all prior parts. Default is “separate”\n\n\n\n\nmstop\n\n\nmethod to find optimum stopping iteration. Default is “max” which is maxit. Alternatives are “aic” and “bic” for AIC and BIC optimization and “cv” for cross validation. mstop can also be a positive integer to set the number of boosting iterations. Then maxit is set to mstop and mstop=“max”.\n\n\n\n\nnfolds\n\n\nif mstopopt = “cv”, number of folds in cross validation.\n\n\n\n\nfoldid\n\n\nif mstopopt = “cv”, an optional vector of values between 1 and nfold identifying the fold each observation is in. If supplied, nfolds can be missing.\n\n\n\n\nmaxvar\n\n\nPositive numeric. Maximum number of parameters to be selected during each iteration (not including intercepts). Used for stability selection.\n\n\n\n\nx, z, y, left, right, truncated, dist, df, link.scale, type, weights, offset, control\n\n\nsee crch.fit for details.\n\n\n\ncrch.boost extends crch to fit censored (tobit) or truncated regression models with conditional heteroscedasticy by boosting. If crch.boost() is supplied as control in crch then crch.boost.fit is used as lower level fitting function. Note that crch.control() with method=boosting is equivalent to crch.boost(). Thus, boosting can more conveniently be called with crch(…, method = “boosting”).\n\nFor crch.boost: A list with components named as the arguments. For crch.boost.fit: An object of class “crch.boost”, i.e., a list with the following elements.\n\n\n\ncoefficients\n\n\nlist of coefficients for location and scale. Scale coefficients are in log-scale. Coefficients are of optimum stopping stopping iteration specified by mstop.\n\n\n\n\ndf\n\n\nif dist = “student”: degrees of freedom of student-t distribution. else NULL.\n\n\n\n\nresiduals\n\n\nthe residuals, that is response minus fitted values.\n\n\n\n\nfitted.values\n\n\nlist of fitted location and scale parameters at optimum stopping iteration specified by mstop.\n\n\n\n\ndist\n\n\nassumed distribution for the dependent variable y.\n\n\n\n\ncens\n\n\nlist of censoring points.\n\n\n\n\ncontrol\n\n\nlist of control parameters.\n\n\n\n\nweights\n\n\ncase weights used for fitting.\n\n\n\n\noffset\n\n\nlist of offsets for location and scale.\n\n\n\n\nn\n\n\nnumber of observations.\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights.\n\n\n\n\nloglik\n\n\nlog-likelihood.\n\n\n\n\nlink\n\n\na list with element “scale” containing the link objects for the scale model.\n\n\n\n\ntruncated\n\n\nlogical indicating wheter a truncated model has been fitted.\n\n\n\n\niterations\n\n\nnumber of boosting iterations.\n\n\n\n\nstepsize\n\n\nboosting stepsize nu.\n\n\n\n\nmstop\n\n\ncriterion used to find optimum stopping iteration.\n\n\n\n\nmstopopt\n\n\noptimum stopping iterations for different criteria.\n\n\n\n\nstandardize\n\n\nlist of center and scale values used to standardize response and regressors.\n\n\n\nMessner JW, Mayr GJ, Zeileis A (2017). Non-Homogeneous Boosting for Predictor Selection in Ensemble Post-Processing. Monthly Weather Review, 145(1), 137–147. doi:10.1175/MWR-D-16-0088.1\n\ncrch, crch.control\n\n\nlibrary(\"crch\")\n\n# generate data\nsuppressWarnings(RNGversion(\"3.5.0\"))\nset.seed(5)\nx &lt;- matrix(rnorm(1000*20),1000,20)\ny &lt;- rnorm(1000, 1 + x[,1] - 1.5 * x[,2], exp(-1 + 0.3*x[,3]))\ny &lt;- pmax(0, y)\ndata &lt;- data.frame(cbind(y, x))\n\n# fit model with maximum likelihood\nCRCH &lt;- crch(y ~ .|., data = data, dist = \"gaussian\", left = 0)\n\n# fit model with boosting\nboost &lt;- crch(y ~ .|.,  data = data, dist = \"gaussian\", left = 0,\n  control = crch.boost(mstop = \"aic\"))\n\n# more conveniently, the same model can also be fit through\n# boost &lt;- crch(y ~ .|.,  data = data, dist = \"gaussian\", left = 0,\n#   method = \"boosting\", mstop = \"aic\")\n\n# AIC comparison\nAIC(CRCH, boost)\n\n      df      AIC\nCRCH  42 819.2673\nboost  7 782.1219\n\n# summary\nsummary(boost)\n\n\nCall:\ncrch(formula = y ~ . | ., data = data, dist = \"gaussian\", left = 0, control = crch.boost(mstop = \"aic\"))\n\nStandardized residuals:\n    Min      1Q  Median      3Q     Max \n-2.9273 -0.2963  0.5462  1.4357 22.6650 \n\nmaximum stopping iteration: 100 \n\noptimum stopping iterations:\nmax aic bic \n100  90  90 \n\nNon-zero coefficients after 90 boosting iterations:\nLocation model:\n(Intercept)           V2           V3          V13          V21  \n    0.99111      1.01795     -1.49731      0.04483      0.03668  \n\nScale model with log link:\n(Intercept)           V4  \n    -0.9183       0.2226  \n\nDistribution: gaussian\nLog-likelihood: -384.1 on 7 Df\n\n# plot\nplot(boost)",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch.boost"
    ]
  },
  {
    "objectID": "man/crch.boost.html#auxiliary-functions-for-boosting-crch-models",
    "href": "man/crch.boost.html#auxiliary-functions-for-boosting-crch-models",
    "title": "crch",
    "section": "",
    "text": "Auxiliary functions to fit crch models via boosting\n\ncrch.boost(maxit = 100, nu = 0.1, start = NULL, dot = \"separate\", \n  mstop = c(\"max\", \"aic\", \"bic\", \"cv\"),  nfolds = 10, foldid = NULL, \n  maxvar = NULL)\n\ncrch.boost.fit(x, z, y, left, right, truncated = FALSE, dist = \"gaussian\",\n  df = NULL, link.scale = \"log\", type = \"ml\", weights = NULL, offset = NULL, \n  control = crch.boost())\n\n\n\n\n\nmaxit\n\n\nthe maximum number of boosting iterations.\n\n\n\n\nnu\n\n\nboosting step size. Default is 0.1.\n\n\n\n\nstart\n\n\na previously boosted but not converged “crch.boost” object to continue.\n\n\n\n\ndot\n\n\ncharacter specifying how to process formula parts with a dot (.) on the right-hand side. This can either be “separate” so that each formula part is expanded separately or “sequential” so that the parts are expanded sequentially conditional on all prior parts. Default is “separate”\n\n\n\n\nmstop\n\n\nmethod to find optimum stopping iteration. Default is “max” which is maxit. Alternatives are “aic” and “bic” for AIC and BIC optimization and “cv” for cross validation. mstop can also be a positive integer to set the number of boosting iterations. Then maxit is set to mstop and mstop=“max”.\n\n\n\n\nnfolds\n\n\nif mstopopt = “cv”, number of folds in cross validation.\n\n\n\n\nfoldid\n\n\nif mstopopt = “cv”, an optional vector of values between 1 and nfold identifying the fold each observation is in. If supplied, nfolds can be missing.\n\n\n\n\nmaxvar\n\n\nPositive numeric. Maximum number of parameters to be selected during each iteration (not including intercepts). Used for stability selection.\n\n\n\n\nx, z, y, left, right, truncated, dist, df, link.scale, type, weights, offset, control\n\n\nsee crch.fit for details.\n\n\n\ncrch.boost extends crch to fit censored (tobit) or truncated regression models with conditional heteroscedasticy by boosting. If crch.boost() is supplied as control in crch then crch.boost.fit is used as lower level fitting function. Note that crch.control() with method=boosting is equivalent to crch.boost(). Thus, boosting can more conveniently be called with crch(…, method = “boosting”).\n\nFor crch.boost: A list with components named as the arguments. For crch.boost.fit: An object of class “crch.boost”, i.e., a list with the following elements.\n\n\n\ncoefficients\n\n\nlist of coefficients for location and scale. Scale coefficients are in log-scale. Coefficients are of optimum stopping stopping iteration specified by mstop.\n\n\n\n\ndf\n\n\nif dist = “student”: degrees of freedom of student-t distribution. else NULL.\n\n\n\n\nresiduals\n\n\nthe residuals, that is response minus fitted values.\n\n\n\n\nfitted.values\n\n\nlist of fitted location and scale parameters at optimum stopping iteration specified by mstop.\n\n\n\n\ndist\n\n\nassumed distribution for the dependent variable y.\n\n\n\n\ncens\n\n\nlist of censoring points.\n\n\n\n\ncontrol\n\n\nlist of control parameters.\n\n\n\n\nweights\n\n\ncase weights used for fitting.\n\n\n\n\noffset\n\n\nlist of offsets for location and scale.\n\n\n\n\nn\n\n\nnumber of observations.\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights.\n\n\n\n\nloglik\n\n\nlog-likelihood.\n\n\n\n\nlink\n\n\na list with element “scale” containing the link objects for the scale model.\n\n\n\n\ntruncated\n\n\nlogical indicating wheter a truncated model has been fitted.\n\n\n\n\niterations\n\n\nnumber of boosting iterations.\n\n\n\n\nstepsize\n\n\nboosting stepsize nu.\n\n\n\n\nmstop\n\n\ncriterion used to find optimum stopping iteration.\n\n\n\n\nmstopopt\n\n\noptimum stopping iterations for different criteria.\n\n\n\n\nstandardize\n\n\nlist of center and scale values used to standardize response and regressors.\n\n\n\nMessner JW, Mayr GJ, Zeileis A (2017). Non-Homogeneous Boosting for Predictor Selection in Ensemble Post-Processing. Monthly Weather Review, 145(1), 137–147. doi:10.1175/MWR-D-16-0088.1\n\ncrch, crch.control\n\n\nlibrary(\"crch\")\n\n# generate data\nsuppressWarnings(RNGversion(\"3.5.0\"))\nset.seed(5)\nx &lt;- matrix(rnorm(1000*20),1000,20)\ny &lt;- rnorm(1000, 1 + x[,1] - 1.5 * x[,2], exp(-1 + 0.3*x[,3]))\ny &lt;- pmax(0, y)\ndata &lt;- data.frame(cbind(y, x))\n\n# fit model with maximum likelihood\nCRCH &lt;- crch(y ~ .|., data = data, dist = \"gaussian\", left = 0)\n\n# fit model with boosting\nboost &lt;- crch(y ~ .|.,  data = data, dist = \"gaussian\", left = 0,\n  control = crch.boost(mstop = \"aic\"))\n\n# more conveniently, the same model can also be fit through\n# boost &lt;- crch(y ~ .|.,  data = data, dist = \"gaussian\", left = 0,\n#   method = \"boosting\", mstop = \"aic\")\n\n# AIC comparison\nAIC(CRCH, boost)\n\n      df      AIC\nCRCH  42 819.2673\nboost  7 782.1219\n\n# summary\nsummary(boost)\n\n\nCall:\ncrch(formula = y ~ . | ., data = data, dist = \"gaussian\", left = 0, control = crch.boost(mstop = \"aic\"))\n\nStandardized residuals:\n    Min      1Q  Median      3Q     Max \n-2.9273 -0.2963  0.5462  1.4357 22.6650 \n\nmaximum stopping iteration: 100 \n\noptimum stopping iterations:\nmax aic bic \n100  90  90 \n\nNon-zero coefficients after 90 boosting iterations:\nLocation model:\n(Intercept)           V2           V3          V13          V21  \n    0.99111      1.01795     -1.49731      0.04483      0.03668  \n\nScale model with log link:\n(Intercept)           V4  \n    -0.9183       0.2226  \n\nDistribution: gaussian\nLog-likelihood: -384.1 on 7 Df\n\n# plot\nplot(boost)",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch.boost"
    ]
  },
  {
    "objectID": "man/hxlr.control.html",
    "href": "man/hxlr.control.html",
    "title": "crch",
    "section": "",
    "text": "Auxiliary function for hxlr fitting. Specifies a list of values passed to optim.\n\n\n\nhxlr.control(method = \"BFGS\", maxit = 5000, hessian = TRUE, \n  trace = FALSE, start = NULL, ...)\n\n\n\n\n\n\nmethod\n\n\noptimization method used in optim\n\n\n\n\nmaxit\n\n\nthe maximum number of iterations.\n\n\n\n\nhessian\n\n\nlogical. Should a numerically differentiated Hessian matrix be returned?\n\n\n\n\ntrace\n\n\nnon-negative integer. If positive, tracing information on the progress of the optimization is produced.\n\n\n\n\nstart\n\n\ninitial values for the parameters to be optimized over.\n\n\n\n\n…\n\n\nAdditional parameters passed to optim.\n\n\n\n\n\n\nA list with components named as the arguments.\n\n\n\nhxlr, optim",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "hxlr.control"
    ]
  },
  {
    "objectID": "man/hxlr.control.html#control-options-for-hxlr-models",
    "href": "man/hxlr.control.html#control-options-for-hxlr-models",
    "title": "crch",
    "section": "",
    "text": "Auxiliary function for hxlr fitting. Specifies a list of values passed to optim.\n\n\n\nhxlr.control(method = \"BFGS\", maxit = 5000, hessian = TRUE, \n  trace = FALSE, start = NULL, ...)\n\n\n\n\n\n\nmethod\n\n\noptimization method used in optim\n\n\n\n\nmaxit\n\n\nthe maximum number of iterations.\n\n\n\n\nhessian\n\n\nlogical. Should a numerically differentiated Hessian matrix be returned?\n\n\n\n\ntrace\n\n\nnon-negative integer. If positive, tracing information on the progress of the optimization is produced.\n\n\n\n\nstart\n\n\ninitial values for the parameters to be optimized over.\n\n\n\n\n…\n\n\nAdditional parameters passed to optim.\n\n\n\n\n\n\nA list with components named as the arguments.\n\n\n\nhxlr, optim",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "hxlr.control"
    ]
  },
  {
    "objectID": "man/cnorm.html",
    "href": "man/cnorm.html",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right censored normal distribution.\n\n\n\ndcnorm(x, mean = 0, sd = 1, left = -Inf, right = Inf, log = FALSE)\n\npcnorm(q, mean = 0, sd = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqcnorm(p, mean = 0, sd = 1, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nrcnorm(n, mean = 0, sd = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmean\n\n\nvector of means.\n\n\n\n\nsd\n\n\nvector of standard deviations.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf mean or sd are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe censored normal distribution has density \\(f(x)\\):\n\n\n\n\\(\\Phi((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Phi((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\phi((x - \\mu)/\\sigma)/\\sigma\\)\n\n\nif \\(left &lt; x &lt; right\\)\n\n\n\nwhere \\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively, \\(\\mu\\) is the mean of the distribution, and \\(\\sigma\\) the standard deviation.\n\n\n\ndcnorm gives the density, pcnorm gives the distribution function, qcnorm gives the quantile function, and rcnorm generates random deviates.\n\n\n\ndnorm",
    "crumbs": [
      "Distributions",
      "cnorm"
    ]
  },
  {
    "objectID": "man/cnorm.html#the-censored-normal-distribution",
    "href": "man/cnorm.html#the-censored-normal-distribution",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right censored normal distribution.\n\n\n\ndcnorm(x, mean = 0, sd = 1, left = -Inf, right = Inf, log = FALSE)\n\npcnorm(q, mean = 0, sd = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqcnorm(p, mean = 0, sd = 1, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nrcnorm(n, mean = 0, sd = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmean\n\n\nvector of means.\n\n\n\n\nsd\n\n\nvector of standard deviations.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf mean or sd are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe censored normal distribution has density \\(f(x)\\):\n\n\n\n\\(\\Phi((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Phi((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\phi((x - \\mu)/\\sigma)/\\sigma\\)\n\n\nif \\(left &lt; x &lt; right\\)\n\n\n\nwhere \\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively, \\(\\mu\\) is the mean of the distribution, and \\(\\sigma\\) the standard deviation.\n\n\n\ndcnorm gives the density, pcnorm gives the distribution function, qcnorm gives the quantile function, and rcnorm generates random deviates.\n\n\n\ndnorm",
    "crumbs": [
      "Distributions",
      "cnorm"
    ]
  },
  {
    "objectID": "man/crch.html",
    "href": "man/crch.html",
    "title": "crch",
    "section": "",
    "text": "Fitting censored (tobit) or truncated regression models with conditional heteroscedasticy.\n\ncrch(formula, data, subset, na.action, weights, offset, \n  link.scale = c(\"log\", \"identity\", \"quadratic\"),\n  dist = c(\"gaussian\", \"logistic\", \"student\"), df = NULL, \n  left = -Inf, right = Inf, truncated = FALSE, \n  type = c(\"ml\", \"crps\"), control = crch.control(...), \n  model = TRUE, x = FALSE, y = FALSE, ...)\n\ntrch(formula, data, subset, na.action, weights, offset, \n  link.scale = c(\"log\", \"identity\", \"quadratic\"),\n  dist = c(\"gaussian\", \"logistic\", \"student\"), df = NULL, \n  left = -Inf, right = Inf, truncated = TRUE, \n  type = c(\"ml\", \"crps\"), control = crch.control(...), \n  model = TRUE, x = FALSE, y = FALSE, ...)\n\ncrch.fit(x, z, y, left, right, truncated = FALSE, dist = \"gaussian\",\n  df = NULL, link.scale = \"log\", type = \"ml\", weights = NULL, offset = NULL, \n  control = crch.control()) \n\n\n\n\n\nformula\n\n\na formula expression of the form y ~ x | z where y is the response and x and z are regressor variables for the location and the scale of the fitted distribution respectively.\n\n\n\n\ndata\n\n\nan optional data frame containing the variables occurring in the formulas.\n\n\n\n\nsubset\n\n\nan optional vector specifying a subset of observations to be used for fitting.\n\n\n\n\nna.action\n\n\na function which indicates what should happen when the data contain NAs.\n\n\n\n\nweights\n\n\noptional case weights in fitting.\n\n\n\n\noffset\n\n\noptional numeric vector with a priori known component to be included in the linear predictor for the location. For crch.fit, offset can also be a list of 2 offsets used for the location and scale respectively.\n\n\n\n\nlink.scale\n\n\ncharacter specification of the link function in the scale model. Currently, “identity”, “log”, “quadratic” are supported. The default is “log”. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ndist\n\n\nassumed distribution for the dependent variable y.\n\n\n\n\ndf\n\n\noptional degrees of freedom for dist=“student”. If omitted the degrees of freedom are estimated.\n\n\n\n\nleft\n\n\nleft limit for the censored dependent variable y. If set to -Inf, y is assumed not to be left-censored.\n\n\n\n\nright\n\n\nright limit for the censored dependent variable y. If set to Inf, y is assumed not to be right-censored.\n\n\n\n\ntruncated\n\n\nlogical. If TRUE truncated model is fitted with left and right interpreted as truncation points, If FALSE censored model is fitted. Default is FALSE\n\n\n\n\ntype\n\n\nloss function to be optimized. Can be either “ml” for maximum likelihood (default) or “crps” for minimum continuous ranked probability score (CRPS).\n\n\n\n\ncontrol\n\n\na list of control parameters passed to optim or to the internal boosting algorithm if control=crch.boost(). Default is crch.control().\n\n\n\n\nmodel\n\n\nlogical. If TRUE model frame is included as a component of the returned value.\n\n\n\n\nx, y\n\n\nfor crch: logical. If TRUE the model matrix and response vector used for fitting are returned as components of the returned value. for crch.fit: x is a design matrix with regressors for the location and y is a vector of observations.\n\n\n\n\nz\n\n\na design matrix with regressors for the scale.\n\n\n\n\n…\n\n\narguments to be used to form the default control argument if it is not supplied directly.\n\n\n\ncrch fits censored (tobit) or truncated regression models with conditional heteroscedasticy with maximum likelihood estimation. Student-t, Gaussian, and logistic distributions can be fitted to left- and/or right censored or truncated responses. Different regressors can be used to model the location and the scale of this distribution. If control=crch.boost() optimization is performed by boosting.\ntrch is a wrapper function for crch with default truncated = TRUE.\ncrch.fit is the lower level function where the actual fitting takes place.\n\nAn object of class “crch” or “crch.boost”, i.e., a list with the following elements.\n\n\n\ncoefficients\n\n\nlist of coefficients for location, scale, and df. Scale and df coefficients are in log-scale.\n\n\n\n\ndf\n\n\nif dist = “student”: degrees of freedom of student-t distribution. else NULL.\n\n\n\n\nresiduals\n\n\nthe residuals, that is response minus fitted values.\n\n\n\n\nfitted.values\n\n\nlist of fitted location and scale parameters.\n\n\n\n\ndist\n\n\nassumed distribution for the dependent variable y.\n\n\n\n\ncens\n\n\nlist of censoring points.\n\n\n\n\noptim\n\n\noutput from optimization from optim.\n\n\n\n\nmethod\n\n\noptimization method used for optim.\n\n\n\n\ntype\n\n\nused loss function (maximum likelihood or minimum CRPS).\n\n\n\n\ncontrol\n\n\nlist of control parameters passed to optim\n\n\n\n\nstart\n\n\nstarting values of coefficients used in the optimization.\n\n\n\n\nweights\n\n\ncase weights used for fitting.\n\n\n\n\noffset\n\n\nlist of offsets for location and scale.\n\n\n\n\nn\n\n\nnumber of observations.\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights.\n\n\n\n\nloglik\n\n\nlog-likelihood.\n\n\n\n\nvcov\n\n\ncovariance matrix.\n\n\n\n\nlink\n\n\na list with element “scale” containing the link objects for the scale model.\n\n\n\n\ntruncated\n\n\nlogical indicating wheter a truncated model has been fitted.\n\n\n\n\nconverged\n\n\nlogical variable whether optimization has converged or not.\n\n\n\n\niterations\n\n\nnumber of iterations in optimization.\n\n\n\n\ncall\n\n\nfunction call.\n\n\n\n\nformula\n\n\nthe formula supplied.\n\n\n\n\nterms\n\n\nthe terms objects used.\n\n\n\n\nlevels\n\n\nlist of levels of the factors used in fitting for location and scale respectively.\n\n\n\n\ncontrasts\n\n\n(where relevant) the contrasts used.\n\n\n\n\ny\n\n\nif requested, the response used.\n\n\n\n\nx\n\n\nif requested, the model matrix used.\n\n\n\n\nmodel\n\n\nif requested, the model frame used.\n\n\n\n\nstepsize, mstop, mstopopt, standardize\n\n\nreturn values of boosting optimization. See crch.boost for details.\n\n\n\nMessner JW, Mayr GJ, Zeileis A (2016). Heteroscedastic Censored and Truncated Regression with crch. The R Journal, 3(1), 173–181. doi:10.32614/RJ-2016-012\nMessner JW, Zeileis A, Broecker J, Mayr GJ (2014). Probabilistic Wind Power Forecasts with an Inverse Power Curve Transformation and Censored Regression. Wind Energy, 17(11), 1753–1766. doi:10.1002/we.1666\n\npredict.crch, crch.control, crch.boost\n\n\nlibrary(\"crch\")\n\ndata(\"RainIbk\", package = \"crch\")\n## mean and standard deviation of square root transformed ensemble forecasts\nRainIbk$sqrtensmean &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, mean)\nRainIbk$sqrtenssd &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, sd)\n\n## fit linear regression model with Gaussian distribution \nCRCH &lt;- crch(sqrt(rain) ~ sqrtensmean, data = RainIbk, dist = \"gaussian\")\n## same as lm?\nall.equal(\n  coef(lm(sqrt(rain) ~ sqrtensmean, data = RainIbk)),\n  head(coef(CRCH), -1),\n  tol = 1e-6)\n\n[1] TRUE\n\n## print\nCRCH\n\n\nCall:\ncrch(formula = sqrt(rain) ~ sqrtensmean, data = RainIbk, dist = \"gaussian\")\n\nCoefficients (location model):\n(Intercept)  sqrtensmean  \n     0.1468       0.5817  \n\nCoefficients (scale model with log link):\n(Intercept)  \n     0.4945  \n\nDistribution: gaussian\n\n## summary\nsummary(CRCH)\n\n\nCall:\ncrch(formula = sqrt(rain) ~ sqrtensmean, data = RainIbk, dist = \"gaussian\")\n\nStandardized residuals:\n    Min      1Q  Median      3Q     Max \n-2.4256 -0.7120 -0.1562  0.5786  4.8408 \n\nCoefficients (location model):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.14683    0.05456   2.691  0.00713 ** \nsqrtensmean  0.58173    0.01540  37.781  &lt; 2e-16 ***\n\nCoefficients (scale model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.49454    0.01003   49.31   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nDistribution: gaussian\nLog-likelihood: -9512 on 3 Df\nNumber of iterations in BFGS optimization: 3 \n\n## left censored regression model with censoring point 0:\nCRCH2 &lt;- crch(sqrt(rain) ~ sqrtensmean, data = RainIbk, \n  dist = \"gaussian\", left = 0)\n\n## left censored regression model with censoring point 0 and \n## conditional heteroscedasticy:\nCRCH3 &lt;- crch(sqrt(rain) ~ sqrtensmean|sqrtenssd, data = RainIbk, \n  dist = \"gaussian\",  left = 0)\n\n## left censored regression model with censoring point 0 and \n## conditional heteroscedasticy with logistic distribution:\nCRCH4 &lt;- crch(sqrt(rain) ~ sqrtensmean|sqrtenssd, data = RainIbk, \n  dist = \"logistic\", left = 0)\n\n## compare AIC \nAIC(CRCH, CRCH2, CRCH3, CRCH4)\n\n      df      AIC\nCRCH   3 19029.75\nCRCH2  3 17961.76\nCRCH3  4 17914.41\nCRCH4  4 17867.35",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch"
    ]
  },
  {
    "objectID": "man/crch.html#censored-and-truncated-regression-with-conditional-heteroscedasticy",
    "href": "man/crch.html#censored-and-truncated-regression-with-conditional-heteroscedasticy",
    "title": "crch",
    "section": "",
    "text": "Fitting censored (tobit) or truncated regression models with conditional heteroscedasticy.\n\ncrch(formula, data, subset, na.action, weights, offset, \n  link.scale = c(\"log\", \"identity\", \"quadratic\"),\n  dist = c(\"gaussian\", \"logistic\", \"student\"), df = NULL, \n  left = -Inf, right = Inf, truncated = FALSE, \n  type = c(\"ml\", \"crps\"), control = crch.control(...), \n  model = TRUE, x = FALSE, y = FALSE, ...)\n\ntrch(formula, data, subset, na.action, weights, offset, \n  link.scale = c(\"log\", \"identity\", \"quadratic\"),\n  dist = c(\"gaussian\", \"logistic\", \"student\"), df = NULL, \n  left = -Inf, right = Inf, truncated = TRUE, \n  type = c(\"ml\", \"crps\"), control = crch.control(...), \n  model = TRUE, x = FALSE, y = FALSE, ...)\n\ncrch.fit(x, z, y, left, right, truncated = FALSE, dist = \"gaussian\",\n  df = NULL, link.scale = \"log\", type = \"ml\", weights = NULL, offset = NULL, \n  control = crch.control()) \n\n\n\n\n\nformula\n\n\na formula expression of the form y ~ x | z where y is the response and x and z are regressor variables for the location and the scale of the fitted distribution respectively.\n\n\n\n\ndata\n\n\nan optional data frame containing the variables occurring in the formulas.\n\n\n\n\nsubset\n\n\nan optional vector specifying a subset of observations to be used for fitting.\n\n\n\n\nna.action\n\n\na function which indicates what should happen when the data contain NAs.\n\n\n\n\nweights\n\n\noptional case weights in fitting.\n\n\n\n\noffset\n\n\noptional numeric vector with a priori known component to be included in the linear predictor for the location. For crch.fit, offset can also be a list of 2 offsets used for the location and scale respectively.\n\n\n\n\nlink.scale\n\n\ncharacter specification of the link function in the scale model. Currently, “identity”, “log”, “quadratic” are supported. The default is “log”. Alternatively, an object of class “link-glm” can be supplied.\n\n\n\n\ndist\n\n\nassumed distribution for the dependent variable y.\n\n\n\n\ndf\n\n\noptional degrees of freedom for dist=“student”. If omitted the degrees of freedom are estimated.\n\n\n\n\nleft\n\n\nleft limit for the censored dependent variable y. If set to -Inf, y is assumed not to be left-censored.\n\n\n\n\nright\n\n\nright limit for the censored dependent variable y. If set to Inf, y is assumed not to be right-censored.\n\n\n\n\ntruncated\n\n\nlogical. If TRUE truncated model is fitted with left and right interpreted as truncation points, If FALSE censored model is fitted. Default is FALSE\n\n\n\n\ntype\n\n\nloss function to be optimized. Can be either “ml” for maximum likelihood (default) or “crps” for minimum continuous ranked probability score (CRPS).\n\n\n\n\ncontrol\n\n\na list of control parameters passed to optim or to the internal boosting algorithm if control=crch.boost(). Default is crch.control().\n\n\n\n\nmodel\n\n\nlogical. If TRUE model frame is included as a component of the returned value.\n\n\n\n\nx, y\n\n\nfor crch: logical. If TRUE the model matrix and response vector used for fitting are returned as components of the returned value. for crch.fit: x is a design matrix with regressors for the location and y is a vector of observations.\n\n\n\n\nz\n\n\na design matrix with regressors for the scale.\n\n\n\n\n…\n\n\narguments to be used to form the default control argument if it is not supplied directly.\n\n\n\ncrch fits censored (tobit) or truncated regression models with conditional heteroscedasticy with maximum likelihood estimation. Student-t, Gaussian, and logistic distributions can be fitted to left- and/or right censored or truncated responses. Different regressors can be used to model the location and the scale of this distribution. If control=crch.boost() optimization is performed by boosting.\ntrch is a wrapper function for crch with default truncated = TRUE.\ncrch.fit is the lower level function where the actual fitting takes place.\n\nAn object of class “crch” or “crch.boost”, i.e., a list with the following elements.\n\n\n\ncoefficients\n\n\nlist of coefficients for location, scale, and df. Scale and df coefficients are in log-scale.\n\n\n\n\ndf\n\n\nif dist = “student”: degrees of freedom of student-t distribution. else NULL.\n\n\n\n\nresiduals\n\n\nthe residuals, that is response minus fitted values.\n\n\n\n\nfitted.values\n\n\nlist of fitted location and scale parameters.\n\n\n\n\ndist\n\n\nassumed distribution for the dependent variable y.\n\n\n\n\ncens\n\n\nlist of censoring points.\n\n\n\n\noptim\n\n\noutput from optimization from optim.\n\n\n\n\nmethod\n\n\noptimization method used for optim.\n\n\n\n\ntype\n\n\nused loss function (maximum likelihood or minimum CRPS).\n\n\n\n\ncontrol\n\n\nlist of control parameters passed to optim\n\n\n\n\nstart\n\n\nstarting values of coefficients used in the optimization.\n\n\n\n\nweights\n\n\ncase weights used for fitting.\n\n\n\n\noffset\n\n\nlist of offsets for location and scale.\n\n\n\n\nn\n\n\nnumber of observations.\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights.\n\n\n\n\nloglik\n\n\nlog-likelihood.\n\n\n\n\nvcov\n\n\ncovariance matrix.\n\n\n\n\nlink\n\n\na list with element “scale” containing the link objects for the scale model.\n\n\n\n\ntruncated\n\n\nlogical indicating wheter a truncated model has been fitted.\n\n\n\n\nconverged\n\n\nlogical variable whether optimization has converged or not.\n\n\n\n\niterations\n\n\nnumber of iterations in optimization.\n\n\n\n\ncall\n\n\nfunction call.\n\n\n\n\nformula\n\n\nthe formula supplied.\n\n\n\n\nterms\n\n\nthe terms objects used.\n\n\n\n\nlevels\n\n\nlist of levels of the factors used in fitting for location and scale respectively.\n\n\n\n\ncontrasts\n\n\n(where relevant) the contrasts used.\n\n\n\n\ny\n\n\nif requested, the response used.\n\n\n\n\nx\n\n\nif requested, the model matrix used.\n\n\n\n\nmodel\n\n\nif requested, the model frame used.\n\n\n\n\nstepsize, mstop, mstopopt, standardize\n\n\nreturn values of boosting optimization. See crch.boost for details.\n\n\n\nMessner JW, Mayr GJ, Zeileis A (2016). Heteroscedastic Censored and Truncated Regression with crch. The R Journal, 3(1), 173–181. doi:10.32614/RJ-2016-012\nMessner JW, Zeileis A, Broecker J, Mayr GJ (2014). Probabilistic Wind Power Forecasts with an Inverse Power Curve Transformation and Censored Regression. Wind Energy, 17(11), 1753–1766. doi:10.1002/we.1666\n\npredict.crch, crch.control, crch.boost\n\n\nlibrary(\"crch\")\n\ndata(\"RainIbk\", package = \"crch\")\n## mean and standard deviation of square root transformed ensemble forecasts\nRainIbk$sqrtensmean &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, mean)\nRainIbk$sqrtenssd &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, sd)\n\n## fit linear regression model with Gaussian distribution \nCRCH &lt;- crch(sqrt(rain) ~ sqrtensmean, data = RainIbk, dist = \"gaussian\")\n## same as lm?\nall.equal(\n  coef(lm(sqrt(rain) ~ sqrtensmean, data = RainIbk)),\n  head(coef(CRCH), -1),\n  tol = 1e-6)\n\n[1] TRUE\n\n## print\nCRCH\n\n\nCall:\ncrch(formula = sqrt(rain) ~ sqrtensmean, data = RainIbk, dist = \"gaussian\")\n\nCoefficients (location model):\n(Intercept)  sqrtensmean  \n     0.1468       0.5817  \n\nCoefficients (scale model with log link):\n(Intercept)  \n     0.4945  \n\nDistribution: gaussian\n\n## summary\nsummary(CRCH)\n\n\nCall:\ncrch(formula = sqrt(rain) ~ sqrtensmean, data = RainIbk, dist = \"gaussian\")\n\nStandardized residuals:\n    Min      1Q  Median      3Q     Max \n-2.4256 -0.7120 -0.1562  0.5786  4.8408 \n\nCoefficients (location model):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.14683    0.05456   2.691  0.00713 ** \nsqrtensmean  0.58173    0.01540  37.781  &lt; 2e-16 ***\n\nCoefficients (scale model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.49454    0.01003   49.31   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nDistribution: gaussian\nLog-likelihood: -9512 on 3 Df\nNumber of iterations in BFGS optimization: 3 \n\n## left censored regression model with censoring point 0:\nCRCH2 &lt;- crch(sqrt(rain) ~ sqrtensmean, data = RainIbk, \n  dist = \"gaussian\", left = 0)\n\n## left censored regression model with censoring point 0 and \n## conditional heteroscedasticy:\nCRCH3 &lt;- crch(sqrt(rain) ~ sqrtensmean|sqrtenssd, data = RainIbk, \n  dist = \"gaussian\",  left = 0)\n\n## left censored regression model with censoring point 0 and \n## conditional heteroscedasticy with logistic distribution:\nCRCH4 &lt;- crch(sqrt(rain) ~ sqrtensmean|sqrtenssd, data = RainIbk, \n  dist = \"logistic\", left = 0)\n\n## compare AIC \nAIC(CRCH, CRCH2, CRCH3, CRCH4)\n\n      df      AIC\nCRCH   3 19029.75\nCRCH2  3 17961.76\nCRCH3  4 17914.41\nCRCH4  4 17867.35",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch"
    ]
  },
  {
    "objectID": "man/coef.crch.boost.html",
    "href": "man/coef.crch.boost.html",
    "title": "crch",
    "section": "",
    "text": "Methods for extracting information from fitted crch.boost objects.\n\n\n\n## S3 method for class 'crch.boost'\ncoef(object, model = c(\"full\", \"location\", \"scale\", \"df\"), \n  mstop = NULL, zero.coefficients = FALSE, standardize = FALSE, ...)\n## S3 method for class 'crch.boost'\nprint(x, digits = max(3, getOption(\"digits\") - 3),\n  mstop = NULL, zero.coefficients = FALSE, ...)\n## S3 method for class 'crch.boost'\nsummary(object, mstop = NULL, zero.coefficients = FALSE, ...)\n## S3 method for class 'crch.boost'\nlogLik(object, mstop = NULL, ...)\n\n\n\n\n\n\n\nobject, x\n\n\nan object of class “crch.boost”.\n\n\n\n\nmodel\n\n\nmodel for which coefficients shall be returned.\n\n\n\n\nmstop\n\n\nstopping iteration for which coefficients shall be returned. Can be either a character (“max”, “aic”, “bic”, “cv”) or a numeric value.\n\n\n\n\nzero.coefficients\n\n\nlogical whether zero coefficients are returned.\n\n\n\n\nstandardize\n\n\nlogical whether coefficients shall be standardized.\n\n\n\n\ndigits\n\n\nthe number of significant digits to use when printing.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nIn addition to the methods above, the “crch” methods terms, model.frame, model.matrix, residuals, and fitted can be used also for “crch.boost” objects .\n\n\n\ncrch.boost, coef.crch",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "coef.crch.boost"
    ]
  },
  {
    "objectID": "man/coef.crch.boost.html#methods-for-boosted-crch-models",
    "href": "man/coef.crch.boost.html#methods-for-boosted-crch-models",
    "title": "crch",
    "section": "",
    "text": "Methods for extracting information from fitted crch.boost objects.\n\n\n\n## S3 method for class 'crch.boost'\ncoef(object, model = c(\"full\", \"location\", \"scale\", \"df\"), \n  mstop = NULL, zero.coefficients = FALSE, standardize = FALSE, ...)\n## S3 method for class 'crch.boost'\nprint(x, digits = max(3, getOption(\"digits\") - 3),\n  mstop = NULL, zero.coefficients = FALSE, ...)\n## S3 method for class 'crch.boost'\nsummary(object, mstop = NULL, zero.coefficients = FALSE, ...)\n## S3 method for class 'crch.boost'\nlogLik(object, mstop = NULL, ...)\n\n\n\n\n\n\n\nobject, x\n\n\nan object of class “crch.boost”.\n\n\n\n\nmodel\n\n\nmodel for which coefficients shall be returned.\n\n\n\n\nmstop\n\n\nstopping iteration for which coefficients shall be returned. Can be either a character (“max”, “aic”, “bic”, “cv”) or a numeric value.\n\n\n\n\nzero.coefficients\n\n\nlogical whether zero coefficients are returned.\n\n\n\n\nstandardize\n\n\nlogical whether coefficients shall be standardized.\n\n\n\n\ndigits\n\n\nthe number of significant digits to use when printing.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nIn addition to the methods above, the “crch” methods terms, model.frame, model.matrix, residuals, and fitted can be used also for “crch.boost” objects .\n\n\n\ncrch.boost, coef.crch",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "coef.crch.boost"
    ]
  },
  {
    "objectID": "man/TruncatedStudentsT.html",
    "href": "man/TruncatedStudentsT.html",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-truncated t distributions using the workflow from the distributions3 package.\n\nTruncatedStudentsT(df, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\ndf\n\n\nnumeric. The degrees of freedom of the underlying untruncated t distribution. Can be any positive number, with df = Inf corresponding to the normal distribution.\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying untruncated t distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying untruncated t distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left truncation point. Can be any real number, defaults to -Inf (untruncated). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the untruncated t distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right truncation point. Can be any real number, defaults to Inf (untruncated). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the untruncated t distribution at this point.\n\n\n\nThe constructor function TruncatedStudentsT sets up a distribution object, representing the truncated t probability distribution by the corresponding parameters: the degrees of freedom df, the latent mean location = \\(\\mu\\) and latent scale parameter scale = \\(\\sigma\\) (i.e., the parameters of the underlying untruncated t variable), the left truncation point (with -Inf corresponding to untruncated), and the right truncation point (with Inf corresponding to untruncated).\nThe truncated t distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\\(f(x) = 1/\\sigma \\tau((x - \\mu)/\\sigma) / (T((right - \\mu)/\\sigma) - T((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise, where \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the standard t distribution with df degrees of freedom, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of truncated t distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the TruncatedStudentsT distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the truncated t distributions in the crch package, see dtt, and the crps_tt function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (always TRUE).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA TruncatedStudentsT distribution object.\n\ndtt, StudentsT, CensoredStudentsT, TruncatedNormal, TruncatedLogistic\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three truncated t distributions:\n## - untruncated standard t with 5 degrees of freedom\n## - left-truncated at zero with 5 df, latent location = 1 and scale = 1\n## - interval-truncated in [0, 5] with 5 df, latent location = 2 and scale = 2\nX &lt;- TruncatedStudentsT(\n  df       = c(   5,   5, 5),\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 2),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"TruncatedStudentsT(df = 5, location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"TruncatedStudentsT(df = 5, location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"TruncatedStudentsT(df = 5, location = 2, scale = 2, left =    0, right =   5)\"\n\n## compute mean of the truncated distribution\nmean(X)\n\n[1] 0.000000 1.402643 2.287847\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1       r_2        r_3         r_4         r_5\n[1,] -0.3618879 0.4694046 -0.6565922 -0.06169882 -2.18313389\n[2,]  0.9166752 1.8390221  1.8795242  0.88274478  0.02392676\n[3,]  2.9245453 0.6966685  0.5923259  1.49145953  1.00217689\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"untruncated\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-truncated at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-truncated in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3796067 0.2684288 0.2272668\n\npdf(X, x, log = TRUE)\n\n[1] -0.9686196 -1.3151695 -1.4816304\n\nlog_pdf(X, x)\n\n[1] -0.9686196 -1.3151695 -1.4816304\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.0000000 0.1906476\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.000000 1.242002 2.223569\n\n## cdf() and quantile() are inverses (except at truncation points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05    q_0.5   q_0.95\n[1,] -2.0150484 0.000000 2.015048\n[2,]  0.1713748 1.242002 3.172937\n[3,]  0.3048628 2.223569 4.503390\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.015048  1.242002  4.503390\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.015048\n[2,]  1.242002\n[3,]  4.503390\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical   empirical\n[1,]    0.000000 -0.02414368\n[2,]    1.402643  1.37202824\n[3,]    2.287847  2.29976419\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1]       Inf 0.0000000 0.3016241",
    "crumbs": [
      "distributions3 objects",
      "TruncatedStudentsT"
    ]
  },
  {
    "objectID": "man/TruncatedStudentsT.html#create-a-truncated-students-t-distribution",
    "href": "man/TruncatedStudentsT.html#create-a-truncated-students-t-distribution",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-truncated t distributions using the workflow from the distributions3 package.\n\nTruncatedStudentsT(df, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\ndf\n\n\nnumeric. The degrees of freedom of the underlying untruncated t distribution. Can be any positive number, with df = Inf corresponding to the normal distribution.\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying untruncated t distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying untruncated t distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left truncation point. Can be any real number, defaults to -Inf (untruncated). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the untruncated t distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right truncation point. Can be any real number, defaults to Inf (untruncated). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the untruncated t distribution at this point.\n\n\n\nThe constructor function TruncatedStudentsT sets up a distribution object, representing the truncated t probability distribution by the corresponding parameters: the degrees of freedom df, the latent mean location = \\(\\mu\\) and latent scale parameter scale = \\(\\sigma\\) (i.e., the parameters of the underlying untruncated t variable), the left truncation point (with -Inf corresponding to untruncated), and the right truncation point (with Inf corresponding to untruncated).\nThe truncated t distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\\(f(x) = 1/\\sigma \\tau((x - \\mu)/\\sigma) / (T((right - \\mu)/\\sigma) - T((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise, where \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the standard t distribution with df degrees of freedom, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of truncated t distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the TruncatedStudentsT distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the truncated t distributions in the crch package, see dtt, and the crps_tt function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (always TRUE).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA TruncatedStudentsT distribution object.\n\ndtt, StudentsT, CensoredStudentsT, TruncatedNormal, TruncatedLogistic\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three truncated t distributions:\n## - untruncated standard t with 5 degrees of freedom\n## - left-truncated at zero with 5 df, latent location = 1 and scale = 1\n## - interval-truncated in [0, 5] with 5 df, latent location = 2 and scale = 2\nX &lt;- TruncatedStudentsT(\n  df       = c(   5,   5, 5),\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 2),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"TruncatedStudentsT(df = 5, location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"TruncatedStudentsT(df = 5, location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"TruncatedStudentsT(df = 5, location = 2, scale = 2, left =    0, right =   5)\"\n\n## compute mean of the truncated distribution\nmean(X)\n\n[1] 0.000000 1.402643 2.287847\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1       r_2        r_3         r_4         r_5\n[1,] -0.3618879 0.4694046 -0.6565922 -0.06169882 -2.18313389\n[2,]  0.9166752 1.8390221  1.8795242  0.88274478  0.02392676\n[3,]  2.9245453 0.6966685  0.5923259  1.49145953  1.00217689\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"untruncated\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-truncated at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-truncated in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3796067 0.2684288 0.2272668\n\npdf(X, x, log = TRUE)\n\n[1] -0.9686196 -1.3151695 -1.4816304\n\nlog_pdf(X, x)\n\n[1] -0.9686196 -1.3151695 -1.4816304\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.0000000 0.1906476\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.000000 1.242002 2.223569\n\n## cdf() and quantile() are inverses (except at truncation points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05    q_0.5   q_0.95\n[1,] -2.0150484 0.000000 2.015048\n[2,]  0.1713748 1.242002 3.172937\n[3,]  0.3048628 2.223569 4.503390\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.015048  1.242002  4.503390\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.015048\n[2,]  1.242002\n[3,]  4.503390\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical   empirical\n[1,]    0.000000 -0.02414368\n[2,]    1.402643  1.37202824\n[3,]    2.287847  2.29976419\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1]       Inf 0.0000000 0.3016241",
    "crumbs": [
      "distributions3 objects",
      "TruncatedStudentsT"
    ]
  },
  {
    "objectID": "man/predict.hxlr.html",
    "href": "man/predict.hxlr.html",
    "title": "crch",
    "section": "",
    "text": "Obtains various types of predictions/fitted values for heteroscedastic extended logistic regression (HXLR) models.\n\n\n\n## S3 method for class 'hxlr'\npredict(object, newdata = NULL, type = c(\"class\", \"probability\",\n  \"cumprob\", \"location\", \"scale\"), thresholds = object\\$thresholds,\n  na.action = na.pass, ...)\n## S3 method for class 'hxlr'\nfitted(object, type = c(\"class\", \"probability\", \n  \"cumprob\", \"location\", \"scale\"), ...)\n\n\n\n\n\n\n\nobject\n\n\nan object of class “hxlr”.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict.\n\n\n\n\ntype\n\n\ntype of prediction: “probability” returns a data frame with category probabilities, “cumprob” returns cumulative probabilities, “location” and “scale” return the location and scale of the predicted latent distribution respectively, and “class” returns the category with the highest probability. Default is “class”.\n\n\n\n\nthresholds\n\n\noptional thresholds used for defining the thresholds for types “probability”, “cumprob”, and “class”. Can differ from thresholds used for fitting. If omitted, the same thresholds as for fitting are used.\n\n\n\n\nna.action\n\n\nA function which indicates what should happen when the data contain NAs. Default is na.pass\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nFor type “prob” a matrix with number of intervals (= number of thresholds + 1) columns is produced. Each row corresponds to a row in newdata and contains the predicted probabilities to fall in the corresponding interval.\nFor type “cumprob” a matrix with number of thresholds columns is produced. Each row corresponds to a row in newdata and contains the predicted probabilities to fall below the corresponding threshold.\nFor types “class”, “location”, and “scale” a vector is returned respectively with either the most probable categories (“class”) or the location (“location”) or scale (scale) of the latent distribution.\n\n\n\nhxlr",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "predict.hxlr"
    ]
  },
  {
    "objectID": "man/predict.hxlr.html#predictions-for-fitted-hxlr-models",
    "href": "man/predict.hxlr.html#predictions-for-fitted-hxlr-models",
    "title": "crch",
    "section": "",
    "text": "Obtains various types of predictions/fitted values for heteroscedastic extended logistic regression (HXLR) models.\n\n\n\n## S3 method for class 'hxlr'\npredict(object, newdata = NULL, type = c(\"class\", \"probability\",\n  \"cumprob\", \"location\", \"scale\"), thresholds = object\\$thresholds,\n  na.action = na.pass, ...)\n## S3 method for class 'hxlr'\nfitted(object, type = c(\"class\", \"probability\", \n  \"cumprob\", \"location\", \"scale\"), ...)\n\n\n\n\n\n\n\nobject\n\n\nan object of class “hxlr”.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict.\n\n\n\n\ntype\n\n\ntype of prediction: “probability” returns a data frame with category probabilities, “cumprob” returns cumulative probabilities, “location” and “scale” return the location and scale of the predicted latent distribution respectively, and “class” returns the category with the highest probability. Default is “class”.\n\n\n\n\nthresholds\n\n\noptional thresholds used for defining the thresholds for types “probability”, “cumprob”, and “class”. Can differ from thresholds used for fitting. If omitted, the same thresholds as for fitting are used.\n\n\n\n\nna.action\n\n\nA function which indicates what should happen when the data contain NAs. Default is na.pass\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nFor type “prob” a matrix with number of intervals (= number of thresholds + 1) columns is produced. Each row corresponds to a row in newdata and contains the predicted probabilities to fall in the corresponding interval.\nFor type “cumprob” a matrix with number of thresholds columns is produced. Each row corresponds to a row in newdata and contains the predicted probabilities to fall below the corresponding threshold.\nFor types “class”, “location”, and “scale” a vector is returned respectively with either the most probable categories (“class”) or the location (“location”) or scale (scale) of the latent distribution.\n\n\n\nhxlr",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "predict.hxlr"
    ]
  },
  {
    "objectID": "man/CensoredLogistic.html",
    "href": "man/CensoredLogistic.html",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-censored logistic distributions using the workflow from the distributions3 package.\n\nCensoredLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying uncensored logistic distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying uncensored logistic distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left censoring point. Can be any real number, defaults to -Inf (uncensored). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the uncensored logistic distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right censoring point. Can be any real number, defaults to Inf (uncensored). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the uncensored logistic distribution at this point.\n\n\n\nThe constructor function CensoredLogistic sets up a distribution object, representing the censored logistic probability distribution by the corresponding parameters: the latent mean location = \\(\\mu\\) and latent standard deviation scale = \\(\\sigma\\) (i.e., the parameters of the underlying uncensored logistic variable), the left censoring point (with -Inf corresponding to uncensored), and the right censoring point (with Inf corresponding to uncensored).\nThe censored logistic distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\n\\(\\Lambda((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Lambda((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\lambda((x - \\mu)/\\sigma)/\\sigma\\)\n\n\notherwise\n\n\n\nwhere \\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of censored logistic distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the CensoredLogistic distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the censored logistic distributions in the crch package, see dclogis, and the crps_clogis function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (only TRUE if there is no censoring, i.e., if both left and right are infinite).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA CensoredLogistic distribution object.\n\ndclogis, Logistic, TruncatedLogistic, CensoredNormal, CensoredStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three censored logistic distributions:\n## - uncensored standard logistic\n## - left-censored at zero with latent location = 1 and scale = 1\n## - interval-censored in [0, 5] with latent location = 2 and scale = 1\nX &lt;- CensoredLogistic(\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 1),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"CensoredLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"CensoredLogistic(location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"CensoredLogistic(location = 2, scale = 1, left =    0, right =   5)\"\n\n## compute mean of the censored distribution\nmean(X)\n\n[1] 0.000000 1.313262 2.078341\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1        r_2        r_3         r_4        r_5\n[1,] -0.5489266 0.71149394 -0.9934677 -0.09368233 -3.1677767\n[2,]  0.3829342 2.00150190  2.0657180  0.31347300  0.0000000\n[3,]  2.7294189 0.05283236  0.0000000  1.19632319  0.5573964\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"uncensored\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-censored at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-censored in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.2500000 0.2689414 0.1966119\n\npdf(X, x, log = TRUE)\n\n[1] -1.386294 -1.313262 -1.626523\n\nlog_pdf(X, x)\n\n[1] -1.386294 -1.313262 -1.626523\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.2689414 0.2689414\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0 1 2\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n        q_0.05 q_0.5   q_0.95\n[1,] -2.944439     0 2.944439\n[2,]  0.000000     1 3.944439\n[3,]  0.000000     2 4.944439\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.944439  1.000000  4.944439\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.944439\n[2,]  1.000000\n[3,]  4.944439\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 -0.0299458\n[2,]    1.313262  1.2761385\n[3,]    2.078341  2.0830220\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.3862944 0.5822031 0.6176368",
    "crumbs": [
      "distributions3 objects",
      "CensoredLogistic"
    ]
  },
  {
    "objectID": "man/CensoredLogistic.html#create-a-censored-logistic-distribution",
    "href": "man/CensoredLogistic.html#create-a-censored-logistic-distribution",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-censored logistic distributions using the workflow from the distributions3 package.\n\nCensoredLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying uncensored logistic distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying uncensored logistic distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left censoring point. Can be any real number, defaults to -Inf (uncensored). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the uncensored logistic distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right censoring point. Can be any real number, defaults to Inf (uncensored). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the uncensored logistic distribution at this point.\n\n\n\nThe constructor function CensoredLogistic sets up a distribution object, representing the censored logistic probability distribution by the corresponding parameters: the latent mean location = \\(\\mu\\) and latent standard deviation scale = \\(\\sigma\\) (i.e., the parameters of the underlying uncensored logistic variable), the left censoring point (with -Inf corresponding to uncensored), and the right censoring point (with Inf corresponding to uncensored).\nThe censored logistic distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\n\\(\\Lambda((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Lambda((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\lambda((x - \\mu)/\\sigma)/\\sigma\\)\n\n\notherwise\n\n\n\nwhere \\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of censored logistic distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the CensoredLogistic distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the censored logistic distributions in the crch package, see dclogis, and the crps_clogis function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (only TRUE if there is no censoring, i.e., if both left and right are infinite).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA CensoredLogistic distribution object.\n\ndclogis, Logistic, TruncatedLogistic, CensoredNormal, CensoredStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three censored logistic distributions:\n## - uncensored standard logistic\n## - left-censored at zero with latent location = 1 and scale = 1\n## - interval-censored in [0, 5] with latent location = 2 and scale = 1\nX &lt;- CensoredLogistic(\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 1),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"CensoredLogistic(location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"CensoredLogistic(location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"CensoredLogistic(location = 2, scale = 1, left =    0, right =   5)\"\n\n## compute mean of the censored distribution\nmean(X)\n\n[1] 0.000000 1.313262 2.078341\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1        r_2        r_3         r_4        r_5\n[1,] -0.5489266 0.71149394 -0.9934677 -0.09368233 -3.1677767\n[2,]  0.3829342 2.00150190  2.0657180  0.31347300  0.0000000\n[3,]  2.7294189 0.05283236  0.0000000  1.19632319  0.5573964\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"uncensored\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-censored at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-censored in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.2500000 0.2689414 0.1966119\n\npdf(X, x, log = TRUE)\n\n[1] -1.386294 -1.313262 -1.626523\n\nlog_pdf(X, x)\n\n[1] -1.386294 -1.313262 -1.626523\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.2689414 0.2689414\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0 1 2\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n        q_0.05 q_0.5   q_0.95\n[1,] -2.944439     0 2.944439\n[2,]  0.000000     1 3.944439\n[3,]  0.000000     2 4.944439\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.944439  1.000000  4.944439\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.944439\n[2,]  1.000000\n[3,]  4.944439\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 -0.0299458\n[2,]    1.313262  1.2761385\n[3,]    2.078341  2.0830220\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.3862944 0.5822031 0.6176368",
    "crumbs": [
      "distributions3 objects",
      "CensoredLogistic"
    ]
  },
  {
    "objectID": "man/tt.html",
    "href": "man/tt.html",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right truncated student-t distribution with df degrees of freedom.\n\n\n\ndtt(x, location = 0, scale = 1, df, left = -Inf, right = Inf, log = FALSE)\n\nptt(q, location = 0, scale = 1, df, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqtt(p, location = 0, scale = 1, df, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nrtt(n, location = 0, scale = 1, df, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\ndf\n\n\ndegrees of freedom (&gt; 0, maybe non-integer). df = Inf is allowed.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe truncated student-t distribution has density\n\nf(x) = 1/((x - )/) / (T((right - )/) - T((left - )/))\nfor \\(left \\le x \\le right\\), and 0 otherwise.\nwhere \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the student-t distribution with df degrees of freedom respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndtt gives the density, ptt gives the distribution function, qtt gives the quantile function, and rtt generates random deviates.\n\n\n\ndt",
    "crumbs": [
      "Distributions",
      "tt"
    ]
  },
  {
    "objectID": "man/tt.html#the-truncated-student-t-distribution",
    "href": "man/tt.html#the-truncated-student-t-distribution",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right truncated student-t distribution with df degrees of freedom.\n\n\n\ndtt(x, location = 0, scale = 1, df, left = -Inf, right = Inf, log = FALSE)\n\nptt(q, location = 0, scale = 1, df, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqtt(p, location = 0, scale = 1, df, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nrtt(n, location = 0, scale = 1, df, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\ndf\n\n\ndegrees of freedom (&gt; 0, maybe non-integer). df = Inf is allowed.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe truncated student-t distribution has density\n\nf(x) = 1/((x - )/) / (T((right - )/) - T((left - )/))\nfor \\(left \\le x \\le right\\), and 0 otherwise.\nwhere \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the student-t distribution with df degrees of freedom respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndtt gives the density, ptt gives the distribution function, qtt gives the quantile function, and rtt generates random deviates.\n\n\n\ndt",
    "crumbs": [
      "Distributions",
      "tt"
    ]
  },
  {
    "objectID": "man/ct.html",
    "href": "man/ct.html",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right censored student-t distribution with df degrees of freedom.\n\n\n\ndct(x, location = 0, scale = 1, df, left = -Inf, right = Inf, log = FALSE)\n\npct(q, location = 0, scale = 1, df, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqct(p, location = 0, scale = 1, df, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nrct(n, location = 0, scale = 1, df, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\ndf\n\n\ndegrees of freedom (&gt; 0, maybe non-integer). df = Inf is allowed.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe censored student-t distribution has density \\(f(x)\\):\n\n\n\n\\(T((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - T((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\tau((x - \\mu)/\\sigma)/\\sigma\\)\n\n\nif \\(left &lt; x &lt; right\\)\n\n\n\nwhere \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the student-t distribution with df degrees of freedom respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndct gives the density, pct gives the distribution function, qct gives the quantile function, and rct generates random deviates.\n\n\n\ndt",
    "crumbs": [
      "Distributions",
      "ct"
    ]
  },
  {
    "objectID": "man/ct.html#the-censored-student-t-distribution",
    "href": "man/ct.html#the-censored-student-t-distribution",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right censored student-t distribution with df degrees of freedom.\n\n\n\ndct(x, location = 0, scale = 1, df, left = -Inf, right = Inf, log = FALSE)\n\npct(q, location = 0, scale = 1, df, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqct(p, location = 0, scale = 1, df, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nrct(n, location = 0, scale = 1, df, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\ndf\n\n\ndegrees of freedom (&gt; 0, maybe non-integer). df = Inf is allowed.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe censored student-t distribution has density \\(f(x)\\):\n\n\n\n\\(T((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - T((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\tau((x - \\mu)/\\sigma)/\\sigma\\)\n\n\nif \\(left &lt; x &lt; right\\)\n\n\n\nwhere \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the student-t distribution with df degrees of freedom respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndct gives the density, pct gives the distribution function, qct gives the quantile function, and rct generates random deviates.\n\n\n\ndt",
    "crumbs": [
      "Distributions",
      "ct"
    ]
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "crch 1.2-0",
    "section": "",
    "text": "crch 1.2-0\n\nImproved implementations of expectation and variance of censored and truncated normal distributions (contributed by Ioannis Kosmidis).\nTurned vignette(\"crch\", package = \"crch\") from Sweave into Quarto vignettes. Some improvements/updates in the text.\nNew package web page (via altdoc/quarto) at https://topmodels.R-Forge.R-project.org/crch/\n\n\n\ncrch 1.1-2\n\nFixed name of first argument in crps() method to be consistent with the generic.\n\n\n\ncrch 1.1-1\n\nAdded methods for is_discrete() and is_continuous() for the new distributions3 objects.\nReplaced deprecated C function finite() with isfinite() (again).\n\n\n\ncrch 1.1-0\n\nAdded support for distributions3 workflows for censored and truncated normal, logistic, and Student’s t distributions: CensoredNormal(), TruncatedNormal(), CensoredLogistic(), TruncatedLogistic(), CensoredStudentsT(), TruncatedStudentsT(). See the corresponding manual pages for examples illustrating how to work with the distributions in practice, for computing moments, probabilities, densities, simulating random values, etc.\nAdded prodist() method for extracting the distributions3 objects above from fitted crch objects, either in-sample or out-of-sample.\nBug fix in the computation of the mean of censored or truncated logistic distributions with large (or infinite) censoring/truncation points.\n\n\n\ncrch 1.0-4\n\nReplaced deprecated C function finite() with isfinite().\n\n\n\ncrch 1.0-3\n\nUpdated contact information.\n\n\n\ncrch 1.0-1\n\nAdded argument type to crch() which can be set to \"crps\" for parameter estimation with minimum CRPS instead of maximum likelihood.\nAdded S3 method for crps() from scoringRules for crch objects.\nImprovements for the predict() method:\n\nNew types \"parameter\", \"density\", \"probability\", and \"crps\".\nWith type = \"response\" now the expected value and not the location parameter is returned (not equal for censored and truncated distributions). For better backward compatibility, the default type is set to \"location\".\n\nAdded pit(), rootogram(), and simulate() methods for crch objects.\nChanged argument names mean and sd to location and scale in logistic and Student’s t distribution functions\nAdded new function crch.stabsel() for stability selection based on\ncrch.boost.fit(). Some S3 methods for the returned class stabsel.crch are also provided.\n\n\n\ncrch 1.0-0\n\nNew release accompanying the R Journal paper: Heteroscedastic Censored and Truncated Regression with crch by Messner, Mayr, and Zeileis. See also citation(\"crch\").\nAdded estfun() method for crch objects\n\n\n\ncrch 0.9-2\n\nThe crch() function now supports coefficient optimization by boosting to automatically select the most relevant input variables in high-dimensional data settings. Extractor and plotting functions for corresponding crch.boost objects are also available.\nTransferred functions to estimate density, distribution, score, and Hessian matrices to C code to accelerate coefficient optimization.\nAdded option to crch() to avoid computation of covariance matrix.\nAdded left and right arguments to predict.crch() and predict.crch.boost() to allow quantile predictions for non-constant censoring or truncation points.\n\n\n\ncrch 0.9-1\n\nAdded model.matrix() and model.frame() methods for crch objects\nBug fix in predict.crch(): In previous versions predictions for models with other link functions than the log gave wrong results\n\n\n\ncrch 0.9-0\n\nAdded vignette to introduce the crch() function with some theoretical background and an illustrating example: vignette(\"crch\", package = \"crch\")\nThe crch() function now also supports truncated responses. Furthermore added a wrapper function trch() to fit truncated regression models.\ncrch(): Analytical gradients and Hessian matrices are provided for most models to speed up maximum likelihood optimization (not available for Student’s t distribution with degrees of freedom estimation).\ncrch(): For the scale model a link function can now be specified (\"log\", \"identity\", or \"quadratic\"). In previous version only the log was supported.\nAdded functions for probability density, cumulative distribution, random numbers, and quantiles for censored and truncated normal, logistic, and Student’s t distributions.\nThe residuals() method for crch objects now also provides quantile residuals (Dunn and Smyth 1996).\nAdded update() method for crch objects.\n\n\n\ncrch 0.1-0\n\nFirst official release of the package on CRAN. See citation(\"crch\") for the accompanying manuscripts. Note that the interface of both crch() and hxlr() is still under development and might change in future versions of the package."
  },
  {
    "objectID": "vignettes/crch.html",
    "href": "vignettes/crch.html",
    "title": "Heteroscedastic Censored and Truncated Regression with crch",
    "section": "",
    "text": "Censored or truncated response variables occur in a variety of applications. Censored data arise if exact values are only reported in a restricted range. Data may fall outside this range but are reported at the range limits. In contrast, if data outside this range are omitted completely we call it truncated. E.g., consider wind measurements with an instrument that needs a certain minimum wind speed to start working. If wind speeds below this minimum are recorded as \\(\\le\\)minimum the data is censored. If only wind speeds exceeding this limit are reported and those below are omitted the data is truncated. Even if the generating process is not as clear, censoring or truncation can be useful to consider limited data such as precipitation observations.\nThe tobit (Tobin 1958) and truncated regression (Cragg 1971) models are common linear regression models for censored and truncated conditionally normally distributed responses respectively.\nBeside truncated data, truncated regression is also used in two-part models (Cragg 1971) for censored type data: A binary (e.g., probit) regression model fits the exceedance probability of the lower limit and a truncated regression model fits the value given the lower limit is exceeded.\nUsually linear models like the tobit or truncated regression models assume homoscedasticity which means that the variance of an underlying normal distribution does not depend on covariates. However, sometimes this assumption does not hold and models that can consider conditional heteroscedasticity should be used. Such models have been proposed, e.g., for generalized linear models Smyth (1989), generalized additive models Rigby and Stasinopoulos (2005), or beta regression (Cribari-Neto and Zeileis 2010). There also exist several R packages with functions implementing the above models, e.g., dglm (Dunn, Smyth, and Corty 2023), glmx (Zeileis, Koenker, and Doebler 2023), gamlss (Rigby and Stasinopoulos 2005), betareg (Grün, Kosmidis, and Zeileis 2012) amongst others.\nThe crch package provides functions to fit censored and truncated regression models that consider conditional heteroscedasticity. It has a convenient interface to estimate these models with maximum likelihood and provides several methods for analysis and prediction. In addition to the typical conditional Gaussian distribution assumptions it also allows for logistic and student-t distributions with heavier tails.\nThe outline of the paper is as follows. Section 2 describes the censored and truncated regression models, and Section 3 presents their R implementation. Section 4 illustrates the package functions with numerical weather prediction data of precipitation in Innsbruck (Austria) and finally Section 5 summarizes the paper."
  },
  {
    "objectID": "vignettes/crch.html#sec-intro",
    "href": "vignettes/crch.html#sec-intro",
    "title": "Heteroscedastic Censored and Truncated Regression with crch",
    "section": "",
    "text": "Censored or truncated response variables occur in a variety of applications. Censored data arise if exact values are only reported in a restricted range. Data may fall outside this range but are reported at the range limits. In contrast, if data outside this range are omitted completely we call it truncated. E.g., consider wind measurements with an instrument that needs a certain minimum wind speed to start working. If wind speeds below this minimum are recorded as \\(\\le\\)minimum the data is censored. If only wind speeds exceeding this limit are reported and those below are omitted the data is truncated. Even if the generating process is not as clear, censoring or truncation can be useful to consider limited data such as precipitation observations.\nThe tobit (Tobin 1958) and truncated regression (Cragg 1971) models are common linear regression models for censored and truncated conditionally normally distributed responses respectively.\nBeside truncated data, truncated regression is also used in two-part models (Cragg 1971) for censored type data: A binary (e.g., probit) regression model fits the exceedance probability of the lower limit and a truncated regression model fits the value given the lower limit is exceeded.\nUsually linear models like the tobit or truncated regression models assume homoscedasticity which means that the variance of an underlying normal distribution does not depend on covariates. However, sometimes this assumption does not hold and models that can consider conditional heteroscedasticity should be used. Such models have been proposed, e.g., for generalized linear models Smyth (1989), generalized additive models Rigby and Stasinopoulos (2005), or beta regression (Cribari-Neto and Zeileis 2010). There also exist several R packages with functions implementing the above models, e.g., dglm (Dunn, Smyth, and Corty 2023), glmx (Zeileis, Koenker, and Doebler 2023), gamlss (Rigby and Stasinopoulos 2005), betareg (Grün, Kosmidis, and Zeileis 2012) amongst others.\nThe crch package provides functions to fit censored and truncated regression models that consider conditional heteroscedasticity. It has a convenient interface to estimate these models with maximum likelihood and provides several methods for analysis and prediction. In addition to the typical conditional Gaussian distribution assumptions it also allows for logistic and student-t distributions with heavier tails.\nThe outline of the paper is as follows. Section 2 describes the censored and truncated regression models, and Section 3 presents their R implementation. Section 4 illustrates the package functions with numerical weather prediction data of precipitation in Innsbruck (Austria) and finally Section 5 summarizes the paper."
  },
  {
    "objectID": "vignettes/crch.html#sec-models",
    "href": "vignettes/crch.html#sec-models",
    "title": "Heteroscedastic Censored and Truncated Regression with crch",
    "section": "\n2 Regression models",
    "text": "2 Regression models\nFor both, censored and truncated regression, a normalized latent response \\((y^*-\\mu)/\\sigma\\) is assumed to follow a certain distribution \\(D\\)\n\\[\n  \\frac{y^*-\\mu}{\\sigma} \\sim  D\n\\]\nThe location parameter \\(\\mu\\) and a link function of the scale parameter \\(g(\\sigma)\\) are assumed to relate linearly to covariates \\(\\mathbf{x} = (1, x_1,\nx_2, \\ldots)^\\top\\) and \\(\\mathbf{z} = (1, z_1, z_2, \\ldots)^\\top\\):\n\\[\n\\begin{eqnarray}\n    \\mu &= &\\mathbf{x}^{\\top}\\beta \\\\\n    g(\\sigma) & = & \\mathbf{z}^{\\top}\\gamma\n\\end{eqnarray}\n\\tag{1}\\]\nwhere \\(\\beta=(\\beta_0, \\beta_1, \\beta_2, \\ldots)^\\top\\) and \\(\\gamma=(\\gamma_0,\n\\gamma_1, \\gamma_2, \\ldots)^\\top\\) are coefficient vectors. The link function \\(g(\\cdot):\\mathbb{R}^+ \\mapsto \\mathbb{R}\\) is a strictly increasing and twice differentiable function; e.g., the logarithm (i.e., ) is a well suited function. Although they only map to \\(\\mathbb{R}^+\\), the identity \\(g(\\sigma) = \\sigma\\) or the quadratic function \\(g(\\sigma)=\\sigma^2\\) can be usefull as well. However, problems in the numerical optimization can occur.\nCommonly \\(D\\) is the standard normal distribution so that \\(y^*\\) is assumed to be normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\). \\(D\\) might also be assumed to be a standard logistic or a student-t distribution if heavier tails are required. The tail weight of the student-t distribution can be controlled by the degrees of freedom \\(\\nu\\) which can either be set to a certain value or estimated as an additional parameter. To assure positive values, \\(\\log(\\nu)\\) is modeled in the latter case.\n\\[\n  \\log(\\nu) = \\delta\n\\tag{2}\\]\n\n2.1 Censored regression (tobit)\nThe exact values of censored responses are only known in an interval defined by \\(\\text{left}\\) and \\(\\text{right}\\). Observation outside this interval are mapped to the interval limits\n\\[\n  y = \\begin{cases} \\text{left} & y^* \\le \\text{left} \\\\\n    y^* & \\text{left} &lt; y^* &lt; \\text{right}\\\\\n    \\text{right} & y^* \\ge \\text{right} \\end{cases}\n\\]\nThe coefficients \\(\\beta\\), \\(\\gamma\\), and \\(\\delta\\) (Equation 1 and Equation 2)) can be estimated by maximizing the sum over the data set of the log-likelihood function \\(\\log(f_{\\text{cens}}(y, \\mu, \\sigma))\\), where\n\\[\n  f_{\\text{cens}}(y, \\mu, \\sigma) =  \n    \\begin{cases} F\\left(\\frac{\\text{left} - \\mu}{\\sigma}\\right)\n      & y \\le \\text{left} \\\\\n    f\\left(\\frac{y - \\mu}{\\sigma}\\right)\n      & \\text{left} &lt; y &lt; \\text{right} \\\\\n    \\left(1 - F\\left(\\frac{\\text{right} - \\mu}{\\sigma}\\right)\\right)\n      & y \\ge \\text{right} \\end{cases}\n\\]\n\\(F()\\) and \\(f()\\) are the cumulative distribution function and the probability density function of \\(D\\), respectively. If \\(D\\) is the normal distribution this model is a heteroscedastic variant of the tobit model (Tobin 1958).\n\n2.2 Truncated regression\nTruncated responses occur when latent responses below or above some thresholds are omitted.\n\\[\n  y = y^*|\\text{left} &lt; y^* &lt; \\text{right}\n\\]\nThen \\(y\\) follows a truncated distribution with probability density function\n\\[\n  f_{\\text{tr}}(y, \\mu, \\sigma) =\n    \\frac{f\\left(\\frac{y - \\mu}{\\sigma}\\right)}\n    {F\\left(\\frac{\\text{right} - \\mu}{\\sigma}\\right) -\n    F\\left(\\frac{\\text{left} - \\mu}{\\sigma}\\right)}\n\\]\nIn that case the coefficients \\(\\beta\\), \\(\\gamma\\), and \\(\\delta\\) can be estimated by maximizing the sum over the data set of the log-likelihood function\n\\[\n  \\log(f_{\\text{tr}}(y, \\mu, \\sigma))\n\\]"
  },
  {
    "objectID": "vignettes/crch.html#sec-impl",
    "href": "vignettes/crch.html#sec-impl",
    "title": "Heteroscedastic Censored and Truncated Regression with crch",
    "section": "\n3 R implementation",
    "text": "3 R implementation\nThe models from the previous section can both be fitted with the crch() function provided by the crch package. This function takes a formula and data, sets up the likelihood function, gradients and Hessian matrix and uses optim() to maximize the likelihood. It returns an 3 object for which various standard methods are available. We tried to build an interface as similar to glm() as possible to facilitate the usage.\n\ncrch(formula, data, subset, na.action, weights, offset, link.scale = \"log\", \n  dist = \"gaussian\", df = NULL, left = -Inf, right = Inf, truncated = FALSE,\n  type = \"ml\", control = crch.control(...),\n  model = TRUE, x = FALSE, y = FALSE, ...)\n\nHere formula, data, na.action, weights, and offset have their standard model frame meanings (e.g., Chambers and Hastie 1992). However, as provided in the Formula package (Zeileis and Croissant 2010) formula can have two parts separated by | where the first part defines the location model and the second part the scale model. E.g., with y ~ x1 + x2 | z1 + z2 the location model is specified by y ~ x1 + x2 and the scale model by ~ z1 + z2. Known offsets can be specified for the location model by offset or for both, the location and scale model, inside formula, i.e., y ~ x1 + x2 + offset(x3) | z1 + z2 + offset(z3).\nThe link function \\(g(\\cdot)\\) for the scale model can be specified by link.scale. The default is \"log\", also supported are \"identity\" and \"quadratic\". Furthermore, an arbitrary link function can be specified by supplying an object of class \"link-glm\" containing linkfun, linkinv, mu.eta, and name. Furthermore it must contain the second derivative dmu.deta if analytical Hessians are employed.\ndist specifies the used distribution. Currently supported are \"gaussian\" (the default), \"logistic\", and \"student\". If dist = \"student\" the degrees of freedom can be set by the df argument. If set to NULL (the default) the degrees of freedom are estimated by maximum likelihood (Equation 2).\nleft and right define the lower and upper censoring or truncation points respectively. The logical argument truncated defines whether a censored or truncated model is estimated. Note that also a wrapper function trch() exists that is equivalent to crch() but with default truncated = TRUE.\nWith type = \"ml\" maximum likelihood estimation is carried out with the R function optim() using control options specified in crch.control(). By default the \"BFGS\" method is applied. If no starting values are supplied, coefficients from lm() are used as starting values for the location part. For the scale model the intercept is initialized with the link function of the residual standard deviation from lm() and the remaining scale coefficients are initialized with 0. If the degrees of freedom of a distribution are estimated they are initialized by 10. For the distribution with estimated degrees of freedom the covariance matrix estimate is derived from the numerical Hessian returned by optim(). For fixed degrees of freedom and Gaussian and logistic distributions the covariance matrix is derived analytically. However, by setting hessian = TRUE the numerical Hessian can be employed for those models as well.\nAs alternative estimation methods type = \"crps\" and/or control = crch.boost(...) are available. With type = \"crps\" the objective function is the minimum continuous ranked probability score (CRPS) as a more robust alternative to maximum likelihood. With control options set by crch.boost() boosting is used for estimation, i.e., where the iterations in the fitting of the model are stopped early (offering various criteria for selecting the number of iterations automatically). Moreover, a convenience interface crch.stabsel() for stability selection based on boosted crch() models is provided.\nFinally model, y, and x specify whether the model frame, response, or model matrix are returned.\nThe returned model fit of class \"crch\" (and additionally \"crch.boost\" if the model is fitted by boosting) is a list similar to \"glm\" objects. Some components like coefficients are lists with elements for location, scale, and degrees of freedom. The package also provides a set of extractor methods for \"crch\" objects that are listed in Table 1.\n\n\nTable 1: Functions and methods for objects of class \"crch\".\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nprint()\nPrint function call and estimated coefficients.\n\n\nsummary()\nStandard regression output (coefficient estimates, standard errors, partial Wald tests). Returns an object of class \"summary.crch\" containing summary statistics which has a print() method.\n\n\ncoef()\nExtract model coefficients where model specifies whether a single vector containing all coefficients (\"full\") or the coefficients for the location (\"location\"), scale (\"scale\") or degrees of freedom (\"df\") are returned.\n\n\nvcov()\nVariance-covariance matrix of the estimated coefficients.\n\n\npredict()\nPredictions for new data where \"type\" controls whether location (\"response\"/\"location\"), scale (\"scale\") or quantiles (\"quantile\") are predicted. Quantile probabilities are specified by at.\n\n\nfitted()\nFitted values for observed data where \"type\" controls whether location (\"location\") or scale (\"scale\") values are returned.\n\n\nresiduals()\nExtract various types of residuals where type can be \"standardized\" (default), \"pearson\", \"response\", or \"quantile\".\n\n\nterms()\nExtract terms of model components.\n\n\nlogLik()\nExtract fitted log-likelihood.\n\n\n\n\n\n\nAdditional to the crch() function and corresponding methods the crch package also provides probability density, cumulative distribution, random number, and quantile functions for censored and truncated normal, logistic, and student-t distributions. Furthermore it also provides a function hxlr() (heteroscedastic extended logistic regression) to fit heteroscedastic interval-censored regression models (Messner, Zeileis, Mayr, et al. 2014).\nNote that alternative to crch() heteroscedastic censored and truncated models could also be fitted by the R package gamlss (Rigby and Stasinopoulos 2005) with the add-on packages gamlss.cens and gamlss.tr. However, for the special case of linear censored of truncated regression models with Gaussian, logistic, or student-t distribution crch provides a fast and convenient interface and various useful methods for analysis and prediction. Also, crch provides the alternative fitting methods minimum CRPS estimation, boosting, and stability selection."
  },
  {
    "objectID": "vignettes/crch.html#sec-examples",
    "href": "vignettes/crch.html#sec-examples",
    "title": "Heteroscedastic Censored and Truncated Regression with crch",
    "section": "\n4 Example",
    "text": "4 Example\nThis section shows a weather forecast example application of censored and truncated regression models fitted with crch(). Weather forecasts are usually based on numerical weather prediction (NWP) models that take the current state of the atmosphere and compute future weather by numerically simulating the most important atmospheric processes. However, because of uncertain initial conditions and unknown or unresolved processes these numerical predictions are always subject to errors. To estimate these errors, many weather centers provide so called ensemble forecasts: several NWP runs that use different initial conditions and model formulations. Unfortunately these ensemble forecasts cannot consider all error sources so that they are often still biased and uncalibrated. Thus they are often calibrated and corrected for systematic errors by statistical post-processing.\nOne popular post-processing method is heteroscedastic linear regression where the ensemble mean is used as regressor for the location and the ensemble standard deviation or variance is used as regressor for the scale (e.g., Gneiting et al. 2005). Because not all meteorological variables can be assumed to be normally distributed this idea has also been extended to other distributions including truncated regression for wind (Thorarinsdottir and Gneiting 2010) and censored regression for wind power (Messner, Zeileis, Broecker, et al. 2014) or precipitation (Messner, Mayr, et al. 2014).\nThe following example applies heteroscedastic censored regression with a logistic distribution assumption to precipitation data in Innsbruck (Austria). Furthermore, a two-part model tests whether the occurrence of precipitation and the precipitation amount are driven by the same process.\nFirst, the crch package is loaded together with an included precipitation data set with forecasts and observations for Innsbruck (Austria)\n\nlibrary(\"crch\")\ndata(\"RainIbk\", package = \"crch\")\n\nThe data.frame RainIbk contains observed 3 day-accumulated precipitation amounts (rain) and the corresponding 11 member ensemble forecasts of total accumulated precipitation amount between 5 and 8 days in advance (rainfc.1, rainfc.2, \\(\\ldots\\) rainfc.11). The rownames are the end date of the 3 days over which the precipitation amounts are accumulated respectively; i.e., the respective forecasts are issued 8 days before these dates.\nIn previous studies it has been shown that it is of advantage to model the square root of precipitation rather than precipitation itself. Thus all precipitation amounts are square rooted before ensemble mean and standard deviation are derived. Furthermore, events with no variation in the ensemble are omitted:\n\nRainIbk &lt;- sqrt(RainIbk)\nRainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, mean)\nRainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc',names(RainIbk))], 1, sd)\nRainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\nA scatterplot of rain against ensmean\n\nplot(rain ~ ensmean, data = RainIbk, pch = 19, col = gray(0, alpha = 0.2))\nabline(0, 1, col = 2)\n\nindicates a linear relationship that differs from a 1-to-1 relationship (Figure 1). Precipitation is clearly non-negative with many zero observations. Thus censored regression or a two-part model are suitable to estimate this relationship.\nFirst we fit a logistic censored model for rain with ensmean as regressor for the location and log(enssd) as regressor for the scale.\n\nCRCH &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, \n  dist = \"logistic\")\nsummary(CRCH)\n## \n## Call:\n## crch(formula = rain ~ ensmean | log(enssd), data = RainIbk, \n##     dist = \"logistic\", left = 0)\n## \n## Standardized residuals:\n##    Min     1Q Median     3Q    Max \n## -3.578 -0.655  0.167  1.119  7.499 \n## \n## Coefficients (location model):\n##             Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)  -0.8527     0.0690   -12.3   &lt;2e-16 ***\n## ensmean       0.7869     0.0192    41.0   &lt;2e-16 ***\n## \n## Coefficients (scale model with log link):\n##             Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)   0.1174     0.0146    8.05  8.6e-16 ***\n## log(enssd)    0.2705     0.0350    7.72  1.1e-14 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n## \n## Distribution: logistic\n## Log-likelihood: -8.92e+03 on 4 Df\n## Number of iterations in BFGS optimization: 15\n\nBoth, ensmean and log(enssd) are highly significant according to the Wald test performed by the summary() method. The location model is also shown in Figure 1:\n\nabline(coef(CRCH)[1:2], col = 4)\n\n\n\n\n\n\n\n\nFigure 1: Square rooted precipitation amount against ensemble mean forecasts. A line with intercept 0 and slope 1 is shown in red and the censored regression fit in blue.\n\n\n\n\nIf we compare this model to a constant scale model (tobit model with logistic distribution)\n\nCR &lt;- crch(rain ~ ensmean, data = RainIbk, left = 0, dist = \"logistic\")\ncbind(AIC(CR, CRCH), BIC = BIC(CR, CRCH)[,2])\n##      df   AIC   BIC\n## CR    3 17906 17925\n## CRCH  4 17850 17876\n\nwe see that the scale model clearly improves the fit regarding AIC and BIC.\nA comparison of the logistic model with a Gaussian and a student-t model\n\nCRCHgau &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, \n  dist = \"gaussian\")\nCRCHstud &lt;- crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0, \n  dist = \"student\")\nAIC(CRCH, CRCHgau, CRCHstud)\n##          df   AIC\n## CRCH      4 17850\n## CRCHgau   4 17897\n## CRCHstud  5 17851\n\nconfirms the logistic distribution assumption. Note, that with the estimated degrees of freedom of 9.56 the student-t distribution resembles the (scaled) logistic distribution quite well (see Figure 2).\n\n\n\n\n\n\n\nFigure 2: Probability density functions of a student-t distribution with 9.56 degrees of freedom, a logistic, and a normal distribution. The densities of the logistic and normal distribution are scaled to facilitate comparison.\n\n\n\n\nIn the censored model the occurrence of precipitation and precipitation amount are assumed to be driven by the same process. To test this assumption we compare the censored model with a two-part model consisting of a heteroscedastic logit model and a truncated regression model with logistic distribution assumption. For the heteroscedastic logit model we use hetglm() from the glmx package and for the truncated model we employ the crch() function with the argument truncated = TRUE.\n\nlibrary(\"glmx\")\nBIN &lt;- hetglm(I(rain &gt; 0) ~ ensmean | log(enssd), data = RainIbk,\n  family = binomial(link = \"logit\"))\nTRCH &lt;- crch(rain~ensmean | log(enssd), data = RainIbk, subset = rain &gt; 0, \n  left = 0, dist = \"logistic\", truncated = TRUE)\n\nIn the heteroscedastic logit model, the intercept of the scale model is not identified. Thus, the location coefficients of the censored and truncated regression models have to be scaled to compare them with the logit model.\n\ncbind(\"CRCH\" = c(coef(CRCH, \"location\")/exp(coef(CRCH, \"scale\"))[1], \n    coef(CRCH, \"scale\")[2]), \n  \"BIN\" = coef(BIN), \n  \"TRCH\" = c(coef(TRCH, \"location\")/exp(coef(TRCH, \"scale\"))[1], \n    coef(TRCH, \"scale\")[2]))\n##                 CRCH      BIN    TRCH\n## (Intercept) -0.75818 -1.01817 0.26354\n## ensmean      0.69967  0.77891 0.54560\n## log(enssd)   0.27055  0.45399 0.23262\n\nThe different (scaled) coefficients indicate that different processes drive the occurrence of precipitation and precipitation amount. This is also confirmed by AIC and BIC that are clearly better for the two-part model than for the censored model:\n\nloglik &lt;- c(\"Censored\" = logLik(CRCH), \"Two-Part\" = logLik(BIN) + logLik(TRCH))\ndf &lt;- c(4, 7)\naic &lt;- -2 * loglik + 2 * df\nbic &lt;- -2 * loglik + log(nrow(RainIbk)) * df\ncbind(df, AIC = aic, BIC = bic)\n##          df   AIC   BIC\n## Censored  4 17850 17876\n## Two-Part  7 17745 17790\n\nFinally, we can use the fitted models to predict future precipitation. Therefore assume that the current NWP forecast of square rooted precipitation has an ensemble mean of 1.8 and an ensemble standard deviation of 0.9. A median precipitation forecast of the censored model can then easily be computed with\n\nnewdata &lt;- data.frame(ensmean = 1.8, enssd = 0.9)\npredict(CRCH, newdata, type = \"quantile\", at = 0.5)^2\n##       1 \n## 0.31774\n\nNote, that the prediction has to be squared since all models fit the square root of precipitation. In the two-part model the probability to stay below a threshold \\(q\\) is composed of\n\\[\n  P(y \\le q) = 1-P(y &gt; 0) + P(y&gt;0) \\cdot P(y \\le q|y&gt;0)\n\\]\nThus median precipitation equals the \\((P(y &gt; 0) - 0.5)/P(y&gt;0)\\)-quantile of the truncated distribution.\n\np &lt;- predict(BIN, newdata)\npredict(TRCH, newdata, type = \"quantile\", at = (p - 0.5)/p)^2\n##      1 \n## 0.4157\n\nProbabilities to exceed, e.g., 5mm can be predicted with cumulative distribution functions (e.g., pclogis(), ptlogis()) that are also provided in the crch package.\n\nmu &lt;- predict(CRCH, newdata, type = \"location\")\nsigma &lt;- predict(CRCH, newdata, type = \"scale\")\npclogis(sqrt(5), mu, sigma, lower.tail = FALSE, left = 0)\n## [1] 0.17798\n\nmu &lt;- predict(TRCH, newdata, type = \"location\")\nsigma &lt;- predict(TRCH, newdata, type = \"scale\")\np * ptlogis(sqrt(5), mu, sigma, lower.tail = FALSE, left = 0)\n##       1 \n## 0.21087\n\nNote, that pclogis() could also be replaced by plogis() since they are equivalent between \\(\\text{left}\\) and \\(\\text{right}\\).\nClearly, other types of model misspecification or model generalization (depending on the point of view) for the classical tobit model are possible. In addition to heteroscedasticity, the type of response distribution, and the presence of hurdle effects as explored in the application here, further aspects might have to be addressed by the model. Especially in economics and the social sciences sample selection effects might be present in the two-part model which can be addressed (in the homoscedastic normal case) using the R packages sampleSelection (Toomet and Henningsen 2008) or mhurdle (Croissant, Carlevaro, and Hoareau 2024). Furthermore, the scale link function or potential nonlinearities in the regression functions could be assessed, e.g., using the gamlss suite of packages (Stasinopoulos and Rigby 2007)."
  },
  {
    "objectID": "vignettes/crch.html#sec-summary",
    "href": "vignettes/crch.html#sec-summary",
    "title": "Heteroscedastic Censored and Truncated Regression with crch",
    "section": "\n5 Summary",
    "text": "5 Summary\nCensored and truncated response models are common in econometrics and other statistical applications. However, often the homoscedasticity assumption of these models is not fulfilled. This paper presented the crch package that provides functions to fit censored or truncated regression models with conditional heteroscedasticity. It supports Gaussian, logistic or student-t distributed censored or truncated responses and provides various convenient methods for analysis and prediction. To illustrate the package we showed that heteroscedastic censored and truncated models are well suited to improve precipitation forecasts."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Heteroscedastic Censored and Truncated Regression",
    "section": "Overview",
    "text": "Overview\nThe R package crch provides various regression models for continuous or mixed discrete-continuous data with right- and/or left-censoring or truncation of the response. The models use separate linear predictors for the mean/location and variance/scale parameters and can thus incorporate heteroscedasticity (conditional on regressors). This has prompted the package name crch (pronounced like search) which stands for censored regression with conditional heteroscedasticity.\nA number of different estimation methods can be used:\n\nMaximum likelihood estimation.\nMinimum CRPS estimation.\nBoosting and stability selection.\n\nThe underlying infrastructure for various probability distributions encompasses:\n\nCensored or truncated normal, logistic, and Student-t distributions.\nCorresponding d/p/q/r functions.\n\ndistributions3 objects.\n\nHeteroscedastic extended logistic regression (HXLR) via cumulative link models for ordinal data, obtained by interval-censoring continuous data, is also available."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Heteroscedastic Censored and Truncated Regression",
    "section": "Installation",
    "text": "Installation\nThe stable version of crch is available on CRAN:\ninstall.packages(\"crch\")\nThe latest development version can be installed from R-universe:\ninstall.packages(\"crch\", repos = \"https://zeileis.R-universe.dev\")"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Heteroscedastic Censored and Truncated Regression",
    "section": "License",
    "text": "License\nThe package is available under the General Public License version 3 or version 2"
  },
  {
    "objectID": "index.html#illustration",
    "href": "index.html#illustration",
    "title": "Heteroscedastic Censored and Truncated Regression",
    "section": "Illustration",
    "text": "Illustration\nAn illustration for censored regression from atmospheric sciences is rain forecasting. Here, the observed response data are 3 day-accumulated precipitation amounts over 13 years (2000–2013) at Innsbruck airport. The covariates are obtained from numerical weather predictions (GEFS reforecasts). Package and data can be loaded via:\n\nlibrary(\"crch\")\ndata(\"RainIbk\", package = \"crch\")\n\nEnsemble mean and standard deviation of the numerical rain forecasts are used as the regressors for mean and variance of the observations, respectively.\n\nRainIbk &lt;- sqrt(RainIbk)\nRainIbk$ensmean &lt;- apply(RainIbk[,grep('^rainfc', names(RainIbk))], 1, mean)\nRainIbk$enssd &lt;- apply(RainIbk[,grep('^rainfc', names(RainIbk))], 1, sd)\nRainIbk &lt;- subset(RainIbk, enssd &gt; 0)\n\nThen a classical homoscedastic linear regression is compared with a heteroscedastic logistic distributional regression, censored at zero to account for the point mass at zero (i.e., 3-day periods without rain).\n\nm_lm &lt;- lm(rain ~ ensmean, data = RainIbk)\nm_hclog &lt;- crch::crch(rain ~ ensmean | log(enssd), data = RainIbk, left = 0,\n  dist = \"logistic\")\n\nComparing the fitted regression lines shows that the censored model (in contrast to the classical linear regression) is able to capture a steeper regression line, i.e., a tighter relationship between rain forecasts and actual observations.\n\nplot(rain ~ ensmean, data = RainIbk, pch = 19, ylab = \"Rain\", col = gray(0, alpha = 0.2))\nabline(coef(m_lm)[1:2], col = 3, lwd = 4)\nabline(coef(m_hclog)[1:2], col = 4, lwd = 4)\nlegend(\"topright\", lwd = c(4, 4), lty = c(1, 1), col = c(3, 4),\n  c(\"m_lm\", \"m_hclog\"), bty = \"n\")\n\n\n\n\n\n\n\nThe summary output of the censored model shows that not only the mean of the rain observations but also their standard deviation significantly depends on the corresponding quantities from the numerical weather prediction ensemble.\n\nsummary(m_hclog)\n## \n## Call:\n## crch::crch(formula = rain ~ ensmean | log(enssd), data = RainIbk, dist = \"logistic\", \n##     left = 0)\n## \n## Standardized residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.5780 -0.6554  0.1673  1.1189  7.4990 \n## \n## Coefficients (location model):\n##             Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept) -0.85266    0.06903  -12.35   &lt;2e-16 ***\n## ensmean      0.78686    0.01921   40.97   &lt;2e-16 ***\n## \n## Coefficients (scale model with log link):\n##             Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)  0.11744    0.01460   8.046 8.58e-16 ***\n## log(enssd)   0.27055    0.03503   7.723 1.14e-14 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n## \n## Distribution: logistic\n## Log-likelihood: -8921 on 4 Df\n## Number of iterations in BFGS optimization: 15"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "To report bugs please send a simple e-mail to the package maintainer:\nAchim.Zeileis at R-project dot org\nFor inquiries you can also reach out on social media:\n@zeileis@fosstodon.org (Mastodon)\n@AchimZeileis (X/Twitter)\nFor discussions we also try to follow these channels:\n\nCrossValidated with tobit-regression tag\nR-help mailing list\n\n\n\n\n\nAchim Zeileis  \nJakob W. Messner \nReto Stauffer  \nIoannis Kosmidis  \nGeorg J. Mayr"
  },
  {
    "objectID": "contact.html#reporting-bugs",
    "href": "contact.html#reporting-bugs",
    "title": "Contact",
    "section": "",
    "text": "To report bugs please send a simple e-mail to the package maintainer:\nAchim.Zeileis at R-project dot org\nFor inquiries you can also reach out on social media:\n@zeileis@fosstodon.org (Mastodon)\n@AchimZeileis (X/Twitter)\nFor discussions we also try to follow these channels:\n\nCrossValidated with tobit-regression tag\nR-help mailing list"
  },
  {
    "objectID": "contact.html#authors-and-contributors",
    "href": "contact.html#authors-and-contributors",
    "title": "Contact",
    "section": "",
    "text": "Achim Zeileis  \nJakob W. Messner \nReto Stauffer  \nIoannis Kosmidis  \nGeorg J. Mayr"
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite crch in publications use:\n\nMessner JW, Mayr GJ, Zeileis A (2016). “Heteroscedastic Censored and Truncated Regression with crch.” The R Journal, 8(1), 173–181. doi:10.32614/RJ-2016-012.\n\nIf you use crch.boost() please also cite:\n\nMessner JW, Mayr GJ, Zeileis A (2017). “Non-Homogeneous Boosting for Predictor Selection in Ensemble Post-Processing.” Monthly Weather Review, 145(1), 137–147. doi:10.1175/MWR-D-16-0088.1.\n\nIf you use crch() please also cite:\n\nMessner JW, Zeileis A, Broecker J, Mayr GJ (2014). “Probabilistic Wind Power Forecasts with an Inverse Power Curve Transformation and Censored Regression.” Wind Energy, 17(11), 1753–1766. doi:10.1002/we.1666.\n\nIf you use hxlr() please cite:\n\nMessner JW, Mayr GJ, Zeileis A, Wilks DS (2014). “Heteroscedastic Extended Logistic Regression for Postprocessing of Ensemble Guidance.” Monthly Weather Review, 142(1), 448–456. doi:10.1175/MWR-D-13-00271.1."
  },
  {
    "objectID": "man/CensoredStudentsT.html",
    "href": "man/CensoredStudentsT.html",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-censored t distributions using the workflow from the distributions3 package.\n\nCensoredStudentsT(df, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\ndf\n\n\nnumeric. The degrees of freedom of the underlying uncensored t distribution. Can be any positive number, with df = Inf corresponding to the normal distribution.\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying uncensored t distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying uncensored t distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left censoring point. Can be any real number, defaults to -Inf (uncensored). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the uncensored t distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right censoring point. Can be any real number, defaults to Inf (uncensored). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the uncensored t distribution at this point.\n\n\n\nThe constructor function CensoredStudentsT sets up a distribution object, representing the censored t probability distribution by the corresponding parameters: the degrees of freedom df, the latent mean location = \\(\\mu\\) and latent scale parameter scale = \\(\\sigma\\) (i.e., the parameters of the underlying uncensored t variable), the left censoring point (with -Inf corresponding to uncensored), and the right censoring point (with Inf corresponding to uncensored).\nThe censored t distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\n\\(T((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - T((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\tau((x - \\mu)/\\sigma)/\\sigma\\)\n\n\notherwise\n\n\n\nwhere \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the standard t distribution with df degrees of freedom, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of censored t distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the CensoredStudentsT distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the censored t distributions in the crch package, see dct, and the crps_ct function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (only TRUE if there is no censoring, i.e., if both left and right are infinite).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA CensoredStudentsT distribution object.\n\ndct, StudentsT, TruncatedStudentsT, CensoredNormal, CensoredLogistic\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three censored t distributions:\n## - uncensored standard t with 5 degrees of freedom\n## - left-censored at zero with 5 df, latent location = 1 and scale = 1\n## - interval-censored in [0, 5] with 5 df, latent location = 2 and scale = 2\nX &lt;- CensoredStudentsT(\n  df       = c(   5,   5, 5),\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 2),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"CensoredStudentsT(df = 5, location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"CensoredStudentsT(df = 5, location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"CensoredStudentsT(df = 5, location = 2, scale = 2, left =    0, right =   5)\"\n\n## compute mean of the censored distribution\nmean(X)\n\n[1] 0.000000 1.147911 2.135302\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1        r_2        r_3        r_4       r_5\n[1,] -0.329754 -0.7100405 0.01721632 -0.2439421 0.4039513\n[2,]  1.880227  1.2620058 1.04606093  1.0363624 2.3830650\n[3,]  1.840700  0.1924168 1.99666405  0.0000000 1.6668390\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"uncensored\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-censored at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-censored in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3796067 0.1816087 0.1639593\n\npdf(X, x, log = TRUE)\n\n[1] -0.9686196 -1.7059007 -1.8081373\n\nlog_pdf(X, x)\n\n[1] -0.9686196 -1.7059007 -1.8081373\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.1816087 0.3191494\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0 1 2\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n        q_0.05 q_0.5   q_0.95\n[1,] -2.015048     0 2.015048\n[2,]  0.000000     1 3.015048\n[3,]  0.000000     2 5.000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.015048  1.000000  5.000000\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.015048\n[2,]  1.000000\n[3,]  5.000000\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 0.07350449\n[2,]    1.147911 1.12643481\n[3,]    2.135302 2.14667243\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1]        Inf 0.00000000 0.06200845",
    "crumbs": [
      "distributions3 objects",
      "CensoredStudentsT"
    ]
  },
  {
    "objectID": "man/CensoredStudentsT.html#create-a-censored-students-t-distribution",
    "href": "man/CensoredStudentsT.html#create-a-censored-students-t-distribution",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-censored t distributions using the workflow from the distributions3 package.\n\nCensoredStudentsT(df, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\ndf\n\n\nnumeric. The degrees of freedom of the underlying uncensored t distribution. Can be any positive number, with df = Inf corresponding to the normal distribution.\n\n\n\n\nlocation\n\n\nnumeric. The location parameter of the underlying uncensored t distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nscale\n\n\nnumeric. The scale parameter (standard deviation) of the underlying uncensored t distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left censoring point. Can be any real number, defaults to -Inf (uncensored). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the uncensored t distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right censoring point. Can be any real number, defaults to Inf (uncensored). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the uncensored t distribution at this point.\n\n\n\nThe constructor function CensoredStudentsT sets up a distribution object, representing the censored t probability distribution by the corresponding parameters: the degrees of freedom df, the latent mean location = \\(\\mu\\) and latent scale parameter scale = \\(\\sigma\\) (i.e., the parameters of the underlying uncensored t variable), the left censoring point (with -Inf corresponding to uncensored), and the right censoring point (with Inf corresponding to uncensored).\nThe censored t distribution has probability density function (PDF) \\(f(x)\\):\n\n\n\n\\(T((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - T((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\tau((x - \\mu)/\\sigma)/\\sigma\\)\n\n\notherwise\n\n\n\nwhere \\(T\\) and \\(\\tau\\) are the cumulative distribution function and probability density function of the standard t distribution with df degrees of freedom, respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of censored t distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the CensoredStudentsT distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the censored t distributions in the crch package, see dct, and the crps_ct function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (only TRUE if there is no censoring, i.e., if both left and right are infinite).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA CensoredStudentsT distribution object.\n\ndct, StudentsT, TruncatedStudentsT, CensoredNormal, CensoredLogistic\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three censored t distributions:\n## - uncensored standard t with 5 degrees of freedom\n## - left-censored at zero with 5 df, latent location = 1 and scale = 1\n## - interval-censored in [0, 5] with 5 df, latent location = 2 and scale = 2\nX &lt;- CensoredStudentsT(\n  df       = c(   5,   5, 5),\n  location = c(   0,   1, 2),\n  scale    = c(   1,   1, 2),\n  left     = c(-Inf,   0, 0),\n  right    = c( Inf, Inf, 5)\n)\nX\n\n[1] \"CensoredStudentsT(df = 5, location = 0, scale = 1, left = -Inf, right = Inf)\"\n[2] \"CensoredStudentsT(df = 5, location = 1, scale = 1, left =    0, right = Inf)\"\n[3] \"CensoredStudentsT(df = 5, location = 2, scale = 2, left =    0, right =   5)\"\n\n## compute mean of the censored distribution\nmean(X)\n\n[1] 0.000000 1.147911 2.135302\n\n## higher moments (variance, skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n           r_1        r_2        r_3        r_4       r_5\n[1,] -0.329754 -0.7100405 0.01721632 -0.2439421 0.4039513\n[2,]  1.880227  1.2620058 1.04606093  1.0363624 2.3830650\n[3,]  1.840700  0.1924168 1.99666405  0.0000000 1.6668390\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"uncensored\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-censored at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-censored in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3796067 0.1816087 0.1639593\n\npdf(X, x, log = TRUE)\n\n[1] -0.9686196 -1.7059007 -1.8081373\n\nlog_pdf(X, x)\n\n[1] -0.9686196 -1.7059007 -1.8081373\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.1816087 0.3191494\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0 1 2\n\n## cdf() and quantile() are inverses (except at censoring points)\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n        q_0.05 q_0.5   q_0.95\n[1,] -2.015048     0 2.015048\n[2,]  0.000000     1 3.015048\n[3,]  0.000000     2 5.000000\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -2.015048  1.000000  5.000000\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -2.015048\n[2,]  1.000000\n[3,]  5.000000\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical  empirical\n[1,]    0.000000 0.07350449\n[2,]    1.147911 1.12643481\n[3,]    2.135302 2.14667243\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1]        Inf 0.00000000 0.06200845",
    "crumbs": [
      "distributions3 objects",
      "CensoredStudentsT"
    ]
  },
  {
    "objectID": "man/coef.hxlr.html",
    "href": "man/coef.hxlr.html",
    "title": "crch",
    "section": "",
    "text": "Methods for extracting information from fitted hxlr objects.\n\n\n\n## S3 method for class 'hxlr'\ncoef(object, model = c(\"full\", \"intercept\", \"location\", \"scale\"),\n  type = c(\"CLM\", \"latent\"), ...)\n## S3 method for class 'hxlr'\nvcov(object, model = c(\"full\", \"intercept\", \"location\", \"scale\"), \n  type = c(\"CLM\", \"latent\"), ...)\n## S3 method for class 'hxlr'\nterms(x, model = c(\"full\", \"location\", \"scale\"), ...)\n\n\n\n\n\n\n\nobject, x\n\n\nan object of class “hxlr”.\n\n\n\n\nmodel\n\n\nmodel for which coefficients shall be returned.\n\n\n\n\ntype\n\n\ntype of coefficients. Default are CLM type coefficients. For type “latent” coefficients are converted in coefficients for location and scale of the latent distribution (analog to crch models).\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nIn addition to the methods above, a set of standard extractor functions for “hxlr” objects is available, including methods to the generic functions print, summary, and logLik.\n\n\n\nhxlr",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "coef.hxlr"
    ]
  },
  {
    "objectID": "man/coef.hxlr.html#methods-for-fitted-hxlr-models",
    "href": "man/coef.hxlr.html#methods-for-fitted-hxlr-models",
    "title": "crch",
    "section": "",
    "text": "Methods for extracting information from fitted hxlr objects.\n\n\n\n## S3 method for class 'hxlr'\ncoef(object, model = c(\"full\", \"intercept\", \"location\", \"scale\"),\n  type = c(\"CLM\", \"latent\"), ...)\n## S3 method for class 'hxlr'\nvcov(object, model = c(\"full\", \"intercept\", \"location\", \"scale\"), \n  type = c(\"CLM\", \"latent\"), ...)\n## S3 method for class 'hxlr'\nterms(x, model = c(\"full\", \"location\", \"scale\"), ...)\n\n\n\n\n\n\n\nobject, x\n\n\nan object of class “hxlr”.\n\n\n\n\nmodel\n\n\nmodel for which coefficients shall be returned.\n\n\n\n\ntype\n\n\ntype of coefficients. Default are CLM type coefficients. For type “latent” coefficients are converted in coefficients for location and scale of the latent distribution (analog to crch models).\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nIn addition to the methods above, a set of standard extractor functions for “hxlr” objects is available, including methods to the generic functions print, summary, and logLik.\n\n\n\nhxlr",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "coef.hxlr"
    ]
  },
  {
    "objectID": "man/tnorm.html",
    "href": "man/tnorm.html",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right truncated normal distribution.\n\n\n\ndtnorm(x, mean = 0, sd = 1, left = -Inf, right = Inf, log = FALSE)\n\nptnorm(q, mean = 0, sd = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqtnorm(p, mean = 0, sd = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nrtnorm(n, mean = 0, sd = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmean\n\n\nvector of means.\n\n\n\n\nsd\n\n\nvector of standard deviations.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf mean or sd are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe truncated normal distribution has density\n\nf(x) = 1/((x - )/) / (((right - )/) - ((left - )/))\nfor \\(left \\le x \\le right\\), and 0 otherwise.\n\\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively, \\(\\mu\\) is the mean of the distribution, and \\(\\sigma\\) the standard deviation.\n\n\n\ndtnorm gives the density, ptnorm gives the distribution function, qtnorm gives the quantile function, and rtnorm generates random deviates.\n\n\n\ndnorm",
    "crumbs": [
      "Distributions",
      "tnorm"
    ]
  },
  {
    "objectID": "man/tnorm.html#the-truncated-normal-distribution",
    "href": "man/tnorm.html#the-truncated-normal-distribution",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right truncated normal distribution.\n\n\n\ndtnorm(x, mean = 0, sd = 1, left = -Inf, right = Inf, log = FALSE)\n\nptnorm(q, mean = 0, sd = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqtnorm(p, mean = 0, sd = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nrtnorm(n, mean = 0, sd = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nmean\n\n\nvector of means.\n\n\n\n\nsd\n\n\nvector of standard deviations.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf mean or sd are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe truncated normal distribution has density\n\nf(x) = 1/((x - )/) / (((right - )/) - ((left - )/))\nfor \\(left \\le x \\le right\\), and 0 otherwise.\n\\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively, \\(\\mu\\) is the mean of the distribution, and \\(\\sigma\\) the standard deviation.\n\n\n\ndtnorm gives the density, ptnorm gives the distribution function, qtnorm gives the quantile function, and rtnorm generates random deviates.\n\n\n\ndnorm",
    "crumbs": [
      "Distributions",
      "tnorm"
    ]
  },
  {
    "objectID": "man/tlogis.html",
    "href": "man/tlogis.html",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right truncated logistic distribution.\n\n\n\ndtlogis(x, location = 0, scale = 1, left = -Inf, right = Inf, log = FALSE)\n\nptlogis(q, location = 0, scale = 1, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nqtlogis(p, location = 0, scale = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nrtlogis(n, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\nleft\n\n\nleft truncation point.\n\n\n\n\nright\n\n\nright truncation point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe truncated logistic distribution has density\n\n\\(f(x) = 1/\\sigma \\lambda((x - \\mu)/\\sigma) / (\\Lambda((right - \\mu)/\\sigma) - \\Lambda((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise.\n\\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndtlogis gives the density, ptlogis gives the distribution function, qtlogis gives the quantile function, and rtlogis generates random deviates.\n\n\n\ndlogis",
    "crumbs": [
      "Distributions",
      "tlogis"
    ]
  },
  {
    "objectID": "man/tlogis.html#the-truncated-logistic-distribution",
    "href": "man/tlogis.html#the-truncated-logistic-distribution",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right truncated logistic distribution.\n\n\n\ndtlogis(x, location = 0, scale = 1, left = -Inf, right = Inf, log = FALSE)\n\nptlogis(q, location = 0, scale = 1, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nqtlogis(p, location = 0, scale = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nrtlogis(n, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\nleft\n\n\nleft truncation point.\n\n\n\n\nright\n\n\nright truncation point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe truncated logistic distribution has density\n\n\\(f(x) = 1/\\sigma \\lambda((x - \\mu)/\\sigma) / (\\Lambda((right - \\mu)/\\sigma) - \\Lambda((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise.\n\\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndtlogis gives the density, ptlogis gives the distribution function, qtlogis gives the quantile function, and rtlogis generates random deviates.\n\n\n\ndlogis",
    "crumbs": [
      "Distributions",
      "tlogis"
    ]
  },
  {
    "objectID": "man/predict.crch.html",
    "href": "man/predict.crch.html",
    "title": "crch",
    "section": "",
    "text": "Obtains various types of predictions for crch models.\n\n\n\n## S3 method for class 'crch'\npredict(object, newdata = NULL, type = c(\"location\", \"scale\", \n  \"response\", \"parameter\", \"density\", \"probability\", \"quantile\", \"crps\"), \n  na.action = na.pass, at = 0.5, left = NULL, right = NULL, ...)\n\n## S3 method for class 'crch'\nprodist(object, newdata = NULL, na.action = na.pass,\n  left = NULL, right = NULL, ...)\n\n\n\n\n\n\n\nobject\n\n\nan object of class “crch”.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict.\n\n\n\n\ntype\n\n\ntype of prediction: “location” returns the location of the predicted distribution. “scale” returns the scale of the predicted distribution. “response” returns the expected value of the predicted distribution (not equal to location for censored and truncated distributions). “parameter” returns a data frame with predicted location and scale parameters. “density” evaluates the predictive density at at. “probability” evaluates the predictive CDF at at. “quantile” returns a matrix of predicted quantiles with quantile probabilities at. “crps” returns the CRPS of the predictive distributions at at.\n\n\n\n\nna.action\n\n\na function which indicates what should happen when the data contain NAs. Default is na.pass\n\n\n\n\nat\n\n\na vector of values to evaluate the predictive density (type = “density”), probability (type = “probability”), or CRPS (type = “crps”) or a vector of quantile probabilities used for type = “quantile”. Alternatively, with at = “function” a function is returned that takes at as an argument.\n\n\n\n\nleft\n\n\nleft censoring or truncation point. Only used for type = “quantile”. If NULL, censoring or truncation point is obtained from object.\n\n\n\n\nright\n\n\nright censoring or truncation point. Only used for type = “quantile”. If NULL, censoring or truncation point is obtained from object.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nThe predict method, for type “response”, “location”, or “scale”, returns a vector with either the location or the scale of the predicted distribution. For type “quantile” a matrix of predicted quantiles each column corresponding to an element of at.\nThe prodist method returns the fitted/predict probability distribution object.\n\n\n\ncrch, prodist",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "predict.crch"
    ]
  },
  {
    "objectID": "man/predict.crch.html#predictions-for-fitted-crch-models",
    "href": "man/predict.crch.html#predictions-for-fitted-crch-models",
    "title": "crch",
    "section": "",
    "text": "Obtains various types of predictions for crch models.\n\n\n\n## S3 method for class 'crch'\npredict(object, newdata = NULL, type = c(\"location\", \"scale\", \n  \"response\", \"parameter\", \"density\", \"probability\", \"quantile\", \"crps\"), \n  na.action = na.pass, at = 0.5, left = NULL, right = NULL, ...)\n\n## S3 method for class 'crch'\nprodist(object, newdata = NULL, na.action = na.pass,\n  left = NULL, right = NULL, ...)\n\n\n\n\n\n\n\nobject\n\n\nan object of class “crch”.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict.\n\n\n\n\ntype\n\n\ntype of prediction: “location” returns the location of the predicted distribution. “scale” returns the scale of the predicted distribution. “response” returns the expected value of the predicted distribution (not equal to location for censored and truncated distributions). “parameter” returns a data frame with predicted location and scale parameters. “density” evaluates the predictive density at at. “probability” evaluates the predictive CDF at at. “quantile” returns a matrix of predicted quantiles with quantile probabilities at. “crps” returns the CRPS of the predictive distributions at at.\n\n\n\n\nna.action\n\n\na function which indicates what should happen when the data contain NAs. Default is na.pass\n\n\n\n\nat\n\n\na vector of values to evaluate the predictive density (type = “density”), probability (type = “probability”), or CRPS (type = “crps”) or a vector of quantile probabilities used for type = “quantile”. Alternatively, with at = “function” a function is returned that takes at as an argument.\n\n\n\n\nleft\n\n\nleft censoring or truncation point. Only used for type = “quantile”. If NULL, censoring or truncation point is obtained from object.\n\n\n\n\nright\n\n\nright censoring or truncation point. Only used for type = “quantile”. If NULL, censoring or truncation point is obtained from object.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nThe predict method, for type “response”, “location”, or “scale”, returns a vector with either the location or the scale of the predicted distribution. For type “quantile” a matrix of predicted quantiles each column corresponding to an element of at.\nThe prodist method returns the fitted/predict probability distribution object.\n\n\n\ncrch, prodist",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "predict.crch"
    ]
  },
  {
    "objectID": "man/hxlr.html",
    "href": "man/hxlr.html",
    "title": "crch",
    "section": "",
    "text": "This is a wrapper function for clm (from package ordinal) to fit (heteroscedastic) extended logistic regression (HXLR) models (Messner et al. 2013).\n\nhxlr(formula, data, subset, na.action, weights, thresholds, link, control, ...)\n\n\n\n\n\nformula\n\n\na formula expression of the form y ~ x | z where y is the response and x and z are regressor variables for the location and the scale of the latend distribution respectively. Response can either be a continuous variable or a factor.\n\n\n\n\ndata\n\n\nan optional data frame containing the variables occurring in the formulas.\n\n\n\n\nsubset\n\n\nan optional vector specifying a subset of observations to be used for fitting.\n\n\n\n\nna.action\n\n\na function which indicates what should happen when the data contain NAs. Default is na.omit\n\n\n\n\nweights\n\n\noptional case weights in fitting.\n\n\n\n\nthresholds\n\n\nvector of (transformed) thresholds that are used to cut the continuous response into categories. Data frames or matrices with multiple columns are allowed as well. Then each column is used as separate predictor variable for the intercept model.\n\n\n\n\nlink\n\n\nlink function, i.e., the type of location-scale distribution assumed for the latent distribution. Default is logit.\n\n\n\n\ncontrol\n\n\na list of control parameters passed to optim. Default is hxlr.control\n\n\n\n\n…\n\n\narguments to be used to form the default control argument if it is not supplied directly.\n\n\n\nExtended logistic regression (Wilks 2009) extends binary logistic regression to multi-category responses by including the thresholds, that are used to cut a continuous variable into categories, in the regression equation. Heteroscedastic extended logistic regression (Messner et al. 2013) extends this model further and allows to add additional predictor variables that are used to predict the scale of the latent logistic distribution.\n\nAn object of class “hxlr”, i.e., a list with the following elements.\n\n\n\ncoefficients\n\n\nlist of CLM coefficients for intercept, location, and scale model.\n\n\n\n\nfitted.values\n\n\nlist of fitted location and scale parameters.\n\n\n\n\noptim\n\n\noutput from optimization from optim.\n\n\n\n\nmethod\n\n\nOptimization method used for optim.\n\n\n\n\ncontrol\n\n\nlist of control parameters passed to optim\n\n\n\n\nstart\n\n\nstarting values of coefficients used in the optimization.\n\n\n\n\nweights\n\n\ncase weights used for fitting.\n\n\n\n\nn\n\n\nnumber of observations.\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights.\n\n\n\n\nloglik\n\n\nlog-likelihood.\n\n\n\n\nvcov\n\n\ncovariance matrix.\n\n\n\n\nconverged\n\n\nlogical variable whether optimization has converged or not.\n\n\n\n\niterations\n\n\nnumber of iterations in optimization.\n\n\n\n\ncall\n\n\nfunction call.\n\n\n\n\nscale\n\n\nthe formula supplied.\n\n\n\n\nterms\n\n\nthe terms objects used.\n\n\n\n\nlevels\n\n\nlist of levels of the factors used in fitting for location and scale respectively.\n\n\n\n\nthresholds\n\n\nthe thresholds supplied.\n\n\n\nMessner JW, Mayr GJ, Zeileis A, Wilks DS (2014). Extending Extended Logistic Regression to Effectively Utilize the Ensemble Spread. Monthly Weather Review, 142, 448–456. doi:10.1175/MWR-D-13-00271.1.\nWilks DS (2009). Extending Logistic Regression to Provide Full-Probability-Distribution MOS Forecasts. Meteorological Applications, 368, 361–368.\n\npredict.hxlr, clm\n\n\nlibrary(\"crch\")\n\ndata(\"RainIbk\", package = \"crch\")\n## mean and standard deviation of square root transformed ensemble forecasts\nRainIbk$sqrtensmean &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, mean)\nRainIbk$sqrtenssd &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, sd)\n\n## climatological deciles\nq &lt;- unique(quantile(RainIbk$rain, seq(0.1, 0.9, 0.1)))\n\n## fit ordinary extended logistic regression with ensemble mean as \n## predictor variable\nXLR &lt;- hxlr(sqrt(rain) ~ sqrtensmean, data = RainIbk, thresholds = sqrt(q))\n## print\nXLR\n## summary\nsummary(XLR)\n\n\n## fit ordinary extended logistic regression with ensemble mean \n## and standard deviation as predictor variables\nXLRS &lt;- hxlr(sqrt(rain) ~ sqrtensmean + sqrtenssd, data = RainIbk, \n  thresholds = sqrt(q))\n## fit heteroscedastic extended logistic regression with ensemble \n## standard deviation as predictor for the scale\nHXLR &lt;- hxlr(sqrt(rain) ~ sqrtensmean | sqrtenssd, data = RainIbk, \n  thresholds = sqrt(q))\n\n## compare AIC of different models\nAIC(XLR, XLRS, HXLR)\n\n## XLRS and HXLR are nested in XLR -&gt; likelihood-ratio-tests\nif(require(\"lmtest\")) {\n  lrtest(XLR, XLRS)\n  lrtest(XLR, HXLR)\n}\n\n###################################################################\n## Cross-validation and bootstrapping RPS for different models \n## (like in Messner 2013). \nN &lt;- NROW(RainIbk)\n## function that returns model fits\nfits &lt;- function(data, weights = rep(1, N)) {\n  list(\n    \"XLR\"    = hxlr(sqrt(rain) ~ sqrtensmean, data = data, \n      weights = weights, thresholds = sqrt(q)),\n    \"XLR:S\"  = hxlr(sqrt(rain) ~ sqrtensmean + sqrtenssd, data = data, \n      weights = weights, thresholds = sqrt(q)),\n    \"XLR:SM\" = hxlr(sqrt(rain) ~ sqrtensmean + I(sqrtensmean*sqrtenssd), \n      data = data, weights = weights, thresholds = sqrt(q)),\n    \"HXLR\"   = hxlr(sqrt(rain) ~ sqrtensmean | sqrtenssd, data = data, \n      weights = weights, thresholds = sqrt(q)),\n    \"HXLR:S\" = hxlr(sqrt(rain) ~ sqrtensmean + sqrtenssd | sqrtenssd, \n      data = data, weights = weights, thresholds = sqrt(q))\n  )\n}\n\n\n## cross validation\nid &lt;- sample(1:10, N, replace = TRUE)\nobs &lt;- NULL\npred &lt;- list(NULL)\nfor(i in 1:10) {\n  ## splitting into test and training data set\n  trainIndex &lt;- which(id != i)     \n  testIndex &lt;- which(id == i)                \n  ## weights that are used for fitting the models\n  weights &lt;- as.numeric(table(factor(trainIndex, levels = c(1:N))))\n  ## testdata\n  testdata &lt;- RainIbk[testIndex,]\n  ## observations    \n  obs &lt;- c(obs, RainIbk$rain[testIndex])\n  ## estimation\n  modelfits &lt;- fits(RainIbk, weights)\n  ## Prediction\n  pred2 &lt;- lapply(modelfits, predict, newdata = testdata, type = \"cumprob\")\n  pred &lt;- mapply(rbind, pred, pred2, SIMPLIFY = FALSE)\n}\nnames(pred) &lt;- c(names(modelfits))\n\n## function to compute RPS\nrps &lt;- function(pred, obs) {\n  OBS &lt;- NULL\n  for(i in 1:N) \n    OBS &lt;- rbind(OBS, rep(0:1, c(obs[i] - 1, length(q) - obs[i] + 1)))\n  apply((OBS-pred)^2, 1, sum)\n}\n\n## compute rps\nRPS &lt;- lapply(pred, rps, obs = as.numeric(cut(obs, c(-Inf, q, Inf))))\n\n## bootstrapping mean rps \nrpsall &lt;- NULL\nfor(i in 1:250) {\n  index &lt;- sample(length(obs), replace = TRUE)\n  rpsall &lt;- rbind(rpsall, sapply(RPS, function(x) mean(x[index])))\n}\n  \nrpssall &lt;- 1 - rpsall/rpsall[,1]\nboxplot(rpssall[,-1], ylab = \"RPSS\", main = \"RPSS relative to XLR\")\nabline(h = 0, lty = 2)",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "hxlr"
    ]
  },
  {
    "objectID": "man/hxlr.html#heteroscedastic-extended-logistic-regression",
    "href": "man/hxlr.html#heteroscedastic-extended-logistic-regression",
    "title": "crch",
    "section": "",
    "text": "This is a wrapper function for clm (from package ordinal) to fit (heteroscedastic) extended logistic regression (HXLR) models (Messner et al. 2013).\n\nhxlr(formula, data, subset, na.action, weights, thresholds, link, control, ...)\n\n\n\n\n\nformula\n\n\na formula expression of the form y ~ x | z where y is the response and x and z are regressor variables for the location and the scale of the latend distribution respectively. Response can either be a continuous variable or a factor.\n\n\n\n\ndata\n\n\nan optional data frame containing the variables occurring in the formulas.\n\n\n\n\nsubset\n\n\nan optional vector specifying a subset of observations to be used for fitting.\n\n\n\n\nna.action\n\n\na function which indicates what should happen when the data contain NAs. Default is na.omit\n\n\n\n\nweights\n\n\noptional case weights in fitting.\n\n\n\n\nthresholds\n\n\nvector of (transformed) thresholds that are used to cut the continuous response into categories. Data frames or matrices with multiple columns are allowed as well. Then each column is used as separate predictor variable for the intercept model.\n\n\n\n\nlink\n\n\nlink function, i.e., the type of location-scale distribution assumed for the latent distribution. Default is logit.\n\n\n\n\ncontrol\n\n\na list of control parameters passed to optim. Default is hxlr.control\n\n\n\n\n…\n\n\narguments to be used to form the default control argument if it is not supplied directly.\n\n\n\nExtended logistic regression (Wilks 2009) extends binary logistic regression to multi-category responses by including the thresholds, that are used to cut a continuous variable into categories, in the regression equation. Heteroscedastic extended logistic regression (Messner et al. 2013) extends this model further and allows to add additional predictor variables that are used to predict the scale of the latent logistic distribution.\n\nAn object of class “hxlr”, i.e., a list with the following elements.\n\n\n\ncoefficients\n\n\nlist of CLM coefficients for intercept, location, and scale model.\n\n\n\n\nfitted.values\n\n\nlist of fitted location and scale parameters.\n\n\n\n\noptim\n\n\noutput from optimization from optim.\n\n\n\n\nmethod\n\n\nOptimization method used for optim.\n\n\n\n\ncontrol\n\n\nlist of control parameters passed to optim\n\n\n\n\nstart\n\n\nstarting values of coefficients used in the optimization.\n\n\n\n\nweights\n\n\ncase weights used for fitting.\n\n\n\n\nn\n\n\nnumber of observations.\n\n\n\n\nnobs\n\n\nnumber of observations with non-zero weights.\n\n\n\n\nloglik\n\n\nlog-likelihood.\n\n\n\n\nvcov\n\n\ncovariance matrix.\n\n\n\n\nconverged\n\n\nlogical variable whether optimization has converged or not.\n\n\n\n\niterations\n\n\nnumber of iterations in optimization.\n\n\n\n\ncall\n\n\nfunction call.\n\n\n\n\nscale\n\n\nthe formula supplied.\n\n\n\n\nterms\n\n\nthe terms objects used.\n\n\n\n\nlevels\n\n\nlist of levels of the factors used in fitting for location and scale respectively.\n\n\n\n\nthresholds\n\n\nthe thresholds supplied.\n\n\n\nMessner JW, Mayr GJ, Zeileis A, Wilks DS (2014). Extending Extended Logistic Regression to Effectively Utilize the Ensemble Spread. Monthly Weather Review, 142, 448–456. doi:10.1175/MWR-D-13-00271.1.\nWilks DS (2009). Extending Logistic Regression to Provide Full-Probability-Distribution MOS Forecasts. Meteorological Applications, 368, 361–368.\n\npredict.hxlr, clm\n\n\nlibrary(\"crch\")\n\ndata(\"RainIbk\", package = \"crch\")\n## mean and standard deviation of square root transformed ensemble forecasts\nRainIbk$sqrtensmean &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, mean)\nRainIbk$sqrtenssd &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, sd)\n\n## climatological deciles\nq &lt;- unique(quantile(RainIbk$rain, seq(0.1, 0.9, 0.1)))\n\n## fit ordinary extended logistic regression with ensemble mean as \n## predictor variable\nXLR &lt;- hxlr(sqrt(rain) ~ sqrtensmean, data = RainIbk, thresholds = sqrt(q))\n## print\nXLR\n## summary\nsummary(XLR)\n\n\n## fit ordinary extended logistic regression with ensemble mean \n## and standard deviation as predictor variables\nXLRS &lt;- hxlr(sqrt(rain) ~ sqrtensmean + sqrtenssd, data = RainIbk, \n  thresholds = sqrt(q))\n## fit heteroscedastic extended logistic regression with ensemble \n## standard deviation as predictor for the scale\nHXLR &lt;- hxlr(sqrt(rain) ~ sqrtensmean | sqrtenssd, data = RainIbk, \n  thresholds = sqrt(q))\n\n## compare AIC of different models\nAIC(XLR, XLRS, HXLR)\n\n## XLRS and HXLR are nested in XLR -&gt; likelihood-ratio-tests\nif(require(\"lmtest\")) {\n  lrtest(XLR, XLRS)\n  lrtest(XLR, HXLR)\n}\n\n###################################################################\n## Cross-validation and bootstrapping RPS for different models \n## (like in Messner 2013). \nN &lt;- NROW(RainIbk)\n## function that returns model fits\nfits &lt;- function(data, weights = rep(1, N)) {\n  list(\n    \"XLR\"    = hxlr(sqrt(rain) ~ sqrtensmean, data = data, \n      weights = weights, thresholds = sqrt(q)),\n    \"XLR:S\"  = hxlr(sqrt(rain) ~ sqrtensmean + sqrtenssd, data = data, \n      weights = weights, thresholds = sqrt(q)),\n    \"XLR:SM\" = hxlr(sqrt(rain) ~ sqrtensmean + I(sqrtensmean*sqrtenssd), \n      data = data, weights = weights, thresholds = sqrt(q)),\n    \"HXLR\"   = hxlr(sqrt(rain) ~ sqrtensmean | sqrtenssd, data = data, \n      weights = weights, thresholds = sqrt(q)),\n    \"HXLR:S\" = hxlr(sqrt(rain) ~ sqrtensmean + sqrtenssd | sqrtenssd, \n      data = data, weights = weights, thresholds = sqrt(q))\n  )\n}\n\n\n## cross validation\nid &lt;- sample(1:10, N, replace = TRUE)\nobs &lt;- NULL\npred &lt;- list(NULL)\nfor(i in 1:10) {\n  ## splitting into test and training data set\n  trainIndex &lt;- which(id != i)     \n  testIndex &lt;- which(id == i)                \n  ## weights that are used for fitting the models\n  weights &lt;- as.numeric(table(factor(trainIndex, levels = c(1:N))))\n  ## testdata\n  testdata &lt;- RainIbk[testIndex,]\n  ## observations    \n  obs &lt;- c(obs, RainIbk$rain[testIndex])\n  ## estimation\n  modelfits &lt;- fits(RainIbk, weights)\n  ## Prediction\n  pred2 &lt;- lapply(modelfits, predict, newdata = testdata, type = \"cumprob\")\n  pred &lt;- mapply(rbind, pred, pred2, SIMPLIFY = FALSE)\n}\nnames(pred) &lt;- c(names(modelfits))\n\n## function to compute RPS\nrps &lt;- function(pred, obs) {\n  OBS &lt;- NULL\n  for(i in 1:N) \n    OBS &lt;- rbind(OBS, rep(0:1, c(obs[i] - 1, length(q) - obs[i] + 1)))\n  apply((OBS-pred)^2, 1, sum)\n}\n\n## compute rps\nRPS &lt;- lapply(pred, rps, obs = as.numeric(cut(obs, c(-Inf, q, Inf))))\n\n## bootstrapping mean rps \nrpsall &lt;- NULL\nfor(i in 1:250) {\n  index &lt;- sample(length(obs), replace = TRUE)\n  rpsall &lt;- rbind(rpsall, sapply(RPS, function(x) mean(x[index])))\n}\n  \nrpssall &lt;- 1 - rpsall/rpsall[,1]\nboxplot(rpssall[,-1], ylab = \"RPSS\", main = \"RPSS relative to XLR\")\nabline(h = 0, lty = 2)",
    "crumbs": [
      "Heteroscedastic extended logistic regression",
      "hxlr"
    ]
  },
  {
    "objectID": "man/RainIbk.html",
    "href": "man/RainIbk.html",
    "title": "crch",
    "section": "",
    "text": "Accumulated 5-8 days precipitation amount for Innsbruck. Data includes GEFS reforecasts (Hamill et al. 2013) and observations from SYNOP station Innsbruck Airport (11120) from 2000-01-01 to 2013-09-17.\n\ndata(\"RainIbk\", package = \"crch\")\n\nA data frame with 4977 rows. The first column (rain) are 3 days accumulated precipitation amount observations, Columns 2-12 (rainfc) are 5-8 days accumulated precipitation amount forecasts from the individual ensemble members.\n\nObservations: https://www.ogimet.com/synops.phtml.en\nReforecasts: https://psl.noaa.gov/forecasts/reforecast2/\n\nHamill TM, Bates GT, Whitaker JS, Murray DR, Fiorino M, Galarneau Jr TJ, Zhu Y, Lapenta W (2013). NOAA’s Second-Generation Global Medium-Range Ensemble Reforecast Data Set. Bulletin of the American Meteorological Society, 94(10), 1553-1565.\n\n\nlibrary(\"crch\")\n\n## Spread skill relationship ##\n\n## load and prepare data\ndata(\"RainIbk\", package = \"crch\")\n\n## mean and standard deviation of square root transformed ensemble forecasts\nRainIbk$sqrtensmean &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, mean)\nRainIbk$sqrtenssd &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]),  1, sd)\n\n## quintiles of sqrtenssd\nsdcat &lt;- cut(RainIbk$sqrtenssd, c(-Inf, quantile(RainIbk$sqrtenssd, \n  seq(0.2,0.8,0.2)), Inf), labels = c(1:5))\n\n## mean forecast errors for each quintile\nm &lt;- NULL\nfor(i in levels(sdcat)) {\n  m &lt;- c(m, mean((sqrt(RainIbk$rain)[sdcat == i] -\n  RainIbk$sqrtensmean[sdcat == i])^2, na.rm = TRUE))\n}\n\n## plot\nboxplot((sqrt(rain) - sqrtensmean)^2~sdcat, RainIbk, \n  xlab = \"Quintile of ensemble standard deviation\", \n  ylab = \"mean squared error\", main = \"Spread skill relationship\")",
    "crumbs": [
      "Data sets",
      "RainIbk"
    ]
  },
  {
    "objectID": "man/RainIbk.html#precipitation-observations-and-forecasts-for-innsbruck",
    "href": "man/RainIbk.html#precipitation-observations-and-forecasts-for-innsbruck",
    "title": "crch",
    "section": "",
    "text": "Accumulated 5-8 days precipitation amount for Innsbruck. Data includes GEFS reforecasts (Hamill et al. 2013) and observations from SYNOP station Innsbruck Airport (11120) from 2000-01-01 to 2013-09-17.\n\ndata(\"RainIbk\", package = \"crch\")\n\nA data frame with 4977 rows. The first column (rain) are 3 days accumulated precipitation amount observations, Columns 2-12 (rainfc) are 5-8 days accumulated precipitation amount forecasts from the individual ensemble members.\n\nObservations: https://www.ogimet.com/synops.phtml.en\nReforecasts: https://psl.noaa.gov/forecasts/reforecast2/\n\nHamill TM, Bates GT, Whitaker JS, Murray DR, Fiorino M, Galarneau Jr TJ, Zhu Y, Lapenta W (2013). NOAA’s Second-Generation Global Medium-Range Ensemble Reforecast Data Set. Bulletin of the American Meteorological Society, 94(10), 1553-1565.\n\n\nlibrary(\"crch\")\n\n## Spread skill relationship ##\n\n## load and prepare data\ndata(\"RainIbk\", package = \"crch\")\n\n## mean and standard deviation of square root transformed ensemble forecasts\nRainIbk$sqrtensmean &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]), 1, mean)\nRainIbk$sqrtenssd &lt;- \n  apply(sqrt(RainIbk[,grep('^rainfc',names(RainIbk))]),  1, sd)\n\n## quintiles of sqrtenssd\nsdcat &lt;- cut(RainIbk$sqrtenssd, c(-Inf, quantile(RainIbk$sqrtenssd, \n  seq(0.2,0.8,0.2)), Inf), labels = c(1:5))\n\n## mean forecast errors for each quintile\nm &lt;- NULL\nfor(i in levels(sdcat)) {\n  m &lt;- c(m, mean((sqrt(RainIbk$rain)[sdcat == i] -\n  RainIbk$sqrtensmean[sdcat == i])^2, na.rm = TRUE))\n}\n\n## plot\nboxplot((sqrt(rain) - sqrtensmean)^2~sdcat, RainIbk, \n  xlab = \"Quintile of ensemble standard deviation\", \n  ylab = \"mean squared error\", main = \"Spread skill relationship\")",
    "crumbs": [
      "Data sets",
      "RainIbk"
    ]
  },
  {
    "objectID": "man/coef.crch.html",
    "href": "man/coef.crch.html",
    "title": "crch",
    "section": "",
    "text": "Methods for extracting information from fitted crch objects.\n\n\n\n## S3 method for class 'crch'\ncoef(object, model = c(\"full\", \"location\", \"scale\", \"df\"), ...)\n## S3 method for class 'crch'\nvcov(object, model = c(\"full\", \"location\", \"scale\", \"df\"), ...)\n## S3 method for class 'crch'\nterms(x, model = c(\"location\", \"scale\", \"full\"), ...)\n## S3 method for class 'crch'\nfitted(object, type = c(\"location\", \"scale\"), ...)\n\n\n\n\n\n\n\nobject, x\n\n\nan object of class “crch”.\n\n\n\n\nmodel\n\n\nmodel for which coefficients shall be returned.\n\n\n\n\ntype\n\n\ntype of fitted values.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nIn addition to the methods above, a set of standard extractor functions for “crch” objects is available, including methods to the generic functions print, summary, logLik, and residuals.\n\n\n\ncrch",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "coef.crch"
    ]
  },
  {
    "objectID": "man/coef.crch.html#methods-for-fitted-crch-models",
    "href": "man/coef.crch.html#methods-for-fitted-crch-models",
    "title": "crch",
    "section": "",
    "text": "Methods for extracting information from fitted crch objects.\n\n\n\n## S3 method for class 'crch'\ncoef(object, model = c(\"full\", \"location\", \"scale\", \"df\"), ...)\n## S3 method for class 'crch'\nvcov(object, model = c(\"full\", \"location\", \"scale\", \"df\"), ...)\n## S3 method for class 'crch'\nterms(x, model = c(\"location\", \"scale\", \"full\"), ...)\n## S3 method for class 'crch'\nfitted(object, type = c(\"location\", \"scale\"), ...)\n\n\n\n\n\n\n\nobject, x\n\n\nan object of class “crch”.\n\n\n\n\nmodel\n\n\nmodel for which coefficients shall be returned.\n\n\n\n\ntype\n\n\ntype of fitted values.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nIn addition to the methods above, a set of standard extractor functions for “crch” objects is available, including methods to the generic functions print, summary, logLik, and residuals.\n\n\n\ncrch",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "coef.crch"
    ]
  },
  {
    "objectID": "man/plot.crch.boost.html",
    "href": "man/plot.crch.boost.html",
    "title": "crch",
    "section": "",
    "text": "Plot paths of coefficients or log-likelihood contributions for crch.boost models.\n\n\n\n## S3 method for class 'crch.boost'\nplot(x, loglik = FALSE, \n  standardize = TRUE, which = c(\"both\", \"location\", \"scale\"), \n  mstop = NULL, coef.label = TRUE, col = NULL, ...)\n\n\n\n\n\n\n\nx\n\n\nan object of class “crch.boost”.\n\n\n\n\nloglik\n\n\nlogical whether log-likelihood contribution shall be plotted instead of coefficient value.\n\n\n\n\nstandardize\n\n\nlogical whether coefficients shall be standardized. Not used if loglik = TRUE\n\n\n\n\nwhich\n\n\nwhich coefficients: “location” and “scale” plots only the coefficients for the location and scale part of the model respectively. “both” plots the coefficient paths of both parts in one graph.\n\n\n\n\nmstop\n\n\nStopping iteration for which a vertical line is plotted. Possible choices are “max”, “aic”, “bic”, “cv”, “all”, or “no”. Default is the stopping iteration used for fitting.\n\n\n\n\ncoef.label\n\n\nlogical whether paths shall be labeled.\n\n\n\n\ncol\n\n\nColor(s) for the paths. If which=“both” a vector of two colors where the paths for the location are plotted in the first color and for the scale in the second color.\n\n\n\n\n…\n\n\nfurther arguments passed to plot.ts.\n\n\n\n\n\n\ncrch.boost,plot.ts",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "plot.crch.boost"
    ]
  },
  {
    "objectID": "man/plot.crch.boost.html#visualizing-coefficient-paths-for-boosted-crch-models",
    "href": "man/plot.crch.boost.html#visualizing-coefficient-paths-for-boosted-crch-models",
    "title": "crch",
    "section": "",
    "text": "Plot paths of coefficients or log-likelihood contributions for crch.boost models.\n\n\n\n## S3 method for class 'crch.boost'\nplot(x, loglik = FALSE, \n  standardize = TRUE, which = c(\"both\", \"location\", \"scale\"), \n  mstop = NULL, coef.label = TRUE, col = NULL, ...)\n\n\n\n\n\n\n\nx\n\n\nan object of class “crch.boost”.\n\n\n\n\nloglik\n\n\nlogical whether log-likelihood contribution shall be plotted instead of coefficient value.\n\n\n\n\nstandardize\n\n\nlogical whether coefficients shall be standardized. Not used if loglik = TRUE\n\n\n\n\nwhich\n\n\nwhich coefficients: “location” and “scale” plots only the coefficients for the location and scale part of the model respectively. “both” plots the coefficient paths of both parts in one graph.\n\n\n\n\nmstop\n\n\nStopping iteration for which a vertical line is plotted. Possible choices are “max”, “aic”, “bic”, “cv”, “all”, or “no”. Default is the stopping iteration used for fitting.\n\n\n\n\ncoef.label\n\n\nlogical whether paths shall be labeled.\n\n\n\n\ncol\n\n\nColor(s) for the paths. If which=“both” a vector of two colors where the paths for the location are plotted in the first color and for the scale in the second color.\n\n\n\n\n…\n\n\nfurther arguments passed to plot.ts.\n\n\n\n\n\n\ncrch.boost,plot.ts",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "plot.crch.boost"
    ]
  },
  {
    "objectID": "man/clogis.html",
    "href": "man/clogis.html",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right censored logistic distribution.\n\n\n\ndclogis(x, location = 0, scale = 1, left = -Inf, right = Inf, log = FALSE)\n\npclogis(q, location = 0, scale = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqclogis(p, location = 0, scale = 1, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nrclogis(n, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe censored logistic distribution has density \\(f(x)\\):\n\n\n\n\\(\\Lambda((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Lambda((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\lambda((x - \\mu)/\\sigma)/\\sigma\\)\n\n\nif \\(left &lt; x &lt; right\\)\n\n\n\nwhere \\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndclogis gives the density, pclogis gives the distribution function, qclogis gives the quantile function, and rclogis generates random deviates.\n\n\n\ndlogis",
    "crumbs": [
      "Distributions",
      "clogis"
    ]
  },
  {
    "objectID": "man/clogis.html#the-censored-logistic-distribution",
    "href": "man/clogis.html#the-censored-logistic-distribution",
    "title": "crch",
    "section": "",
    "text": "Density, distribution function, quantile function, and random generation for the left and/or right censored logistic distribution.\n\n\n\ndclogis(x, location = 0, scale = 1, left = -Inf, right = Inf, log = FALSE)\n\npclogis(q, location = 0, scale = 1, left = -Inf, right = Inf, \n  lower.tail = TRUE, log.p = FALSE)\n\nqclogis(p, location = 0, scale = 1, left = -Inf, right = Inf,\n  lower.tail = TRUE, log.p = FALSE)\n\nrclogis(n, location = 0, scale = 1, left = -Inf, right = Inf)\n\n\n\n\n\n\n\nx, q\n\n\nvector of quantiles.\n\n\n\n\np\n\n\nvector of probabilities.\n\n\n\n\nn\n\n\nnumber of observations. If length(n) &gt; 1, the length is taken to be the number required.\n\n\n\n\nlocation\n\n\nlocation parameter.\n\n\n\n\nscale\n\n\nscale parameter.\n\n\n\n\nleft\n\n\nleft censoring point.\n\n\n\n\nright\n\n\nright censoring point.\n\n\n\n\nlog, log.p\n\n\nlogical; if TRUE, probabilities p are given as log(p).\n\n\n\n\nlower.tail\n\n\nlogical; if TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].\n\n\n\n\n\n\nIf location or scale are not specified they assume the default values of 0 and 1, respectively. left and right have the defaults -Inf and Inf respectively.\nThe censored logistic distribution has density \\(f(x)\\):\n\n\n\n\\(\\Lambda((left - \\mu)/\\sigma)\\)\n\n\nif \\(x \\le left\\)\n\n\n\n\n\\(1 - \\Lambda((right - \\mu)/\\sigma)\\)\n\n\nif \\(x \\ge right\\)\n\n\n\n\n\\(\\lambda((x - \\mu)/\\sigma)/\\sigma\\)\n\n\nif \\(left &lt; x &lt; right\\)\n\n\n\nwhere \\(\\Lambda\\) and \\(\\lambda\\) are the cumulative distribution function and probability density function of the standard logistic distribution respectively, \\(\\mu\\) is the location of the distribution, and \\(\\sigma\\) the scale.\n\n\n\ndclogis gives the density, pclogis gives the distribution function, qclogis gives the quantile function, and rclogis generates random deviates.\n\n\n\ndlogis",
    "crumbs": [
      "Distributions",
      "clogis"
    ]
  },
  {
    "objectID": "man/crch.control.html",
    "href": "man/crch.control.html",
    "title": "crch",
    "section": "",
    "text": "Auxiliary function for crch fitting. Specifies a list of values passed to optim.\n\n\n\ncrch.control(method = \"BFGS\", maxit = NULL, hessian = NULL,\n  trace = FALSE, start = NULL, dot = \"separate\",\n  lower = -Inf, upper = Inf, ...)\n\n\n\n\n\n\nmethod\n\n\noptimization method passed to optim\n\n\n\n\nmaxit\n\n\nthe maximum number of iterations. Default is 5000 except for method=“boosting” where the default is 100.\n\n\n\n\nhessian\n\n\nlogical or NULL. If TRUE the numerical Hessian matrix from the optim output is used for estimation of the covariance matrix. If FALSE no covariance matrix is computed. If NULL (the default) the Hessian matrix is computed analytically for dist=“gaussian”, dist=“logistic”, and dist=“student” with predefined df. For dist=“student” without prespecified df, no analytical solution is available and a numerical Hessian matrix is forced.\n\n\n\n\ntrace\n\n\nnon-negative integer. If positive, tracing information on the progress of the optimization is produced.\n\n\n\n\nstart\n\n\ninitial values for the parameters to be optimized over.\n\n\n\n\ndot\n\n\ncharacter specifying how to process formula parts with a dot (.) on the right-hand side. This can either be “separate” so that each formula part is expanded separately or “sequential” so that the parts are expanded sequentially conditional on all prior parts. Default is “separate”\n\n\n\n\nlower, upper\n\n\nbounds on the variables for the “L-BFGS-B” method, or bounds in which to search for method “Brent”.\n\n\n\n\n…\n\n\nadditional parameters passed to optim.\n\n\n\n\n\n\nA list with components named as the arguments.\n\n\n\ncrch, optim",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch.control"
    ]
  },
  {
    "objectID": "man/crch.control.html#control-options-for-crch-models",
    "href": "man/crch.control.html#control-options-for-crch-models",
    "title": "crch",
    "section": "",
    "text": "Auxiliary function for crch fitting. Specifies a list of values passed to optim.\n\n\n\ncrch.control(method = \"BFGS\", maxit = NULL, hessian = NULL,\n  trace = FALSE, start = NULL, dot = \"separate\",\n  lower = -Inf, upper = Inf, ...)\n\n\n\n\n\n\nmethod\n\n\noptimization method passed to optim\n\n\n\n\nmaxit\n\n\nthe maximum number of iterations. Default is 5000 except for method=“boosting” where the default is 100.\n\n\n\n\nhessian\n\n\nlogical or NULL. If TRUE the numerical Hessian matrix from the optim output is used for estimation of the covariance matrix. If FALSE no covariance matrix is computed. If NULL (the default) the Hessian matrix is computed analytically for dist=“gaussian”, dist=“logistic”, and dist=“student” with predefined df. For dist=“student” without prespecified df, no analytical solution is available and a numerical Hessian matrix is forced.\n\n\n\n\ntrace\n\n\nnon-negative integer. If positive, tracing information on the progress of the optimization is produced.\n\n\n\n\nstart\n\n\ninitial values for the parameters to be optimized over.\n\n\n\n\ndot\n\n\ncharacter specifying how to process formula parts with a dot (.) on the right-hand side. This can either be “separate” so that each formula part is expanded separately or “sequential” so that the parts are expanded sequentially conditional on all prior parts. Default is “separate”\n\n\n\n\nlower, upper\n\n\nbounds on the variables for the “L-BFGS-B” method, or bounds in which to search for method “Brent”.\n\n\n\n\n…\n\n\nadditional parameters passed to optim.\n\n\n\n\n\n\nA list with components named as the arguments.\n\n\n\ncrch, optim",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "crch.control"
    ]
  },
  {
    "objectID": "man/TruncatedNormal.html",
    "href": "man/TruncatedNormal.html",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-truncated normal distributions using the workflow from the distributions3 package.\n\nTruncatedNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\n\n\n\n\n\nmu\n\n\nnumeric. The location parameter of the underlying untruncated normal distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nsigma\n\n\nnumeric. The scale parameter (standard deviation) of the underlying untruncated normal distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left truncation point. Can be any real number, defaults to -Inf (untruncated). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the untruncated normal distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right truncation point. Can be any real number, defaults to Inf (untruncated). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the untruncated normal distribution at this point.\n\n\n\nThe constructor function TruncatedNormal sets up a distribution object, representing the truncated normal probability distribution by the corresponding parameters: the latent mean mu = \\(\\mu\\) and latent standard deviation sigma = \\(\\sigma\\) (i.e., the parameters of the underlying untruncated normal variable), the left truncation point (with -Inf corresponding to untruncated), and the right truncation point (with Inf corresponding to untruncated).\nThe truncated normal distribution has probability density function (PDF):\n\n\n\\(f(x) = 1/\\sigma \\phi((x - \\mu)/\\sigma) / (\\Phi((right - \\mu)/\\sigma) - \\Phi((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise, where \\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of truncated normal distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the TruncatedNormal distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the truncated normal distributions in the crch package, see dtnorm, and the crps_tnorm function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (always TRUE).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA TruncatedNormal distribution object.\n\ndtnorm, Normal, CensoredNormal, TruncatedLogistic, TruncatedStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three truncated normal distributions:\n## - untruncated standard normal\n## - left-truncated at zero with latent mu = 1 and sigma = 1\n## - interval-truncated in [0, 5] with latent mu = 1 and sigma = 2\nX &lt;- TruncatedNormal(\n  mu    = c(   0,   1, 1),\n  sigma = c(   1,   1, 2),\n  left  = c(-Inf,   0, 0),\n  right = c( Inf, Inf, 5)\n)\nX\n\n[1] \"TruncatedNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\"\n[2] \"TruncatedNormal(mu = 1, sigma = 1, left =    0, right = Inf)\"\n[3] \"TruncatedNormal(mu = 1, sigma = 2, left =    0, right =   5)\"\n\n## compute mean and variance of the truncated distribution\nmean(X)\n\n[1] 0.000000 1.287600 1.891488\n\nvariance(X)\n\n[1] 1.0000000 0.6296863 1.5063753\n\n## higher moments (skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1       r_2        r_3         r_4         r_5\n[1,] -0.3421647 0.4419331 -0.6121245 -0.05869749 -1.74610318\n[2,]  0.8831861 1.7520048  1.7872496  0.84989937  0.02234993\n[3,]  2.4106941 0.4519601  0.3781711  1.07687138  0.67957521\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"untruncated\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-truncated at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-truncated in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3989423 0.2876000 0.2982914\n\npdf(X, x, log = TRUE)\n\n[1] -0.9189385 -1.2461848 -1.2096844\n\nlog_pdf(X, x)\n\n[1] -0.9189385 -1.2461848 -1.2096844\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.0000000 0.2863151\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.000000 1.200174 1.732409\n\n## cdf() and quantile() are inverses\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05    q_0.5   q_0.95\n[1,] -1.6448536 0.000000 1.644854\n[2,]  0.1609566 1.200174 2.727185\n[3,]  0.1858320 1.732409 4.175247\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -1.644854  1.200174  4.175247\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -1.644854\n[2,]  1.200174\n[3,]  4.175247\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical   empirical\n[1,]    0.000000 -0.01591685\n[2,]    1.287600  1.25873948\n[3,]    1.891488  1.90212846\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.2336950 0.8408519 0.4738612",
    "crumbs": [
      "distributions3 objects",
      "TruncatedNormal"
    ]
  },
  {
    "objectID": "man/TruncatedNormal.html#create-a-truncated-normal-distribution",
    "href": "man/TruncatedNormal.html#create-a-truncated-normal-distribution",
    "title": "crch",
    "section": "",
    "text": "Class and methods for left-, right-, and interval-truncated normal distributions using the workflow from the distributions3 package.\n\nTruncatedNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\n\n\n\n\n\nmu\n\n\nnumeric. The location parameter of the underlying untruncated normal distribution, typically written \\(\\mu\\) in textbooks. Can be any real number, defaults to 0.\n\n\n\n\nsigma\n\n\nnumeric. The scale parameter (standard deviation) of the underlying untruncated normal distribution, typically written \\(\\sigma\\) in textbooks. Can be any positive number, defaults to 1.\n\n\n\n\nleft\n\n\nnumeric. The left truncation point. Can be any real number, defaults to -Inf (untruncated). If set to a finite value, the distribution has a point mass at left whose probability corresponds to the cumulative probability function of the untruncated normal distribution at this point.\n\n\n\n\nright\n\n\nnumeric. The right truncation point. Can be any real number, defaults to Inf (untruncated). If set to a finite value, the distribution has a point mass at right whose probability corresponds to 1 minus the cumulative probability function of the untruncated normal distribution at this point.\n\n\n\nThe constructor function TruncatedNormal sets up a distribution object, representing the truncated normal probability distribution by the corresponding parameters: the latent mean mu = \\(\\mu\\) and latent standard deviation sigma = \\(\\sigma\\) (i.e., the parameters of the underlying untruncated normal variable), the left truncation point (with -Inf corresponding to untruncated), and the right truncation point (with Inf corresponding to untruncated).\nThe truncated normal distribution has probability density function (PDF):\n\n\n\\(f(x) = 1/\\sigma \\phi((x - \\mu)/\\sigma) / (\\Phi((right - \\mu)/\\sigma) - \\Phi((left - \\mu)/\\sigma))\\)\nfor \\(left \\le x \\le right\\), and 0 otherwise, where \\(\\Phi\\) and \\(\\phi\\) are the cumulative distribution function and probability density function of the standard normal distribution respectively.\nAll parameters can also be vectors, so that it is possible to define a vector of truncated normal distributions with potentially different parameters. All parameters need to have the same length or must be scalars (i.e., of length 1) which are then recycled to the length of the other parameters.\nFor the TruncatedNormal distribution objects there is a wide range of standard methods available to the generics provided in the distributions3 package: pdf and log_pdf for the (log-)density (PDF), cdf for the probability from the cumulative distribution function (CDF), quantile for quantiles, random for simulating random variables, crps for the continuous ranked probability score (CRPS), and support for the support interval (minimum and maximum). Internally, these methods rely on the usual d/p/q/r functions provided for the truncated normal distributions in the crch package, see dtnorm, and the crps_tnorm function from the scoringRules package. The methods is_discrete and is_continuous can be used to query whether the distributions are discrete on the entire support (always FALSE) or continuous on the entire support (always TRUE).\nSee the examples below for an illustration of the workflow for the class and methods.\n\nA TruncatedNormal distribution object.\n\ndtnorm, Normal, CensoredNormal, TruncatedLogistic, TruncatedStudentsT\n\n\nlibrary(\"crch\")\n\n\n## package and random seed\nlibrary(\"distributions3\")\nset.seed(6020)\n\n## three truncated normal distributions:\n## - untruncated standard normal\n## - left-truncated at zero with latent mu = 1 and sigma = 1\n## - interval-truncated in [0, 5] with latent mu = 1 and sigma = 2\nX &lt;- TruncatedNormal(\n  mu    = c(   0,   1, 1),\n  sigma = c(   1,   1, 2),\n  left  = c(-Inf,   0, 0),\n  right = c( Inf, Inf, 5)\n)\nX\n\n[1] \"TruncatedNormal(mu = 0, sigma = 1, left = -Inf, right = Inf)\"\n[2] \"TruncatedNormal(mu = 1, sigma = 1, left =    0, right = Inf)\"\n[3] \"TruncatedNormal(mu = 1, sigma = 2, left =    0, right =   5)\"\n\n## compute mean and variance of the truncated distribution\nmean(X)\n\n[1] 0.000000 1.287600 1.891488\n\nvariance(X)\n\n[1] 1.0000000 0.6296863 1.5063753\n\n## higher moments (skewness, kurtosis) are not implemented yet\n\n## support interval (minimum and maximum)\nsupport(X)\n\n      min max\n[1,] -Inf Inf\n[2,]    0 Inf\n[3,]    0   5\n\n## simulate random variables\nrandom(X, 5)\n\n            r_1       r_2        r_3         r_4         r_5\n[1,] -0.3421647 0.4419331 -0.6121245 -0.05869749 -1.74610318\n[2,]  0.8831861 1.7520048  1.7872496  0.84989937  0.02234993\n[3,]  2.4106941 0.4519601  0.3781711  1.07687138  0.67957521\n\n## histograms of 1,000 simulated observations\nx &lt;- random(X, 1000)\nhist(x[1, ], main = \"untruncated\")\n\n\n\n\n\n\nhist(x[2, ], main = \"left-truncated at zero\")\n\n\n\n\n\n\nhist(x[3, ], main = \"interval-truncated in [0, 5]\")\n\n\n\n\n\n\n## probability density function (PDF) and log-density (or log-likelihood)\nx &lt;- c(0, 0, 1)\npdf(X, x)\n\n[1] 0.3989423 0.2876000 0.2982914\n\npdf(X, x, log = TRUE)\n\n[1] -0.9189385 -1.2461848 -1.2096844\n\nlog_pdf(X, x)\n\n[1] -0.9189385 -1.2461848 -1.2096844\n\n## cumulative distribution function (CDF)\ncdf(X, x)\n\n[1] 0.5000000 0.0000000 0.2863151\n\n## quantiles\nquantile(X, 0.5)\n\n[1] 0.000000 1.200174 1.732409\n\n## cdf() and quantile() are inverses\ncdf(X, quantile(X, 0.5))\n\n[1] 0.5 0.5 0.5\n\nquantile(X, cdf(X, 1))\n\n[1] 1 1 1\n\n## all methods above can either be applied elementwise or for\n## all combinations of X and x, if length(X) = length(x),\n## also the result can be assured to be a matrix via drop = FALSE\np &lt;- c(0.05, 0.5, 0.95)\nquantile(X, p, elementwise = FALSE)\n\n         q_0.05    q_0.5   q_0.95\n[1,] -1.6448536 0.000000 1.644854\n[2,]  0.1609566 1.200174 2.727185\n[3,]  0.1858320 1.732409 4.175247\n\nquantile(X, p, elementwise = TRUE)\n\n[1] -1.644854  1.200174  4.175247\n\nquantile(X, p, elementwise = TRUE, drop = FALSE)\n\n      quantile\n[1,] -1.644854\n[2,]  1.200174\n[3,]  4.175247\n\n## compare theoretical and empirical mean from 1,000 simulated observations\ncbind(\n  \"theoretical\" = mean(X),\n  \"empirical\" = rowMeans(random(X, 1000))\n)\n\n     theoretical   empirical\n[1,]    0.000000 -0.01591685\n[2,]    1.287600  1.25873948\n[3,]    1.891488  1.90212846\n\n## evaluate continuous ranked probability score (CRPS) using scoringRules\nlibrary(\"scoringRules\")\ncrps(X, x)\n\n[1] 0.2336950 0.8408519 0.4738612",
    "crumbs": [
      "distributions3 objects",
      "TruncatedNormal"
    ]
  },
  {
    "objectID": "man/predict.crch.boost.html",
    "href": "man/predict.crch.boost.html",
    "title": "crch",
    "section": "",
    "text": "Obtains various types of predictions for crch.boost models.\n\n\n\n## S3 method for class 'crch.boost'\npredict(object, newdata = NULL, mstop = NULL, ...)\n\n\n\n\n\n\n\nobject\n\n\nan object of class “crch.boost”.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict.\n\n\n\n\nmstop\n\n\nstopping iteration. Can be either a character (“max”, “aic”, “bic”, “cv”) or a numeric value. If not NULL, newdata has to be supplied.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nFor type “response”, “location”, or “scale” a vector with either the location or the scale of the predicted distribution.\nFor type “quantile” a matrix of predicted quantiles each column corresponding to an element of at.\n\n\n\ncrch.boost,predict.crch",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "predict.crch.boost"
    ]
  },
  {
    "objectID": "man/predict.crch.boost.html#predictions-for-boosted-crch-models",
    "href": "man/predict.crch.boost.html#predictions-for-boosted-crch-models",
    "title": "crch",
    "section": "",
    "text": "Obtains various types of predictions for crch.boost models.\n\n\n\n## S3 method for class 'crch.boost'\npredict(object, newdata = NULL, mstop = NULL, ...)\n\n\n\n\n\n\n\nobject\n\n\nan object of class “crch.boost”.\n\n\n\n\nnewdata\n\n\nan optional data frame in which to look for variables with which to predict.\n\n\n\n\nmstop\n\n\nstopping iteration. Can be either a character (“max”, “aic”, “bic”, “cv”) or a numeric value. If not NULL, newdata has to be supplied.\n\n\n\n\n…\n\n\nfurther arguments passed to or from other methods.\n\n\n\n\n\n\nFor type “response”, “location”, or “scale” a vector with either the location or the scale of the predicted distribution.\nFor type “quantile” a matrix of predicted quantiles each column corresponding to an element of at.\n\n\n\ncrch.boost,predict.crch",
    "crumbs": [
      "Heteroscedastic censored and truncated regression",
      "predict.crch.boost"
    ]
  }
]