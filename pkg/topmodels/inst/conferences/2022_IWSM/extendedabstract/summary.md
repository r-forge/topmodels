In order to provide accurate and reliable probabilistic forecasts, distributional regression models are frequently used ranging from basic generalized linear models to generalized additive models for locate, scale, and shape.

For assessing the goodness of fit of such probabilistic regression models, graphical assessment techniques are an important complement to proper scoring rules and help to identify possible model misspecifications. Based on a case study of probabilistic precipitation forecasts, three different model specifications are evaluated graphically to reveal different sources of misspecification such as censoring at zero, hereoscedasticity, and heavy tails.

A unified implementation is provided in the newly developed R package topmodels (https://topmodels.R-Forge.R-project.org/).
