% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/distribution.R
\name{distribution_calculate_moments}
\alias{distribution_calculate_moments}
\alias{random.distribution}
\alias{mean.distribution}
\alias{variance.distribution}
\alias{skewness.distribution}
\alias{kurtosis.distribution}
\title{Method for Numerically Evaluate Central Moments of Probability Distributions}
\usage{
distribution_calculate_moments(
  x,
  what,
  gridsize = 500L,
  batchsize = 10000L,
  applyfun = NULL,
  cores = NULL,
  method = NULL,
  ...
)

\method{random}{distribution}(x, n = 1L, drop = TRUE, ...)

\method{mean}{distribution}(x, ...)

\method{variance}{distribution}(x, ...)

\method{skewness}{distribution}(x, ...)

\method{kurtosis}{distribution}(x, ...)
}
\arguments{
\item{x}{object of class \code{c("NumericNormal", "distribution")}.}

\item{what}{single integer, controls what the C code returns. 1L (mean) 2L
(variance) 3L (skewness) 4L (kurtosis).}

\item{gridsize}{integer, number of grid points used for approximation. Defaults to \code{500L}.}

\item{batchsize}{maximum batch size. Used to split the input into batches.
Lower values reduce required memory but may increase computation time.}

\item{applyfun}{an optional \code{\link[base]{lapply}}-style function with arguments
\code{function(X, FUN, \dots)}. It is used to compute the CRPS for each element
of \code{y}. The default is to use the basic \code{lapply}
function unless the \code{cores} argument is specified (see below).}

\item{cores}{numeric. If set to an integer the \code{applyfun} is set to
\code{\link[parallel]{mclapply}} with the desired number of \code{cores},
except on Windows where \code{\link[parallel]{parLapply}} with
\code{makeCluster(cores)} is used.}

\item{method}{character. Should the grid be set up on the observation scale
and \code{method = "cdf"} be used to compute the corresponding probabilities?
Or should the grid be set up on the probability scale and \code{method = "quantile"}
be used to compute the corresponding observations? By default, \code{"cdf"}
is used for discrete observations whose range is smaller than the \code{gridsize}
and \code{"quantile"} otherwise.}

\item{...}{\code{\link{mean.distribution}}, \code{\link{variance.distribution}},
         \code{\link{skewness.distribution}} and
\code{\link{kurtosis.distribution}} forward the additional arguments (\code{...}) to
\code{\link{distribution_calculate_moments}}; all other functions/methods ignore additional arguments.}

\item{n}{Integer. Number of observations to be drawn.}

\item{drop}{Logical. Should the result be simplified to a vector if possible?}
}
\value{
A (potentially named) numeric vector of length \code{length(x)} with the requested central moment.
}
\description{
Method used to evaluate (approximate) the central moments (mean, variance, skewness, and kurtosis)
for probability distributions for which only the cummulative distribution function (CDF) and -
potentially - the quantile function is provided.
}
\details{
For discrete distributions spanning a range less than \code{gridsize} the PDF is calculated
at \eqn{i = \{0, 1, 2, 3, \dots\}} by differenciating the CDF provided which is then used
to calculate the central moments.

For continuous distributions as well as discrete distributions spanning a
wide range of values (larger than \code{gridsize}) a grid with \code{gridsize}
intervals is created. Given the distribution provides a quantile function,
this grid is specified on a (mostly) uniform grid on the quantile scale. If
no quantile function is provided, the \code{0.01} and \code{99.99} percentile are
calculated approximated via the CDF, between which a uniform grid is
spanned. For each interval the density is approximated using numeric
forward differences

\deqn{f(x_j) = (F(x_{i+1}) - F(x_i)) / (x_{i+1} - x_i)}{f(x[j]) = (F(x[i+1]) - F(x[i])) / (x[i+1] - x[i])}

at each \eqn{x_j = (x_{i+1} + x_i) * 0.5}{x[j] = (x[i+1] + x[i]) * 0.5}
with interval width of \eqn{x_{i+1} - x_i}{x[i+1] - x[i]}.
The densities \eqn{f(x_j)}{f(x[j])} and interval mids \eqn{x_j}{x[j]} are used to calculate
the weighted moments.
}
\examples{
library("distributions3")

## ------------- custom Normal distribution (MyNormal) ----------------

## Constructor function for new 'MyNormal' distribution
MyNormal <- function(mu, sigma) {
    d <- data.frame(mu = mu, sigma = sigma)
    class(d) <- c("MyNormal", "distribution")
    return(d)
}

## Additional S3 methods required
cdf.MyNormal <- getS3method("cdf", class = "Normal")
is_discrete.MyNormal   <- getS3method("is_discrete", class = "Normal")
support.MyNormal       <- getS3method("support", class = "Normal")

## ------------- custom Poisson distribution (MyPoisson) --------------

## Custom constructor function for the 'MyPoisson' distribution
MyPoisson <- function(lambda) {
    d <- data.frame(lambda = lambda)
    class(d) <- c("MyPoisson", "distribution")
    return(d)
}

## Additional S3 methods required
cdf.MyPoisson <- getS3method("cdf", class = "Poisson")
is_discrete.MyPoisson   <- getS3method("is_discrete", class = "Poisson")
support.MyPoisson       <- getS3method("support", class = "Poisson")

}
